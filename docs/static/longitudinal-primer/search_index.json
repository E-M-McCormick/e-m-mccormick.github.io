[["index.html", "The Hitchhiker’s Guide to Longitudinal Models Code Companion About", " The Hitchhiker’s Guide to Longitudinal Models Code Companion Ethan M. McCormick, Michelle L. Byrne, John C. Flournoy, Kathryn L. Mills, &amp; Jennifer H. Pfeifer Published: 18 August, 2022 About The following document is a code companion to The Hitchhiker’s Guide to Longitudinal Models: A Primer on Model Selection for Repeated-Measures Methods, https://osf.io/bn6yu/. Some general notes about this code companion: We believe in the importance of using real data in our examples of longitudinal models. However, some of the models we discuss can not yet be fit using publicly-available neuroimaging data (most often due to a limited number of observations). To bridge this gap, we have synthesized data from a number of sources, detailed in Datasets. Variable names and identification codes have been changed to protect the innocent and to provide examples that will be familiar to developmental cognitive neuroscience researchers. However, one limitation of synthesized data is that model fits are often significantly worsened compared to the real data. As such, for pedagogical purposes, we will fit (and sometimes interpret) results from models that we would usually reject in practice based on overall model fit. Given the nature of R, there are likely several ways to accomplish what we outline here. This code should not be taken as the definitive one way that data manipulation or model fitting can be accomplished, but rather as a standard pipeline that should hopefully be accessible to new users of R and longitudinal methods more generally. In general, we will include the code used to generate the results. However, in the interest of spending more time on the models and associated syntax, we may not include an in-depth explanation of every function or syntax option. The rmarkdown source files are available in a public github repository for those interested. While the contents of this primer and code companion will focus on implementation in the R environment, links will be provided to other programs where possible. A fair warning: code in other languages will be provided in an arbitrary and capricious manner. This policy should be familiar to the reader, given their experience with the text of the manuscript (and if very unlucky, the first author). In general, precision beyond the third decimal place is as real as unicorns and so we will round our numbers to that level when we discuss them. "],["01-introduction.html", "Introduction", " Introduction The first thing we can do is run a function that will load the R packages needed for this code companion, and install them to our machine if they are not already. packages &lt;- c(&quot;utils&quot;, &quot;tidyverse&quot;, &quot;downloadthis&quot;, # packages for data management &quot;foreign&quot;, &quot;MplusAutomation&quot;, # packages for writing data &quot;sjPlot&quot;, &quot;broom&quot;, &quot;kableExtra&quot;, # packages for generating tables &quot;nlme&quot;, &quot;lme4&quot;, &quot;lmerTest&quot;, &quot;stats&quot;, # packages for MLMs &quot;mgcv&quot;, &quot;gamm4&quot;, &quot;itsadug&quot;, # packages for GAMMs &quot;lavaan&quot;, # packages for SEMs &quot;ggplot2&quot;, &quot;semPlot&quot;, &quot;ggeffects&quot;, # packages for visualization &quot;interactions&quot;) # packages for probing interactions if (length(setdiff(packages, rownames(installed.packages()))) &gt; 0) { install.packages(setdiff(packages, rownames(installed.packages())), repos = &quot;http://cran.us.r-project.org&quot;) } invisible(lapply(packages, library, character.only = TRUE)) We have automatically generated a downloadable bibliography of the R package versions used in this companion for later reproducibility. knitr::write_bib(c( .packages(), &quot;bookdown&quot;, &quot;knitr&quot;, &quot;rmarkdown&quot; ), &quot;external/hitchhikers-guide-packages.bib&quot;) Download Bibliography file "],["02-canonical.html", "Canonical Models Multilevel Model Generalized Additive Mixed Model Latent Curve Model Latent Change Score Model", " Canonical Models What follows are canonical versions of growth models in each of the four different frameworks. These models represent basic implementations of a linear growth trajectory with random effects for both the intercept and slope, with the exception of the GAMM, where a non-linear spline model is implemented (otherwise it would just re-capitulate the MLM results). This will be the longest chapter of the codebook since we will cover syntax and model output more in-depth than in later chapters. Remain calm and clutch your towel as necessary. First, we need to read in the datasets we will use in this chapter. executive.function &lt;- utils::read.csv(&quot;data/executive-function.csv&quot;, header = TRUE) %&gt;% select(id, dlpfc1:dlpfc4) executive.function.long &lt;- executive.function %&gt;% tidyr::pivot_longer(cols = starts_with(&quot;dlpfc&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% dplyr::mutate(wave = as.numeric(wave) - 1) feedback.learning &lt;- read.csv(&quot;data/feedback-learning.csv&quot;) %&gt;% select(id, age, modularity) While we will usually read in the wide and long versions of the data directly, here we will demonstrate how to reformat the more common wide data format (i.e., each row corresponds to a different individual and repeated measures are new variables) into the long data format (i.e., each row corresponds to a different repeated measure with multiple rows per person). We can use the pivot_longer() function from the tidyr package (alternatives include melt() from the reshape package). We will collect all the columns that begin with the string dlpfc and pass the values into one column, while creating a new column wave from their number indices (e.g., 1 for dlpfc1). We can then use the mutate() function from the dplyr package to change the wave colum from a character to a numeric variable and subtract \\(1\\) from every value so that the first wave is coded as \\(0\\) (this will be important for interpretations later). Details regarding these datasets can be found in Datasets. However, shortly, the executive-function.csv file contains data for \\(342\\) adolescents measured up to \\(4\\) times. At each wave, adolescents played an executive function task while in an fMRI scanner. For now, we will only use the DLPFC measures to build the canonical growth models. The first \\(5\\) individuals are shown below. These data are in wide format. executive.function %&gt;% filter(id &lt;= 5) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Executive Function Data: Wide Format**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Executive Function Data: Wide Format id dlpfc1 dlpfc2 dlpfc3 dlpfc4 1 -0.184 1.129 -0.840 0.472 2 0.801 1.129 0.801 1.457 3 0.472 1.129 0.144 0.144 4 0.472 0.472 0.472 0.472 5 -0.840 2.114 2.442 2.442 We can then see what this looks like in long format. executive.function.long %&gt;% filter(id &lt;= 5) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Executive Function Data: Long Format**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Executive Function Data: Long Format id wave dlpfc 1 0 -0.184 1 1 1.129 1 2 -0.840 1 3 0.472 2 0 0.801 2 1 1.129 2 2 0.801 2 3 1.457 3 0 0.472 3 1 1.129 3 2 0.144 3 3 0.144 4 0 0.472 4 1 0.472 4 2 0.472 4 3 0.472 5 0 -0.840 5 1 2.114 5 2 2.442 5 3 2.442 The feedback-learning.csv file contains data for \\(297\\) adolescents and young adults measured up to \\(3\\) times. At each wave, individuals played a feedback learning task while in an fMRI scanner. ROI timeseries were then used to construct a brain network graph and the modularity of that graph was calculated. Here we will focus on these modularity values. The first \\(5\\) individuals are shown below. feedback.learning %&gt;% filter(id &lt;= 5) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Feedback Learning Data**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Feedback Learning Data id age modularity 1 20.43 0.117 2 16.70 0.127 2 18.65 0.148 2 20.65 0.143 3 22.68 0.124 3 24.68 0.162 3 26.77 0.107 4 11.63 0.102 4 13.86 0.154 4 15.87 0.154 5 16.50 0.158 5 18.48 0.185 5 20.44 0.183 Before we move into fitting the growth models in each of the four frameworks, we can begin by exporting the data to SAS and Mplus compatible file types. We will use the MplusAutomation package to write our Rdata into a .dat file. We have wrapped the command in the capture.output() function so that we can retain a record of the column names (Mplus does not accept files with headers) to prevent referencing the wrong variable when we run our model. The output of the MplusAutomation command prepareMplusData() will be saved in a text file in the same external directory. filename &lt;- &quot;executive-function&quot; capture.output( MplusAutomation::prepareMplusData(executive.function, paste0(&quot;external/&quot;,filename,&quot;.dat&quot;)), file=paste0(&quot;external/&quot;,filename,&quot;_MplusAutomation.txt&quot;)) Although we do not show the running and output of these models in-depth, all the Mplus files needed to recreate the MLM and SEM models are available to be downloaded below. Download Mplus files For readers interested in how to automate running Mplus models through R, please consult the extrememly useful functions in MplusAutomation that allow you to generate syntax, run saved input files, and re-import Mplus models into the R environment. Please note that a local Mplus license is still necessary to run these models. We can also use the package foreign to write out the data to a SAS compatible text file. The write.foreign() function also outputs a syntax file that imports the data into the SAS environment. foreign::write.foreign(executive.function.long, datafile = paste0(&quot;external/&quot;,filename,&quot;.txt&quot;), codefile = paste0(&quot;external/import_&quot;,filename,&quot;.sas&quot;), package=&quot;SAS&quot;) For convenience, all the SAS files needed to recreate the MLM analyses are available for download below. Download SAS files Multilevel Model We will start with the multilevel growth model using our executive.function data. There are a number of package options to fit multilevel models, but we will focus here on two of the most popular: nlme and lme4. We will also use the lmerTest package which outputs p-values for the tests, which are not included in the lme4 package. We will fit a very simple linear model with a random intercept and slope for the DLPFC activation data using all of these packages. For these initial models, we will mostly use wave as our metric of time rather than age for simplicity. We will return to models which use different time variables in later sections. nlme The nlme function lme() separates its syntax into a fixed and random argument using the standard glm() syntax common to R. In the random argument, we indicate that the random intercept (1) and random slope (wave) are nested within id using the pipe (|) character. We will indicate that rows with missing data will be omitted using na.action = na.omit and set the estimator to REstricted Maximum Likelihood (REML). For a discussion of REML versus Full Information Maximum Likelihood (FIML; set method = \"ML\"), see more information here. Once the model is finished running, we can print the model output to the console using the summary() function. Here we use the argument correlation=FALSE to suppress the correlation of fixed effects output, which is unlikely to be of interest to applied researchers. mlm.nlme &lt;- nlme::lme(dlpfc ~ 1 + wave, random = ~ 1 + wave | id, na.action = na.omit, method = &quot;REML&quot;, data = executive.function.long) summary(mlm.nlme, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: executive.function.long ## AIC BIC logLik ## 3510.473 3541.503 -1749.236 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 0.8120176 (Intr) ## wave 0.2231279 -0.354 ## Residual 0.7024454 ## ## Fixed effects: dlpfc ~ 1 + wave ## Value Std.Error DF t-value p-value ## (Intercept) 0.5458598 0.05440921 961 10.032490 0 ## wave 0.1185110 0.02132837 961 5.556492 0 ## Correlation: ## (Intr) ## wave -0.545 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.8835588 -0.5108207 -0.0265644 0.5325893 2.6759419 ## ## Number of Observations: 1304 ## Number of Groups: 342 The first section of the model output shows the loglikelihood (logLik) and associated absolute fit indices (AIC and BIC). The Random effects section shows parameter estimtaes of the standard deviations (StdDev) and correlations (Corr) of the random effects (the identities are denoted by labels to the left of the matrix), as well as the level-1 error standard deviation (Residual). We can see that the standard deviation of the random intercept (\\(StdDev = 0.812\\)) is substantially larger than that of the random slope (\\(StdDev = 0.223\\)). This is often the case and has more to do with the scaling of the effect than anything else. The correlation between the random effects (\\(Corr = -0.354\\)) suggests that individual with higher initial levels of DLPFC activation show lower slope values . We will need to interpret this in the context of the fixed effects (e.g., are the slopes less positive, or more negative?), and plotting the predicted effects is often useful for this interpretation. The Fixed effects section contains the regression estimates of our fixed effects. Here we can see that the average value of DLPFC activation at the intercept is \\(0.546\\). Because we coded the wave predictor to have values of \\(0\\) at the first measurement occasion, this means that the intercept corresponds to initial DLPFC activation. Of course, the units here aren”t meaningful, but initial status is often (but not always) the desired interpretation of the intercept term. Here the slope is positive and significant (\\(\\gamma_{wave} = .199, SE = 0.021, p &lt; .001\\)). The final section contains information about the number of observations and number of groups, which are good values to check to ensure that the nesting of the data in the model corresponds to expectations. lme4 The lmer() function has largely supplanted lme() in most applications of multilevel models. Here, the formula is contained within a single line but is largely the same format. Additionally, the method = \"REML\" argument has been changed to REML = TRUE (REML = FALSE gives us FIML). mlm.lme4 &lt;- lme4::lmer(dlpfc ~ 1 + wave + (1 + wave | id), na.action = na.omit, REML = TRUE, data = executive.function.long) summary(mlm.lme4, correlation = FALSE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: dlpfc ~ 1 + wave + (1 + wave | id) ## Data: executive.function.long ## ## REML criterion at convergence: 3498.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.88358 -0.51082 -0.02656 0.53257 2.67596 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.65939 0.8120 ## wave 0.04979 0.2231 -0.35 ## Residual 0.49342 0.7024 ## Number of obs: 1304, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 0.54586 0.05441 10.032 ## wave 0.11851 0.02133 5.556 The main differences in the output are that lmer() gives the variance of the random effects in addition to the standard deviations, and that there are no longer p-values associated with the fixed effects. However, all the values are identical to the lme() solution (which should make us sigh in relief). If we wish to extract significance information on the random effect components, we can calculate confidence intervals using the confint() function from the stats package. confint(mlm.lme4) ## 2.5 % 97.5 % ## .sig01 0.71618630 0.9100304 ## .sig02 -0.52328047 -0.1152876 ## .sig03 0.15905056 0.2773230 ## .sigma 0.66537145 0.7430663 ## (Intercept) 0.43908311 0.6526543 ## wave 0.07667863 0.1604106 For each parameter, we want to check if the confidence interval contains \\(0\\). Unfortunately, the standard command labels things in non-specific terms (e.g., .sig01). If we want more informative labels, we can include the oldNames = FALSE argument. confint(mlm.lme4, oldNames = TRUE) ## Computing profile confidence intervals ... ## 2.5 % 97.5 % ## .sig01 0.71618630 0.9100304 ## .sig02 -0.52328047 -0.1152876 ## .sig03 0.15905056 0.2773230 ## .sigma 0.66537145 0.7430663 ## (Intercept) 0.43908311 0.6526543 ## wave 0.07667863 0.1604106 As we can see, these labels are much more informative to ensure we are interpreting the correct parameter. Note: sigma will always be the level \\(1\\) residual variance and will not have an informative label. The corresponding command for computing confidence intervals in nlme is intervals(). lmerTest If we wish to retain p-values in our solution, we can load the package lmerTest and use its version of lmer() to fit the model. The syntax is identical to what we used above, and the parameter estimates are as well. mlm.lmerTest &lt;- lmerTest::lmer(dlpfc ~ 1 + wave + (1 + wave | id), na.action = na.omit, REML = TRUE, data = executive.function.long) summary(mlm.lmerTest, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: dlpfc ~ 1 + wave + (1 + wave | id) ## Data: executive.function.long ## ## REML criterion at convergence: 3498.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.88358 -0.51082 -0.02656 0.53257 2.67596 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.65939 0.8120 ## wave 0.04979 0.2231 -0.35 ## Residual 0.49342 0.7024 ## Number of obs: 1304, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.54586 0.05441 340.07130 10.032 &lt; 2e-16 *** ## wave 0.11851 0.02133 331.21032 5.556 5.67e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 MLM Outputs The summary() function output, while extensive, is not formatted for publication. However, we can use a great function tab_model() from the sjPlot package to generate publication-quality tables from the MLM output. Here we will merge the results from the nlme and lmerTest packages. sjPlot::tab_model(mlm.nlme, mlm.lmerTest, show.se = TRUE, show.df = FALSE, show.ci = FALSE, digits = 3, pred.labels = c(&quot;Intercept&quot;, &quot;Wave&quot;), dv.labels = c(&quot;nlme&quot;, &quot;lme4&quot;), string.se = &quot;SE&quot;, string.p = &quot;P-Value&quot;)   nlme lme4 Predictors Estimates SE P-Value Estimates SE P-Value Intercept 0.546 0.054 &lt;0.001 0.546 0.054 &lt;0.001 Wave 0.119 0.021 &lt;0.001 0.119 0.021 &lt;0.001 Random Effects σ2 0.49 0.49 τ00 0.66 id 0.66 id τ11 0.05 id.wave 0.05 id.wave ρ01 -0.35 id -0.35 id ICC 0.57 0.57 N 342 id 342 id Observations 1304 1304 Marginal R2 / Conditional R2 0.015 / 0.572 0.015 / 0.572 If we wish, we can output the table into a file that we can use to incorporate it into a document using the argument file = \"/path/to/output/sjPlot_table.html\". MLM Plotting Model-Implied Trajectories If we want to plot the model-implied trajectories for each individual, we can use the ggplot2 package. To plot data, we need to have it in long format. Fortunately this is the format used in the MLM model so we don”t need to do anything additional. We will plot predicted values generated from the predict() function. While we could append these values to our executive.function.long dataframe in a separate step, we will instead generate the values locally within the ggplot() function. This will save us a step and we won”t have to deal with merging the predicted values into our dataframe or having to remove those values later. Because MLMs drop NA values, our predicted values will not match up to the original dataframe unless we also drop thos NA values, so we will use the drop_na() function from tidyr. ggplot2::ggplot(tidyr::drop_na(executive.function.long), aes(x = wave + 1, y = predict(mlm.lmerTest), group = id, color = factor(id))) + geom_line() + labs(title = &quot;Canonical MLM Trajectories&quot;, x = &quot;Wave&quot;, y = &quot;Predicted DLFPC Activation&quot;) + theme(legend.position = &quot;none&quot;) We can see that there is quite a bit of individual differences both in the initial level, but also in slopes across time, with some individuals showing increases but other showing no change or even decreases across waves. A quick tip is to always use the theme(legend.position = \"none\") function in this kind of plot unless you want the plot to try to show you each individual with the color of their trajectory line. Generalized Additive Mixed Model We can move on to fitting a GAMM model. Unlike the other frameworks, we will use the feedbacklearn data with continuous age across 2 decades in this model. We could, in theory, fit the executive.function data, but that would largely be a waste of the GAMM framework”s potential for longitudinal analysis. Here we will utilize the gamm4 package for fitting GAMMs with the gamm4() function, although other options (e.g., gamm() or gam() from the mgcv package). Fortunately, the gamm4() uses syntax that we are largely familiar with from fitting the MLMs in the prior section. Here we will begin by fitting a simple smooth function for values of network modularity across age. Note here that we standardize the modularity values since the natural scale results in very small variance components, and the units of modularity are not naturally meaningful anyways. To invoke the smoothing function, we wrap the age predictor with the s() function in the formula. Note that the random effects argument resembles the nlme syntax. For now we will allow many of the defaults to kick in, but will investigate them in turn. gamm &lt;- gamm4::gamm4(scale(modularity) ~ 1 + s(age), random = ~ (1 | id), data = feedback.learning) Unlike the MLM models, the GAMM results in two sets of model results from linear and nonlinear parts of the model. To access the linear model we need to specify the mer part of the model output. summary(gamm$mer, correlation = FALSE) ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## ## REML criterion at convergence: 1838.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2280 -0.5682 -0.0059 0.5675 2.5224 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.4795 0.6925 ## Xr s(age) 1.8083 1.3447 ## Residual 0.3762 0.6134 ## Number of obs: 754, groups: id, 297; Xr, 8 ## ## Fixed effects: ## Estimate Std. Error t value ## X(Intercept) -0.009532 0.046447 -0.205 ## Xs(age)Fx1 0.341061 0.223724 1.524 We will ignore the Fixed effects: portion of the output for now because our main effect of interest is the nonlinear smooth of age and we did not include additional linear effects (we will see this more later). Focusing on the Random effects:, we can see that there is a little more person-to-person variability (Groups = id, Name = (Intercept)) than within-person variability (Groups = Residual), but they are roughly equivalent. Note that we have an “extra” random effect (Groups = Xr, Name = s(age)). Although this might lead us to believe that we have included a random within-person slope, but it is a formulation of the smooth itself as a random effect and is not terribly informative here. We could include a true random effect of age by expanding the formula in the random argument (random = ~ (1 + age | id)), but that model is not identified in this data and so we won’t. We can then take a look at the nonlinear portion of the output by summarizing the gam portion of the model. summary(gamm$gam) ## ## Family: gaussian ## Link function: identity ## ## Formula: ## scale(modularity) ~ 1 + s(age) ## ## Parametric coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.009532 0.046447 -0.205 0.837 ## ## Approximate significance of smooth terms: ## edf Ref.df F p-value ## s(age) 4.647 4.647 28.18 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## R-sq.(adj) = 0.162 ## lmer.REML = 1838.4 Scale est. = 0.37624 n = 754 As before, we will mostly ignore the Parametric coefficients: portion (although see that the (Intercept) estimate is identical; this should be of concern if this wasn’t the case). The Approximate significance of smooth terms: portion shows that we have a significant effect of age with a estimated degrees of freedom (EDF) of \\(4.65\\). The EDF give us a shrunken estimate of the smooth complexity (higher values indicate greater complexity). However, this isn’t incredibly helpful to understand the nature of the developmental effect. Instead, let’s turn to the output options and see what we can find there. GAMM Outputs Just like with MLMs, we can generate pretty tables instead of just manually typing out the console output into a word processor. We can use the tab_model() for the mer part of the output, but we need to call the gamtabs() function from the itsadug package for the gam section. itsadug::gamtabs(gamm$gam, type = &quot;html&quot;, pnames = c(&quot;Intercept&quot;), snames = c(&quot;s(Age)&quot;), caption = &quot;Modularity as a Function of Age&quot;) Modularity as a Function of Age A. parametric coefficients Estimate Std. Error t-value p-value Intercept -0.0095 0.0464 -0.2052 0.8375 B. smooth terms edf Ref.df F-value p-value s(Age) 4.6471 4.6471 28.1838 &lt; 0.0001 To visualize the results, we can call the plot.gam() function from the mgcv package (which aliases as plot() when the mgcv package is loaded). We can include the standard errors and a rug plot to show the individual age observations in our data. This can help us identify regions of the estimated trajectory that are more or less supported by the data in addition to the standard error width. mgcv::plot.gam(gamm$gam, se = TRUE, rug = TRUE, shade = TRUE, xlab = &quot;Age&quot;, ylab = &quot;Fitted Modularity Values&quot;) The resulting plot tells a rather interesting story about the developmental trajectory of modularity, with initial increases across early adolescence, a plateauing in mid-adolescence, and then slow declines into young adulthood. However, we can see there is a lot more uncertainty at the later ages (indicated by the sparsity in the hashes in the rug plot). Latent Curve Model We will now turn to the longitudinal modeling within the SEM framework, beginning with the latent curve model (or latent growth model; quantitative people aren”t the best with consistent terminology sometimes). Unlike with the mixed-effects models, we will focus on a single package, lavaan, which has become the workhorse of structural equation modeling natively in R (for running SEMs in Mplus using R commands, see the MplusAutomation package). Like with the MLM, we will fit a simple linear growth model using wave as our metric of time. However, unlike with the MLM, time will not appear as a specific variable in the model; rather we code time measurements directly into the factor loadings. LCM Syntax and Model Fitting First we will define a model syntax object that specifies the model. While we will cover the basics here, consult the lavaan website for a more complete syntax tutorial. linear.lcm &lt;- &quot; # Define the Latent Variables int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4 # Define Factor Means int ~ 1 slp ~ 1 # Define Factor (Co)Variances int ~~ int int ~~ slp slp ~~ slp # Define Indicator Residual Variances dlpfc1 ~~ dlpfc1 dlpfc2 ~~ dlpfc2 dlpfc3 ~~ dlpfc3 dlpfc4 ~~ dlpfc4 &quot; In the first section, we use the =~ operator to define the latent variables (int is the intercept and slp is the linear slope factor). The intercept factor loadings are set by pre-multiplying the individual indicators (dlpfc1-dlpfc4) by values of \\(1\\). We define the slope by pre-multiplying the indicators by linearly increasing values. Here we set the first factor loading to \\(0\\) and each subsequent loading by increasing integers. This has the effect of estimating intercept values that reflect levels of DLPFC activation at the initial observation (where time is coded \\(0\\)) and a slope effect that is expressed in per-wave units (here this relates to per-year changes). Because of defaults built into the lavaan function growth(), we could estimate the full linear LCM with just these first two lines of code (the Mplus syntax is similarly simple). However, for completeness, we will write out the remainder of the model parameters for this initial model. The next two sections define the parameters of the latent variables. Here we estimate intercepts (i.e., the fixed or average intercept and slope) using the regression operator (~) with \\(1\\) on the right hand side and (co)variances using the ~~ operator. Note that variances int ~~ int are just the covariance of a variable with itself (take a shot if that makes your head hurt a little bit). Finally, we can define the residual variances of the indicators using the same ~~ operator. We can then use the growth() function mentioned previously to fit the syntax we wrote to the executive.function data. Here we will estimate the model with Maximum Likelihood (estimator = \"ML\") and we will allow for missing data using the missing = \"FIML\" argument. Standard alternatives might include estimator = \"MLR\" for Robust Maximum Likelihood if we have non-normal continuous data, or estimator = WLSMV if we have discrete data (see the lavaan webpage for a full list of available options). In general, we will always allow for missing data, but we could change to missing = \"listwise\" if we wanted to do only complete-case analysis. This option is actually the lavaan default, so users should be cautious that this is intended and review the number of observations used in the model to confirm intended behavior. lcm &lt;- lavaan::growth(linear.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) LCM Outputs We can then summarize the model output using summary() with some optional arguments. While we will mostly output all of the available information, including fit.measures, raw (estimates) and standardized (standardize) parameter estimates, and rsquare, there might be cases where we are only interested in some subsection of the output. For instance, if we are building a sequence of models, we might only consult fit measures without viewing the parameters and associated inference tests so that our model selection isn”t driven by “peeking” at effects of interest. summary(lcm, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-12 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.229 ## Degrees of freedom 5 ## P-value (Chi-square) 0.942 ## ## Model Test Baseline Model: ## ## Test statistic 381.370 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.012 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1735.785 ## Loglikelihood unrestricted model (H1) -1735.170 ## ## Akaike (AIC) 3489.570 ## Bayesian (BIC) 3524.083 ## Sample-size adjusted Bayesian (BIC) 3495.533 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.014 ## P-value RMSEA &lt;= 0.05 0.990 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.016 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## dlpfc1 1.000 0.880 0.878 ## dlpfc2 1.000 0.880 0.813 ## dlpfc3 1.000 0.880 0.810 ## dlpfc4 1.000 0.880 0.820 ## slp =~ ## dlpfc1 0.000 0.000 0.000 ## dlpfc2 1.000 0.287 0.265 ## dlpfc3 2.000 0.574 0.528 ## dlpfc4 3.000 0.861 0.802 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.126 0.031 -4.102 0.000 -0.499 -0.499 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int 0.543 0.053 10.181 0.000 0.617 0.617 ## slp 0.121 0.021 5.705 0.000 0.420 0.420 ## .dlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int 0.775 0.086 9.009 0.000 1.000 1.000 ## slp 0.082 0.016 5.180 0.000 1.000 1.000 ## .dlpfc1 0.231 0.063 3.675 0.000 0.231 0.229 ## .dlpfc2 0.568 0.055 10.261 0.000 0.568 0.484 ## .dlpfc3 0.582 0.058 10.117 0.000 0.582 0.493 ## .dlpfc4 0.393 0.074 5.308 0.000 0.393 0.341 ## ## R-Square: ## Estimate ## dlpfc1 0.771 ## dlpfc2 0.516 ## dlpfc3 0.507 ## dlpfc4 0.659 One nice thing about fitting our model to the raw data instead of standardizing beforehand is that with the standardize = TRUE argument, we get 3 sets of parameter estimates: the raw scale estimates (under Estimates), the estimates when the latent variables are standardized but the indicators remain in the raw scale (under Std.lv), and the fully standardized solution (under Std.all). In the same spirit of maximizing the information from the model, we can actually re-fit the model using estimator = \"MLR\". Here we will only output the fit.measures to see how the robust estimator changes our model fit information. lcm &lt;- lavaan::growth(linear.lcm, data = executive.function, estimator = &quot;MLR&quot;, missing = &quot;FIML&quot;) summary(lcm, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## Standard Robust ## Test Statistic 1.229 1.139 ## Degrees of freedom 5 5 ## P-value (Chi-square) 0.942 0.951 ## Scaling correction factor 1.079 ## Yuan-Bentler correction (Mplus variant) ## ## Model Test Baseline Model: ## ## Test statistic 381.370 305.720 ## Degrees of freedom 6 6 ## P-value 0.000 0.000 ## Scaling correction factor 1.247 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 1.000 ## Tucker-Lewis Index (TLI) 1.012 1.015 ## ## Robust Comparative Fit Index (CFI) 1.000 ## Robust Tucker-Lewis Index (TLI) 1.013 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1735.785 -1735.785 ## Scaling correction factor 1.135 ## for the MLR correction ## Loglikelihood unrestricted model (H1) -1735.170 -1735.170 ## Scaling correction factor 1.115 ## for the MLR correction ## ## Akaike (AIC) 3489.570 3489.570 ## Bayesian (BIC) 3524.083 3524.083 ## Sample-size adjusted Bayesian (BIC) 3495.533 3495.533 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 0.000 ## 90 Percent confidence interval - lower 0.000 0.000 ## 90 Percent confidence interval - upper 0.014 0.000 ## P-value RMSEA &lt;= 0.05 0.990 0.994 ## ## Robust RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.016 0.016 We can see that we get a new column of robust fit statistics to accompany the standard measures which correct for the non-normality in our data. In this case, our data are not too non-normal and so there is little difference. However, this will not always be the case. To vastly over-simplify, we are looking to see if our Model Test User Model: test statistic is non-significant. However, be aware that this test is over-powered and will often be significant in large samples, even in a well fitting model. We also tend to look for CFI/TLI \\(&gt; 0.95\\), RMSEA \\(&lt; 0.05\\), and SRMR \\(&lt; 0.08\\) to indicate an excellent model fit. While these cutoff values are somewhat arbitrary, they can serve as a rough huristic, and the linear LCM more than satisfies each of these criteria. For more discussion of fit indices, consult the resources outlined in the main text. We can now jump back and orient to the parameter estimate output. summary(lcm, fit.measures = FALSE, estimates= TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-12 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## Standard Robust ## Test Statistic 1.229 1.139 ## Degrees of freedom 5 5 ## P-value (Chi-square) 0.942 0.951 ## Scaling correction factor 1.079 ## Yuan-Bentler correction (Mplus variant) ## ## Parameter Estimates: ## ## Standard errors Sandwich ## Information bread Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## dlpfc1 1.000 0.880 0.878 ## dlpfc2 1.000 0.880 0.813 ## dlpfc3 1.000 0.880 0.810 ## dlpfc4 1.000 0.880 0.820 ## slp =~ ## dlpfc1 0.000 0.000 0.000 ## dlpfc2 1.000 0.287 0.265 ## dlpfc3 2.000 0.574 0.528 ## dlpfc4 3.000 0.861 0.802 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.126 0.037 -3.406 0.001 -0.499 -0.499 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int 0.543 0.053 10.180 0.000 0.617 0.617 ## slp 0.121 0.021 5.704 0.000 0.420 0.420 ## .dlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int 0.775 0.093 8.335 0.000 1.000 1.000 ## slp 0.082 0.017 4.761 0.000 1.000 1.000 ## .dlpfc1 0.231 0.075 3.060 0.002 0.231 0.229 ## .dlpfc2 0.568 0.057 9.884 0.000 0.568 0.484 ## .dlpfc3 0.582 0.062 9.332 0.000 0.582 0.493 ## .dlpfc4 0.393 0.076 5.138 0.000 0.393 0.341 ## ## R-Square: ## Estimate ## dlpfc1 0.771 ## dlpfc2 0.516 ## dlpfc3 0.507 ## dlpfc4 0.659 The first section of parameters Latent Variables: is of little interest to us for now since we pre-determined these factor loadings as a part of our model (but maybe check that they are the values you expect) and there are therefore no inferential tests on these parameters. The Covariances: section shows us the covariance (and correlation if we asked for standardized results) between the intercept and slope. Here we can see that the correlation is strong and negative (\\(r = -0.499\\)) suggesting that those with the lowest initial levels of DLPFC activation tend to show the strongest increases in activation over time. The Intercepts: section shows us the means of the latent factors and would show the conditional (denoted by a . before a variable name) intercepts of the indicators, but we do not estimate these values in a growth model (rather the means are reproduced by the factor means through the loadings, \\(\\mathbf{\\alpha\\Lambda}\\)). Here we can see that the average activation at the initial timepoint is \\(0.543\\) and the average rate of change is \\(0.121\\) units per wave, both of which are significant. Next we have the factor variances and the indicator residual (again denoted with .) variances in the Variances: section. The variances of the intercept and slope are significant suggesting there are meaningful individual differences in initial level and rate of change over time. The residual variances comprise the variance of the indicator not accounted for by the latent variables in the model. Finally, we have the R-Square: section where the proportion of variance explained in each of the endogenous variables (here just the indicators but this could contain other endogenous observed or latent variables in other models). Conveniently, this is simply \\(1\\) minus the standardized residual variance for each item. We can output these parameters in a slightly more compact format using the tidy() function from the broom package and pass it to the kable() function from the kableExtra package to output a table in the \"html\" format. If we were writing a manuscript, we might alternatively wish to output the rmarkdown in PDF form and use the format = \"latex\" argument. broom::tidy(lcm) %&gt;% select(-op, -std.nox) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Linear Latent Curve Model**&quot;, align = &quot;c&quot;, col.names=c(&quot;Parameter&quot;, &quot;Estimate&quot;, &quot;SE&quot;, &quot;Statistic&quot;, &quot;*p*-value&quot;, &quot;Std.LV&quot;, &quot;Std.All&quot;), row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Linear Latent Curve Model Parameter Estimate SE Statistic p-value Std.LV Std.All int =~ dlpfc1 1.000 0.000 NA NA 0.880 0.878 int =~ dlpfc2 1.000 0.000 NA NA 0.880 0.813 int =~ dlpfc3 1.000 0.000 NA NA 0.880 0.810 int =~ dlpfc4 1.000 0.000 NA NA 0.880 0.820 slp =~ dlpfc1 0.000 0.000 NA NA 0.000 0.000 slp =~ dlpfc2 1.000 0.000 NA NA 0.287 0.265 slp =~ dlpfc3 2.000 0.000 NA NA 0.574 0.528 slp =~ dlpfc4 3.000 0.000 NA NA 0.861 0.802 int ~1 0.543 0.053 10.180 0.000 0.617 0.617 slp ~1 0.121 0.021 5.704 0.000 0.420 0.420 int ~~ int 0.775 0.093 8.335 0.000 1.000 1.000 int ~~ slp -0.126 0.037 -3.406 0.001 -0.499 -0.499 slp ~~ slp 0.082 0.017 4.761 0.000 1.000 1.000 dlpfc1 ~~ dlpfc1 0.231 0.075 3.060 0.002 0.231 0.229 dlpfc2 ~~ dlpfc2 0.568 0.057 9.884 0.000 0.568 0.484 dlpfc3 ~~ dlpfc3 0.582 0.062 9.332 0.000 0.582 0.493 dlpfc4 ~~ dlpfc4 0.393 0.076 5.138 0.000 0.393 0.341 dlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 LCM Path Diagrams We might also wish to generate a diagram visualization of the LCM model, either for model checking or for presenting results. We can use the semPaths() function from the semPlot package to do just that. Here we will plot the model results including the intercepts and with black paths. The what argument we will set to \"est\" to scale the size of the paths to the parameter estimate. semPlot::semPaths(lcm, what = &quot;est&quot;, intercepts = TRUE, edge.color = &quot;black&quot;) However, we can see that this path scaling is a little unfortunate because the integer factor loadings sort of swamp out the parameters we are primarily interested in. Instead we can change this argument to what = \"paths\" to have equally-sized paths, and then label those paths with the parameters using whatLabels = \"est\" (or whatLabels = \"std\" for standardized estimates). semPlot::semPaths(lcm, what = &quot;paths&quot;, whatLabels = &quot;est&quot;, intercepts = TRUE, edge.color = &quot;black&quot;) Much better… By standard convention, latent variables are represented as circles, observed variables as squares, regression paths as straight single-headed arrows, and (co)variances as curved double-headed arrows. Parameters that are set to particular values rather than estimated (e.g., factor loadings here and indicator intercepts) are displayed with dashed lines. LCM Plotting Model-Implied Trajectories Finally, like with the MLM, we might want to plot model-implied individual trajectories of DLPFC activation. We have to do a little data management song and dance to get the predicted values and then convert to long format (which we do within the ggplot() function directly instead of creating a new dataframe to store in memory), but the results are the same as before. ggplot2::ggplot(data.frame(id=lcm@Data@case.idx[[1]], lavPredict(lcm,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;dlpfc&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% dplyr::mutate(wave = as.numeric(wave)), aes(x = wave, y = dlpfc, group = id, color = factor(id))) + geom_line() + labs(title = &quot;Canonical LCM Trajectories&quot;, x = &quot;Wave&quot;, y = &quot;Predicted DLFPC Activation&quot;) + theme(legend.position = &quot;none&quot;) Latent Change Score Model Finally, we can turn the LCSM parameterization of the linear growth model. Like the LCM, the time predictor will not appear in our model syntax, but even more strangely (at first), neither will any values of time. Rather we will sum across latent change factors to estimate the slope across time. Linear LCSM The main complication of the LCSM syntax relative to what we saw with the LCM is that we need to generate phantom variables from the indicators and then relate them with fixed path coefficients to the latent change factors. linear.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (delta) delta21 =~ 1*pdlpfc2; delta21 ~~ 0*delta21 delta32 =~ 1*pdlpfc3; delta32 ~~ 0*delta32 delta43 =~ 1*pdlpfc4; delta43 ~~ 0*delta43 # Define Intercept and Slope int =~ 1*pdlpfc1 slp =~ 1*delta21 + 1*delta32 + 1*delta43 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &quot; In the first section, we define the phantoms (e.g., pdlpfc1) with four commands (separated by ; for compactness): 1) define the phantom by the indicator with a factor loading of \\(1\\) (pdlpfc1 =~ 1*dlpfc1), 2) set the intercept of the indicator to \\(0\\) (dlpfc1 ~ 0), 3) estimate the residual variance of the indicator (dlpfc1 ~~ dlpfc1), and set the variance of the phatom to \\(0\\) (pdlpfc1 ~~ 0*pdlpfc1). This, in effect, pushes the characteristics we need from the indicator variable to the phantom, which facilitates the model. In the nexttwo sections, we set regressions of \\(\\gamma = 1\\) between adjacent phantoms variables, define the latent change factor by the phantoms after the initial time point (e.g., delta21 =~ 1*pdlpfc2), and set the variance of the latent change factor to zero. This may not be apparent at first blush, but the regressions of \\(1\\) between adjacent timepoints essentially push the differences in the outcome between observations up into the latent change factors (i.e., what is left over after residualizing out the prior observation). Finally, we have the final definition of the intercept and slope factors. However, unlike the LCM, the intercept factor is only estimated from the initial phantom variable. The slope factor is defined from the latent change factors, but instead of linear factor loadings, all of these loadings are \\(1\\) (this sums across the latent changes to give the overall linear trajectory). Like before, we will take this syntax object and use it to fit the model we specify. Unlike the LCM, we will use the sem() function instead because the growth() defaults won”t serve our purposes with the LCSM. Otherwise, the arguments we will invoke will be the same. While we display it for completeness, we will not spend much time on this output as it exactly recreates the estimates for the LCM we already walked through (we promise; or scroll back up and check). We generate a path diagram for this model as well, but do not display parameter estimates to reduce clutter. lcsm.linear &lt;- sem(linear.lcsm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcsm.linear, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-12 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.229 ## Degrees of freedom 5 ## P-value (Chi-square) 0.942 ## ## Model Test Baseline Model: ## ## Test statistic 381.370 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 1.000 ## Tucker-Lewis Index (TLI) 1.012 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -1735.785 ## Loglikelihood unrestricted model (H1) -1735.170 ## ## Akaike (AIC) 3489.570 ## Bayesian (BIC) 3524.083 ## Sample-size adjusted Bayesian (BIC) 3495.533 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.000 ## 90 Percent confidence interval - lower 0.000 ## 90 Percent confidence interval - upper 0.014 ## P-value RMSEA &lt;= 0.05 0.990 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.016 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pdlpfc1 =~ ## dlpfc1 1.000 0.880 0.878 ## pdlpfc2 =~ ## dlpfc2 1.000 0.778 0.718 ## pdlpfc3 =~ ## dlpfc3 1.000 0.775 0.712 ## pdlpfc4 =~ ## dlpfc4 1.000 0.872 0.812 ## delta21 =~ ## pdlpfc2 1.000 0.369 0.369 ## delta32 =~ ## pdlpfc3 1.000 0.370 0.370 ## delta43 =~ ## pdlpfc4 1.000 0.329 0.329 ## int =~ ## pdlpfc1 1.000 1.000 1.000 ## slp =~ ## delta21 1.000 1.000 1.000 ## delta32 1.000 1.000 1.000 ## delta43 1.000 1.000 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pdlpfc2 ~ ## pdlpfc1 1.000 1.132 1.132 ## pdlpfc3 ~ ## pdlpfc2 1.000 1.004 1.004 ## pdlpfc4 ~ ## pdlpfc3 1.000 0.889 0.889 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.126 0.031 -4.102 0.000 -0.499 -0.499 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.000 0.000 0.000 ## int 0.543 0.053 10.181 0.000 0.617 0.617 ## slp 0.121 0.021 5.705 0.000 0.420 0.420 ## .pdlpfc1 0.000 0.000 0.000 ## .pdlpfc2 0.000 0.000 0.000 ## .pdlpfc3 0.000 0.000 0.000 ## .pdlpfc4 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .dlpfc1 0.231 0.063 3.675 0.000 0.231 0.229 ## .pdlpfc1 0.000 0.000 0.000 ## .dlpfc2 0.568 0.055 10.261 0.000 0.568 0.484 ## .pdlpfc2 0.000 0.000 0.000 ## .dlpfc3 0.582 0.058 10.117 0.000 0.582 0.493 ## .pdlpfc3 0.000 0.000 0.000 ## .dlpfc4 0.393 0.074 5.308 0.000 0.393 0.341 ## .pdlpfc4 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## slp 0.082 0.016 5.180 0.000 1.000 1.000 ## int 0.775 0.086 9.009 0.000 1.000 1.000 ## ## R-Square: ## Estimate ## dlpfc1 0.771 ## pdlpfc1 1.000 ## dlpfc2 0.516 ## pdlpfc2 1.000 ## dlpfc3 0.507 ## pdlpfc3 1.000 ## dlpfc4 0.659 ## pdlpfc4 1.000 ## delta21 1.000 ## delta32 1.000 ## delta43 1.000 broom::tidy(lcsm.linear) %&gt;% arrange(op) %&gt;% select(-op, -std.nox) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Linear Latent Change Score Model**&quot;, align = &quot;c&quot;, col.names=c(&quot;Parameter&quot;, &quot;Estimate&quot;, &quot;SE&quot;, &quot;Statistic&quot;, &quot;*p*-value&quot;, &quot;Std.LV&quot;, &quot;Std.All&quot;), row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Linear Latent Change Score Model Parameter Estimate SE Statistic p-value Std.LV Std.All pdlpfc1 =~ dlpfc1 1.000 0.000 NA NA 0.880 0.878 pdlpfc2 =~ dlpfc2 1.000 0.000 NA NA 0.778 0.718 pdlpfc3 =~ dlpfc3 1.000 0.000 NA NA 0.775 0.712 pdlpfc4 =~ dlpfc4 1.000 0.000 NA NA 0.872 0.812 delta21 =~ pdlpfc2 1.000 0.000 NA NA 0.369 0.369 delta32 =~ pdlpfc3 1.000 0.000 NA NA 0.370 0.370 delta43 =~ pdlpfc4 1.000 0.000 NA NA 0.329 0.329 int =~ pdlpfc1 1.000 0.000 NA NA 1.000 1.000 slp =~ delta21 1.000 0.000 NA NA 1.000 1.000 slp =~ delta32 1.000 0.000 NA NA 1.000 1.000 slp =~ delta43 1.000 0.000 NA NA 1.000 1.000 pdlpfc2 ~ pdlpfc1 1.000 0.000 NA NA 1.132 1.132 pdlpfc3 ~ pdlpfc2 1.000 0.000 NA NA 1.004 1.004 pdlpfc4 ~ pdlpfc3 1.000 0.000 NA NA 0.889 0.889 dlpfc1 ~~ dlpfc1 0.231 0.063 3.675 0 0.231 0.229 pdlpfc1 ~~ pdlpfc1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~~ dlpfc2 0.568 0.055 10.261 0 0.568 0.484 pdlpfc2 ~~ pdlpfc2 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~~ dlpfc3 0.582 0.058 10.117 0 0.582 0.493 pdlpfc3 ~~ pdlpfc3 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~~ dlpfc4 0.393 0.074 5.308 0 0.393 0.341 pdlpfc4 ~~ pdlpfc4 0.000 0.000 NA NA 0.000 0.000 delta21 ~~ delta21 0.000 0.000 NA NA 0.000 0.000 delta32 ~~ delta32 0.000 0.000 NA NA 0.000 0.000 delta43 ~~ delta43 0.000 0.000 NA NA 0.000 0.000 int ~~ slp -0.126 0.031 -4.102 0 -0.499 -0.499 slp ~~ slp 0.082 0.016 5.180 0 1.000 1.000 int ~~ int 0.775 0.086 9.009 0 1.000 1.000 dlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 int ~1 0.543 0.053 10.181 0 0.617 0.617 slp ~1 0.121 0.021 5.705 0 0.420 0.420 pdlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 delta21 ~1 0.000 0.000 NA NA 0.000 0.000 delta32 ~1 0.000 0.000 NA NA 0.000 0.000 delta43 ~1 0.000 0.000 NA NA 0.000 0.000 semPlot::semPaths(lcsm.linear, layout = &quot;tree2&quot;, intercepts = FALSE, edge.color = &quot;black&quot;) Linear LCSM with Proportional Change To a first approximation, the model above is an overly complicated method for estimating the same model we could do with two lines in the LCM. However, this parameterization allows us to include effects that are not possible to include in the LCM. To model proportional change, we regression the latent change factor on the prior timepoint phantom variable (delta21 ~ pdlpfc1). This effect tests how change between timepoints depends on prior level on the outcome of interest, and can be used to model interesting non-linearities (especially exponential trends). While not strictly necessary, it is common practice to create an equality constraint across all proportional effects. Here we accomplish this constraint by pre-multiplying all of these regressions with the same label (beta). The rest of the syntax remains the same as above. proportional.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (delta) delta21 =~ 1*pdlpfc2; delta21 ~~ 0*delta21 delta32 =~ 1*pdlpfc3; delta32 ~~ 0*delta32 delta43 =~ 1*pdlpfc4; delta43 ~~ 0*delta43 # Define Proportional Change Regressions (beta = equality constraint) delta21 ~ beta*pdlpfc1 delta32 ~ beta*pdlpfc2 delta43 ~ beta*pdlpfc3 # Define Intercept and Slope int =~ 1*pdlpfc1 slp =~ 1*delta21 + 1*delta32 + 1*delta43 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &quot; lcsm.proportional &lt;- sem(proportional.lcsm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) We will just focus here on the parameter estimate for the proportional effect (beta), which is negative, but non-significant (\\(\\gamma = -0.090, SE = 0.276, p = 0.745\\)). If we were to interpret this parameter, we would say that those with higher levels at prior timepoints tend to show less positive changes between adjacent timepoints (we would need to interpret these in light of the fixed effects to be certain if this is smaller increases or greater decreases). Interestingly, note that this is similar in kind to the factor covariance we interpreted in the LCM. If we examine that same parameter here, we can see that the correlation has been attenuated (\\(r = -0.295\\)) and is now non-significant. Indeed all the parameter estimates have now changed because we have introduced this new proportional effect. summary(lcsm.proportional, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 32 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## Number of equality constraints 2 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.132 ## Degrees of freedom 4 ## P-value (Chi-square) 0.889 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## pdlpfc1 =~ ## dlpfc1 1.000 ## pdlpfc2 =~ ## dlpfc2 1.000 ## pdlpfc3 =~ ## dlpfc3 1.000 ## pdlpfc4 =~ ## dlpfc4 1.000 ## delta21 =~ ## pdlpfc2 1.000 ## delta32 =~ ## pdlpfc3 1.000 ## delta43 =~ ## pdlpfc4 1.000 ## int =~ ## pdlpfc1 1.000 ## slp =~ ## delta21 1.000 ## delta32 1.000 ## delta43 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## pdlpfc2 ~ ## pdlpfc1 1.000 ## pdlpfc3 ~ ## pdlpfc2 1.000 ## pdlpfc4 ~ ## pdlpfc3 1.000 ## delta21 ~ ## pdlpfc1 (beta) -0.090 0.276 -0.325 0.745 ## delta32 ~ ## pdlpfc2 (beta) -0.090 0.276 -0.325 0.745 ## delta43 ~ ## pdlpfc3 (beta) -0.090 0.276 -0.325 0.745 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.074 0.162 -0.457 0.647 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int 0.540 0.054 9.994 0.000 ## slp 0.179 0.183 0.981 0.326 ## .pdlpfc1 0.000 ## .pdlpfc2 0.000 ## .pdlpfc3 0.000 ## .pdlpfc4 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.208 0.102 2.043 0.041 ## .pdlpfc1 0.000 ## .dlpfc2 0.573 0.058 9.820 0.000 ## .pdlpfc2 0.000 ## .dlpfc3 0.577 0.060 9.570 0.000 ## .pdlpfc3 0.000 ## .dlpfc4 0.413 0.095 4.358 0.000 ## .pdlpfc4 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## slp 0.079 0.016 4.970 0.000 ## int 0.796 0.115 6.925 0.000 Like before, we can generate tables, a path diagram, and plot model-implied individual trajectories. Note that the proportional model does not generate noticeably non-linear implied trajectories due to the very weak proportional effect. broom::tidy(lcsm.proportional) %&gt;% arrange(op) %&gt;% select(-op, -std.nox) %&gt;% kableExtra::kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Linear Latent Change Score Model with Proportional Change**&quot;, align = &quot;c&quot;, col.names=c(&quot;Parameter&quot;, &quot;Label&quot;, &quot;Estimate&quot;, &quot;SE&quot;, &quot;Statistic&quot;, &quot;*p*-value&quot;, &quot;Std.LV&quot;, &quot;Std.All&quot;), row.names = FALSE) %&gt;% kableExtra::row_spec(row = 0, align = &quot;c&quot;) Linear Latent Change Score Model with Proportional Change Parameter Label Estimate SE Statistic p-value Std.LV Std.All pdlpfc1 =~ dlpfc1 1.000 0.000 NA NA 0.892 0.891 pdlpfc2 =~ dlpfc2 1.000 0.000 NA NA 0.777 0.716 pdlpfc3 =~ dlpfc3 1.000 0.000 NA NA 0.776 0.714 pdlpfc4 =~ dlpfc4 1.000 0.000 NA NA 0.861 0.802 delta21 =~ pdlpfc2 1.000 0.000 NA NA 0.405 0.405 delta32 =~ pdlpfc3 1.000 0.000 NA NA 0.370 0.370 delta43 =~ pdlpfc4 1.000 0.000 NA NA 0.303 0.303 int =~ pdlpfc1 1.000 0.000 NA NA 1.000 1.000 slp =~ delta21 1.000 0.000 NA NA 0.895 0.895 slp =~ delta32 1.000 0.000 NA NA 0.983 0.983 slp =~ delta43 1.000 0.000 NA NA 1.080 1.080 pdlpfc2 ~ pdlpfc1 1.000 0.000 NA NA 1.148 1.148 pdlpfc3 ~ pdlpfc2 1.000 0.000 NA NA 1.002 1.002 pdlpfc4 ~ pdlpfc3 1.000 0.000 NA NA 0.900 0.900 delta21 ~ pdlpfc1 beta -0.090 0.276 -0.325 0.745 -0.254 -0.254 delta32 ~ pdlpfc2 beta -0.090 0.276 -0.325 0.745 -0.243 -0.243 delta43 ~ pdlpfc3 beta -0.090 0.276 -0.325 0.745 -0.267 -0.267 dlpfc1 ~~ dlpfc1 0.208 0.102 2.043 0.041 0.208 0.207 pdlpfc1 ~~ pdlpfc1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~~ dlpfc2 0.573 0.058 9.820 0.000 0.573 0.487 pdlpfc2 ~~ pdlpfc2 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~~ dlpfc3 0.577 0.060 9.570 0.000 0.577 0.490 pdlpfc3 ~~ pdlpfc3 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~~ dlpfc4 0.413 0.095 4.358 0.000 0.413 0.357 pdlpfc4 ~~ pdlpfc4 0.000 0.000 NA NA 0.000 0.000 delta21 ~~ delta21 0.000 0.000 NA NA 0.000 0.000 delta32 ~~ delta32 0.000 0.000 NA NA 0.000 0.000 delta43 ~~ delta43 0.000 0.000 NA NA 0.000 0.000 int ~~ slp -0.074 0.162 -0.457 0.647 -0.295 -0.295 slp ~~ slp 0.079 0.016 4.970 0.000 1.000 1.000 int ~~ int 0.796 0.115 6.925 0.000 1.000 1.000 dlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 dlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 int ~1 0.540 0.054 9.994 0.000 0.605 0.605 slp ~1 0.179 0.183 0.981 0.326 0.637 0.637 pdlpfc1 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc2 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc3 ~1 0.000 0.000 NA NA 0.000 0.000 pdlpfc4 ~1 0.000 0.000 NA NA 0.000 0.000 delta21 ~1 0.000 0.000 NA NA 0.000 0.000 delta32 ~1 0.000 0.000 NA NA 0.000 0.000 delta43 ~1 0.000 0.000 NA NA 0.000 0.000 semPlot::semPaths(lcsm.proportional, layout = &quot;tree2&quot;, intercepts = FALSE, edge.color = &quot;black&quot;) ggplot2::ggplot(data.frame(id=lcsm.proportional@Data@case.idx[[1]], lavPredict(lcsm.proportional,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;dlpfc&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% dplyr::mutate(wave = as.numeric(wave)), aes(x = wave, y = dlpfc, group = id, color = factor(id))) + geom_line() + labs(title = &quot;Canonical Proportional LCSM Trajectories&quot;, x = &quot;Wave&quot;, y = &quot;Predicted DLFPC Activation&quot;) + theme(legend.position = &quot;none&quot;) "],["03-time.html", "Time Structure Assessment Schedules Time Coding Additional Considerations", " Time Structure Now that we have covered the basic forms of each of the four modeling frameworks, we can start thinking more deeply about how to include time in our longitudinal models. We will begin by visualizing different kinds of assessment schedules and how our models might change depending on the structure of our observations. We will read in subsets of datasets that appear elsewhere in this primer codebook that follow each of three exemplar assessment types. The single.cohort and accelerated datasets were drawn from the executive.function and feedback.learning datasets we saw in the canonical models chapter. The multiple.cohort dataset has been drawn from the adversity dataset (for details, see the Datasets chapter), which measures white matter development across 8 waves. These data contain fractional anisotropy (FA) measures derived from the forceps minor (fmin), a white matter tract that spans the hemispheres of the medial prefrontal cortex. We will see this dataset again when we consider predictors in the Covariates chapter. single.cohort &lt;- read.csv(&quot;data/single-cohort.csv&quot;, header = TRUE) multiple.cohort &lt;- read.csv(&quot;data/multiple-cohort.csv&quot;, header = TRUE) accelerated &lt;- read.csv(&quot;data/accelerated.csv&quot;, header = TRUE) Assessment Schedules Single Cohort Data As we cover in the main text, single cohort studies are by far the most common in longitudinal modeling. Below we can plot the assessment schedule for the canonical models we worked with in the last chapter. To declutter the plot, we have selected 50 individuals from the larger dataset and ordered them by their age at the first assessment. set.seed(12345) ggplot(single.cohort %&gt;% pivot_longer(cols=starts_with(&quot;age&quot;), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Age&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;) + theme(legend.position = &quot;top&quot;) We can see that there is some noise in the assessment schedule, as individuals are not observed at exactly intervals, however, we can see clear separation in ages between each wave. Because we cover this data extensively in the Canonical Models chapter, we will not show model fits here. However, we should note that because of the structure of this data, age and wave of assessment are highly collinear (and are more so the better job we do at observing individuals at regular intervals). This will impact our considerations about time later. Multiple Cohort Data A slightly more complex assessment schedule design is the multiple cohort design. In these designs, we have multiple, discrete ages at the first assessment which vary across cohorts. Here we can plot our multiple.cohort data, which is organized into three cohorts, beginning at ages \\(4\\), \\(5\\), and \\(6\\). While at later ages the cohorts mix somewhat in terms of ages sampled, no individual is observed at consecutive ages. This highlights a key advantage of the multiple cohort design; they can often provide coverage of a wider developmental window without requiring additional subjects or waves of assessment using principles of planned missingness. ggplot(multiple.cohort %&gt;% pivot_longer(cols=starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(....)(.+)&quot;) %&gt;% drop_na(fmin) %&gt;% mutate(age = as.numeric(age)), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(age), shape = factor(cohort)), size=2) + labs(x = &quot;Age&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) + guides(color = &quot;none&quot;) Here we will demonstrate how one might model this type of data using the linear latent curve model for simplicity; however, we could implement this model in any of the 4 modeling frameworks we discussed. To preface the model results, the values of the fmin outcome were normalized to the first age assessed (fmin4) because of the relatively small natural scale of FA values. We have also read in the full adversity data file due to convergence issues with the subsample in multiple.cohort. mc.wm.model &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 &quot; mc.wm &lt;- growth(mc.wm.model, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) The real leverage that FIML gives us is apparent using this model. We can measure across \\(8\\) ages despite no individual having more than \\(4\\) observations. We can see the abbreviated results below. summary(mc.wm, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 33 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 42.960 ## Degrees of freedom 31 ## P-value (Chi-square) 0.075 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fmin4 1.000 0.656 0.638 ## fmin5 1.000 0.656 0.685 ## fmin6 1.000 0.656 0.623 ## fmin7 1.000 0.656 0.582 ## fmin8 1.000 0.656 0.531 ## fmin9 1.000 0.656 0.535 ## fmin10 1.000 0.656 0.542 ## fmin11 1.000 0.656 0.480 ## slp =~ ## fmin4 0.000 0.000 0.000 ## fmin5 1.000 0.125 0.130 ## fmin6 2.000 0.249 0.237 ## fmin7 3.000 0.374 0.331 ## fmin8 4.000 0.499 0.404 ## fmin9 5.000 0.623 0.508 ## fmin10 6.000 0.748 0.618 ## fmin11 7.000 0.872 0.638 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 0.006 0.023 0.276 0.783 0.077 0.077 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## int 0.026 0.053 0.485 0.628 0.039 0.039 ## slp 0.049 0.012 4.020 0.000 0.393 0.393 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.627 0.141 4.440 0.000 0.627 0.593 ## .fmin5 0.458 0.102 4.475 0.000 0.458 0.500 ## .fmin6 0.591 0.105 5.646 0.000 0.591 0.533 ## .fmin7 0.664 0.091 7.315 0.000 0.664 0.522 ## .fmin8 0.796 0.125 6.389 0.000 0.796 0.522 ## .fmin9 0.621 0.095 6.565 0.000 0.621 0.413 ## .fmin10 0.398 0.116 3.438 0.001 0.398 0.272 ## .fmin11 0.589 0.125 4.694 0.000 0.589 0.315 ## int 0.431 0.117 3.690 0.000 1.000 1.000 ## slp 0.016 0.006 2.685 0.007 1.000 1.000 With this model, we will be warned that coverage for certain pairwise combinations is \\(&lt; 10\\%\\), which just reflects the fact that almost no individuals gave data at adjacent ages. We could inspect the model coverage using the lavInspect() function using the argument what = \"coverage\". Note the values at or near \\(0\\) on the 1-off diagonal (e.g., fmin5 and fmin4). lavInspect(mc.wm, what = &quot;coverage&quot;) ## fmin4 fmin5 fmin6 fmin7 fmin8 fmin9 fmin10 fmin11 ## fmin4 0.299 ## fmin5 0.000 0.420 ## fmin6 0.078 0.000 0.359 ## fmin7 0.209 0.264 0.000 0.472 ## fmin8 0.030 0.123 0.239 0.008 0.372 ## fmin9 0.196 0.204 0.070 0.342 0.003 0.430 ## fmin10 0.070 0.113 0.198 0.040 0.244 0.035 0.334 ## fmin11 0.151 0.239 0.055 0.342 0.040 0.359 0.030 0.430 Finally, we can generate a path diagram, highlighting that the intercept and slope are estimated from all ages even though no individual is measured across all of those ages. semPaths(mc.wm, intercepts = TRUE, edge.color = &quot;black&quot;) Accelerated Design The most complex assessment schedule is the accelerated longitudinal design, where no two individual are assessed at the same maturational state (usually age). While it isn’t strictly necessary that we have some smooth continuum of starting ages, accelerated longitudinal studies most often follow this approach. We can see an example below. set.seed(12345) ggplot(accelerated %&gt;% group_by(id) %&gt;% filter(length(unique(wave)) == 3) %&gt;% ungroup() %&gt;% filter(id %in% sample(id, 100)), aes(x = age, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Age&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) Unlike the single or multiple-cohort data, where we have discrete timepoints of observations, here we have as many as three unique timepoints per person since individuals are unlikely to be the exact same age. While it is possible to fit this type of model using definition variables in an SEM (see the Mplus code for the TSCORE option), it is far more common to fit these assessment schedules with mixed effects models, where we can include precise age into the model as a continuous predictor. We can use the multilevel model to fit a quadratic growth curve to this data. Note that the linear and quadratic effects are fixed effects that are pooled across individuals, and that only the random intercept is included. We could include additional random effects if the data support them, although we would need sufficient numbers of observations within-person to do so. accel &lt;- lmer(scale(modularity) ~ 1 + age + I(age^2) + (1 | id), na.action = na.omit, REML = TRUE, data = accelerated) We can see the results of this model below. summary(accel) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: scale(modularity) ~ 1 + age + I(age^2) + (1 | id) ## Data: accelerated ## ## REML criterion at convergence: 642.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.02380 -0.55867 -0.00133 0.56810 2.43080 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.4079 0.6386 ## Residual 0.5131 0.7163 ## Number of obs: 243, groups: id, 81 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -4.229027 0.928266 239.194448 -4.556 8.32e-06 *** ## age 0.460537 0.105741 239.506334 4.355 1.97e-05 *** ## I(age^2) -0.011828 0.002949 238.656609 -4.011 8.10e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) age ## age -0.982 ## I(age^2) 0.940 -0.986 If we want to get the overall fixed effects trend, rather than individual trajectories (as we did in the Canonical models), we can use the ggpredict() function from the ggeffects package to generate predicted values of the outcome at specific values of the predictor. This package is especially useful for generating ggplot-compatible dataframes when plotting interactions, but we can still use it for main effects (although a polynomial is a special form of an interaction). We can specify the levels of the predictor within the brackets ([]) or set them to all as we will here to get the full range of ages in our plot. We can then pass this dataframe to ggplot and plot the effect of age with confidence bands shaded. accel.effects = ggeffects::ggpredict(accel, terms=&#39;age [all]&#39;) ggplot(data=accel.effects, aes(x=x,y=predicted)) + geom_line() + geom_ribbon(aes(ymin=conf.low, ymax=conf.high), alpha=.2) + labs(x=&#39;Age&#39;, y = &#39;Predicted Learning Rate&#39;) We can see quite a pronounced inverted-U quadratic effect here, with a peak around twenty. While we have this plot here, we might wish to know if the simple linear slope is significant at various points along the curve (i.e., is modularity significantly increasing or decreasing at a given age). To do so, we can use the simple_slopes() function from the interactions package. One quirk is that this function does not recognize a polynomial term like the one we have here. Instead, the function looks for separate variable labels. Well fortunately we can just trick it into working as we would like by duplicating the age variable under a new name (age_temp). We can then re-estimate our model with the interaction of age and our temporary age variable included (i.e., age:age_temp). accelerated &lt;- accelerated %&gt;% mutate(age_temp = age) probe.accel &lt;- lmer(scale(modularity) ~ 1 + age + age:age_temp + (1 | id), na.action = na.omit, REML = TRUE, data = accelerated) We can then pass the new model object to the simple_slopes() function with age as our focal predictor and age_temp as the moderator (of course in this case, it doesn’t matter which variable we put in which position). We can toggle the jnplot argument to TRUE in order to generate a plot of the linear effect of age as a function of age. This plot will show us where within the quadratic curve, we have significant increases or decreases, and where the linear effect is not significant. interactions::sim_slopes(probe.accel, data = accelerated, pred = age, modx = age_temp, jnplot = TRUE, jnalpha = 0.05) ## JOHNSON-NEYMAN INTERVAL ## ## When age_temp is OUTSIDE the interval [18.79, 27.02], the slope of age is p &lt; .05. ## ## Note: The range of observed values of age_temp is [8.01, 28.46] ## SIMPLE SLOPES ANALYSIS ## ## Slope of age when age_temp = 13.14157 (- 1 SD): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.10 0.02 4.40 0.00 ## ## Slope of age when age_temp = 17.17288 (Mean): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.05 0.02 3.01 0.00 ## ## Slope of age when age_temp = 21.20419 (+ 1 SD): ## ## Est. S.E. t val. p ## ------ ------ -------- ------ ## 0.01 0.02 0.33 0.74 We can see that from around 19 to 27, the linear effect of age (i.e., the slope of the tangent line) is not significant but is significantly positive before and significantly negative after this age range. We round these numbers because we cannot really think we have such precise measurements to say that linear increases in modularity become non-significant exactly at 18.79. However, this sort of plot can help us distinguish between truly quadratic effects (within increases and decreases) versus a plateauing of the outcome at later ages. Time Coding One point of frequent confusion when modeling data (nevermind longitudinal models) is the role of centering the predictors for model results/fit/etc. In general, centering predictors does not change the fundamental information contained within the model, although sometimes it is necessary for practical reason (e.g., reducing collinearity between main effects and product terms). In longitudinal models, the main centering concern is where to place the intercept (i.e., where time is coded 0). While many of our parameter estimates will indeed change based on where we choose to estimate the intercept (most notably the…wait for it…intercept, as well as covariances with the intercept). Here we will demonstrate with the LCM framework since the factor-loading matrix makes what is happening very explicit, but you could replicate these results with any of the other approaches. First, we can fit the linear model to the single-cohort data we showed above. Here we will place the \\(0\\) factor loading at the first time point which will result in the intercept reflecting individual differences in the level of the outcome at the initial assessment (i.e., initial status). initial.status &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&quot; initial.status.fit &lt;- growth(initial.status, data = single.cohort, estimator = &quot;ML&quot;, missing=&quot;FIML&quot;) summary(initial.status.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Model Test Baseline Model: ## ## Test statistic 72.730 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.893 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -248.174 ## Loglikelihood unrestricted model (H1) -242.104 ## ## Akaike (AIC) 514.347 ## Bayesian (BIC) 531.555 ## Sample-size adjusted Bayesian (BIC) 503.306 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.169 ## 90 Percent confidence interval - lower 0.045 ## 90 Percent confidence interval - upper 0.293 ## P-value RMSEA &lt;= 0.05 0.055 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.113 We will focus first on fit and then circle back to parameter estimates later. Here the chi-square test statistics is \\(12.14\\) on \\(5%\\) degrees of freedom (\\(p = 0.033\\)), the \\(CFI = 0.893\\) and the \\(RMSEA = 0.169\\). We can then re-estimate the model where we code the last factor loading as \\(0\\) instead so the intercept will represent final status. final.status &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ -3*dlpfc1 + -2*dlpfc2 + -1*dlpfc3 + 0*dlpfc4&quot; final.status.fit &lt;- growth(final.status, data = single.cohort, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(final.status.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 25 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Model Test Baseline Model: ## ## Test statistic 72.730 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.893 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -248.174 ## Loglikelihood unrestricted model (H1) -242.104 ## ## Akaike (AIC) 514.347 ## Bayesian (BIC) 531.555 ## Sample-size adjusted Bayesian (BIC) 503.306 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.169 ## 90 Percent confidence interval - lower 0.045 ## 90 Percent confidence interval - upper 0.293 ## P-value RMSEA &lt;= 0.05 0.055 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.113 Looking at the model fit values, they are exactly identical to the initial status model. We have effectively re-arranged deck chairs on the Titanic (and Rose is about to shove Jack off that door; don’t @ me) as far as model fit goes. So why might we wish to reformulate this model? Well, individual differences in level might be interesting to interpret substantively at one point over another depending on our application of interest. While many research hypotheses will lend themselves naturally to the initial status approach, in intervention work or a training study we might be far more interesting in interpreting where individuals end up (spoken with all the authority of someone who does not do intervention work). Initial Status LCM Parameter Estimate SE Statistic p-value Std.LV Std.All dlpfc1 ~~ dlpfc1 0.280 0.196 1.427 0.154 0.280 0.307 dlpfc2 ~~ dlpfc2 0.459 0.140 3.275 0.001 0.459 0.435 dlpfc3 ~~ dlpfc3 0.389 0.128 3.039 0.002 0.389 0.368 dlpfc4 ~~ dlpfc4 0.640 0.278 2.302 0.021 0.640 0.428 int ~~ int 0.631 0.207 3.039 0.002 1.000 1.000 slp ~~ slp 0.055 0.054 1.010 0.313 1.000 1.000 int ~~ slp -0.045 0.097 -0.467 0.641 -0.243 -0.243 int ~1 0.628 0.132 4.761 0.000 0.791 0.791 slp ~1 0.114 0.054 2.120 0.034 0.487 0.487 Final Status LCM Parameter Estimate SE Statistic p-value Std.LV Std.All dlpfc1 ~~ dlpfc1 0.280 0.196 1.427 0.154 0.280 0.307 dlpfc2 ~~ dlpfc2 0.459 0.140 3.275 0.001 0.459 0.435 dlpfc3 ~~ dlpfc3 0.389 0.128 3.039 0.002 0.389 0.368 dlpfc4 ~~ dlpfc4 0.640 0.278 2.302 0.021 0.640 0.428 int ~~ int 0.853 0.262 3.262 0.001 1.000 1.000 slp ~~ slp 0.055 0.054 1.010 0.313 1.000 1.000 int ~~ slp 0.119 0.093 1.284 0.199 0.552 0.552 int ~1 0.970 0.158 6.124 0.000 1.050 1.050 slp ~1 0.114 0.054 2.120 0.034 0.487 0.487 We can see that some parameters won’t change based on the time-coding. For instance, the residual variances of the repeated measures (and therefore the R-squares), and the mean and variance of the slope factor. However, the mean and variance of the intercept changes, as does the correlation between the slope and intercept (initial status: \\(r = -0.243\\); final status: \\(r = 0.552\\)). Note that the sign of the correlation flips and the magnitude of the difference is quite substantial. This should urge caution not to interpret the intercept outside of the specific timepoint it is estimated for since it’s parameter values will be context specific (due to rank-order shifts due to random slopes). If we wanted to use a mixed effect model, we might be better off just transforming our predictor variable to reflect the code we want. We can transform the single.cohort data below to suit our purposes. single.cohort.long &lt;- single.cohort %&gt;% pivot_longer(cols=starts_with(c(&quot;age&quot;, &quot;dlpfc&quot;)), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% mutate(wave = as.numeric(wave), age_initial = age - min(age, na.rm = TRUE), age_final = age - max(age, na.rm = TRUE)) We can then fit the models as we usually do to see the equivalencies. initial.status.mlm &lt;- lmer(dlpfc ~ 1 + age_initial + (1 + age_initial | id), na.action = na.omit, REML = TRUE, data = single.cohort.long) final.status.mlm &lt;- lmer(dlpfc ~ 1 + age_final + (1 + age_final | id), na.action = na.omit, REML = TRUE, data = single.cohort.long) tab_model(initial.status.mlm, final.status.mlm, show.se = TRUE, show.df = FALSE, show.ci = FALSE, digits = 3, pred.labels = c(&quot;Intercept&quot;, &quot;Age - min(Age)&quot;, &quot;Age - max(Age)&quot;), dv.labels = c(&quot;Initial Status&quot;, &quot;Final Status&quot;), string.se = &quot;SE&quot;, string.p = &quot;P-Value&quot;)   Initial Status Final Status Predictors Estimates SE P-Value Estimates SE P-Value Intercept 0.619 0.145 &lt;0.001 0.984 0.166 &lt;0.001 Age - min(Age) 0.106 0.056 0.062 Age - max(Age) 0.106 0.056 0.062 Random Effects σ2 0.43 0.43 τ00 0.66 id 0.98 id τ11 0.07 id.age_initial 0.07 id.age_final ρ01 -0.33 id 0.63 id ICC 0.62 0.62 N 50 id 50 id Observations 191 191 Marginal R2 / Conditional R2 0.012 / 0.624 0.012 / 0.624 Note that the slope estimates are identical, while estimates involving the intercept change as we saw before. Additional Considerations One thing that has been consistent across all the models that we have fit thus far is that they are structured primarily by the chronological age of the individuals in question. Even when we have used wave of assessment as the nominal variable encoding time, waves have been spaced into yearly assessments and the lack of heterogeneity in ages collapses age and wave (either in reality or in practice when we fix factor loadings). However, nothing stops us from structuring the repeated measures by some other metric of maturation, practice, or anything else (except for pesky things like convention and serious measurement/modeling challenges, but that’s all). For instance, we could plot our repeated measures in the accelerated data again, but instead of chronological age, we could put pubertal status (measured by Tanner stage) on the x-axis. That would result in the plot below. Alternative Metrics of Time ggplot(accelerated, aes(x = puberty, y = id)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Tanner Stage&quot;, y = &quot;Individual&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) In some ways, this roughly resembles the age plot, with some individuals being measured at earlier stages of puberty and other later. However, close inspection starts to uncover some issues. First, we often stop measuring puberty once individual reach a certain age/stage of development, so puberty as a measure of maturation is limited in it’s utility outside of a fairly specific phase of development. We can already see for subjects who are measured first at later ages having missing data for later observations because puberty measures were not taken. There is also the curious case that some subset of individuals seem to move backwards in pubertal development (this should be treated as an error, but it’s amusing nonetheless). However, the key feature of interest in a plot like this is that, unlike age, there is not reason to expect that all individuals “age” at the same rate across puberty, seen by the uneven spacing between waves within individuals. This variation is just one of the exciting opportunities that modeling maturation using metric other than age present (although they do come with their own challenges; there is an admittedly understandable reason that age is the predominate variable in longitudinal models). One other advantage is within-age heterogeneity, which we can see by plotting Tanner Stage by age in the plot below. ggplot(accelerated, aes(x = age, y = puberty)) + geom_line(aes(group = id), size = .5) + geom_point(aes(color = as.factor(wave))) + labs(x = &quot;Age&quot;, y = &quot;Tanner Stage&quot;, color = &quot;Wave&quot;, shape = &quot;Cohort&quot;) + theme(legend.position = &quot;top&quot;) We can see that same-age peers may differ considerable (depending on when we measure them) in their pubertal development. We can also fit puberty-related trajectories to the modularity data below. accel &lt;- lmer(scale(modularity) ~ 1 + puberty + (1 | id), na.action = na.omit, REML = TRUE, data = accelerated) summary(accel, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: scale(modularity) ~ 1 + puberty + (1 | id) ## Data: accelerated ## ## REML criterion at convergence: 417.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -2.49262 -0.65415 0.04191 0.58260 2.43878 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 0.3322 0.5763 ## Residual 0.6698 0.8184 ## Number of obs: 150, groups: id, 67 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.96653 0.28495 133.98649 -3.392 0.000913 *** ## puberty 0.34156 0.09681 145.04845 3.528 0.000561 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Of course, we might wish to model age and puberty simultaneously. That may present practical challenges in this data, since age and puberty are highly correlated \\(r = 0.796\\), but some strategies for modeling multiple growth processes have been suggested elsewhere (see the relevant portion of the main text for details). Residual Estimates The final consideration we will explore in our discussion of time is the structure of the residuals of our repeated measures. This is often not of great theoretical importance (I don’t really believe you if you tell me your theory is specific enough to know if residual variance should be constant or not…call me a grinch), but it can be really important for model results. Essentially, an overly restrictive assumption about residual variances at the individual observation level can radiate out into the random effects structure and bias your effects. Here we will show how to specify both forms of a model in a mixed effect and structural equation model, and test which one is a better fit to the data. We can start with the LCM, where heteroscedasticity (i.e., unique residual estimates across) is the default. To obtain this model, we use the same syntax we have seen repeatedly so far. lcm.het &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4&quot; lcm.het.fit &lt;- growth(lcm.het, data = single.cohort, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcm.het.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 22 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 12.140 ## Degrees of freedom 5 ## P-value (Chi-square) 0.033 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## slp =~ ## dlpfc1 0.000 ## dlpfc2 1.000 ## dlpfc3 2.000 ## dlpfc4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.045 0.097 -0.467 0.641 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int 0.628 0.132 4.761 0.000 ## slp 0.114 0.054 2.120 0.034 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.280 0.196 1.427 0.154 ## .dlpfc2 0.459 0.140 3.275 0.001 ## .dlpfc3 0.389 0.128 3.039 0.002 ## .dlpfc4 0.640 0.278 2.302 0.021 ## int 0.631 0.207 3.039 0.002 ## slp 0.055 0.054 1.010 0.313 We can easily see that each residual obtains a unique value with an associated inference test (.dlpfc1 - .dlpfc4). To constrain these residuals equal across time, we have to explicitly write out the residual term (we have been relying on sensible defaults thus far) and then pre-multiply each estimate by the same alpha-numeric label. Lavaan will interpret repeated labels as a request for an equality constraint on those parameters. We can see this constraint in action below. lcm.hom &lt;- &quot;int =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4 dlpfc1 ~~ c1*dlpfc1 dlpfc2 ~~ c1*dlpfc2 dlpfc3 ~~ c1*dlpfc3 dlpfc4 ~~ c1*dlpfc4&quot; The choice of constraint (here c1) is somewhat arbitrary, but the point is that it can contain characters and numbers (although it must begin with a character). When we fit the model, we will see those parameters will be held equal. lcm.hom.fit &lt;- growth(lcm.hom, data = single.cohort, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcm.hom.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 19 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## Number of equality constraints 3 ## ## Number of observations 50 ## Number of missing patterns 5 ## ## Model Test User Model: ## ## Test statistic 14.724 ## Degrees of freedom 8 ## P-value (Chi-square) 0.065 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## slp =~ ## dlpfc1 0.000 ## dlpfc2 1.000 ## dlpfc3 2.000 ## dlpfc4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.041 0.061 -0.668 0.504 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int 0.640 0.134 4.761 0.000 ## slp 0.108 0.055 1.969 0.049 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 (c1) 0.435 0.065 6.732 0.000 ## .dlpfc2 (c1) 0.435 0.065 6.732 0.000 ## .dlpfc3 (c1) 0.435 0.065 6.732 0.000 ## .dlpfc4 (c1) 0.435 0.065 6.732 0.000 ## int 0.590 0.189 3.129 0.002 ## slp 0.059 0.032 1.838 0.066 Lavaan conveniently includes the labels in the output and we can see that now all of the residuals obtain the exact same value, and exact same inferential test (note how that changes the inference on the residual of dlpfc1 from above). However, note how other parameter estimates (namely the factor means and variances) change as well. These changes are small (for reasons we will see) but it is important to note we are making real changes to the model with the introduction of this constraint. We can then get a likelihood-ratio test of difference in fit, using the lavTestLRT() function, because the simplified homoscedastic model is nested within the more complex heteroscedastic model. Note that we list the homoscedastic model first. lavaan::lavTestLRT(lcm.hom.fit, lcm.het.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## lcm.het.fit 5 514.35 531.56 12.140 ## lcm.hom.fit 8 510.93 522.40 14.724 2.5837 3 0.4604 However, in the output, the heteroscedastic model is listed first. This is because the more complex model is always the reference and we are testing whether the imposition of model simplifications (i.e., constraints; here homoscedastic residuals) significantly decreases model fit. Here we can see that the chi-square difference test is not significant (\\(p = 0.460\\)), so we could retain the simplification without decreasing the fit of the model to our data. This is the reason that our parameters did not change much. In models where we would reject homoscedasticity, the imposition of the constraint would lead to more pronounced parameter changes elsewhere in the model. While there is not an associated inference test for the AIC/BIC, we could also use those values for model comparisons if we wished. To implement heteroscedastic residuals in mixed-effects models, we have to leave our familiar lmer() and travel back in time to the days of lme(). We can first fit the canonical model we know and love, where the default is homoscedasticity. mlm.hom &lt;- nlme::lme(dlpfc ~ 1 + wave, random = ~ 1 + wave | id, na.action = na.omit, method = &quot;REML&quot;, data = single.cohort.long) summary(mlm.hom, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: single.cohort.long ## AIC BIC logLik ## 517.3124 536.7629 -252.6562 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 0.8717474 (Intr) ## wave 0.2500535 -0.489 ## Residual 0.6595289 ## ## Fixed effects: dlpfc ~ 1 + wave ## Value Std.Error DF t-value p-value ## (Intercept) 0.5321058 0.16886967 140 3.150985 0.0020 ## wave 0.1076007 0.05524678 140 1.947638 0.0535 ## Correlation: ## (Intr) ## wave -0.705 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.09037990 -0.49924910 -0.04034052 0.65971936 2.07352349 ## ## Number of Observations: 191 ## Number of Groups: 50 Note that in the Random effects portion of the output, we obtain a single numerical value for the residual \\(\\sigma^2 = 0.660\\). To fit a heteroscedastic model, we need to make use of a new argument, weights. We can specify the form argument of the varIdent() (“variance identity) function to obtain a unique estimate per wave. mlm.het &lt;- nlme::lme(dlpfc ~ 1 + wave, random = ~ 1 + wave | id, weights = varIdent(form = ~ 1 | wave), na.action = na.omit, method = &quot;REML&quot;, data = single.cohort.long) summary(mlm.het, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: single.cohort.long ## AIC BIC logLik ## 520.7754 549.9511 -251.3877 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 0.8975009 (Intr) ## wave 0.2413003 -0.495 ## Residual 0.5269518 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | wave ## Parameter estimates: ## 1 2 3 4 ## 1.000000 1.287069 1.184203 1.515231 ## Fixed effects: dlpfc ~ 1 + wave ## Value Std.Error DF t-value p-value ## (Intercept) 0.5144231 0.16258045 140 3.164114 0.0019 ## wave 0.1139612 0.05386346 140 2.115743 0.0361 ## Correlation: ## (Intr) ## wave -0.675 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -2.09852285 -0.47236320 -0.01588848 0.64203216 2.12263672 ## ## Number of Observations: 191 ## Number of Groups: 50 Looking at the Random effects output, we still only see a single value for the residual. Unfortunately the output structure here leaves something to be desired. We need to look to the Variance function output section where we see for unique values. Well these are not technically the residual estimates, but rather they indicate the relative size of the residual scaled to the first estimate (the one we see in the Random effects section). To extract the actual estimates, we can use the following code. mlm.het$sigma * exp(as.numeric(mlm.het$modelStruct$varStruct)) ## [1] 0.6782232 0.6240178 0.7984535 So the first residual can be extracted as model$sigma, but the residual weights from the model are stuck in the varStruct portion of the fitted lme() object and are in the \\(log(\\sigma)\\) scale. So we have to extract the values, convert them to numeric format, exponentiate them, and then multiple the weights by the estimated residual to obtain the other three estimates (tired yet?). Fortunately, model comparisons are straightforward with the anova() function, which we can use in the same way we used lavTestLRT() to compare LCMs early. anova(mlm.het, mlm.hom) ## Model df AIC BIC logLik Test L.Ratio p-value ## mlm.het 1 9 520.7754 549.9511 -251.3877 ## mlm.hom 2 6 517.3124 536.7629 -252.6562 1 vs 2 2.537015 0.4686 Like before, these results indicate that imposing homoscedasticity does not significantly decrease model fit. "],["04-shape.html", "The Shape of Development Polynomial Trajectories Piecewise Trajectories Nonlinear Trajectories Fixed and Random Effects", " The Shape of Development However, we define the underlying metric of time to structure our longitudinal model, one of the key substantive questions often underlying work in developmental science is to characterize the course that a given construct takes over time. Here we will highlight many of the different developmental trajectories that we can fit to our data, starting with relatively simple polynomial shapes and working our way up to modeling fully nonlinear trends. In addition to the feedback.learning data we have used thus far, we will also use data drawn from the external-math.csv and adversity.csv files. The external.math data contains up to \\(5\\) repeated observations from \\(405\\) children aged \\(6\\) to \\(14\\), measured once every \\(2\\) years. Here we will focus on measures of externalizing behavior and math proficiency. The adversity data contains fractional anisotropy (FA) measures from \\(398\\) children measured up to \\(4\\) times across ages \\(4\\) to \\(11\\). We previously used a subset of this data in the Time chapter, but here we will utilize the entire sample. external.math &lt;- read.csv(&quot;data/external-math.csv&quot;) adversity &lt;- read.csv(&quot;data/adversity.csv&quot;) feedback.learning &lt;- read.csv(&quot;data/feedback-learning.csv&quot;) %&gt;% select(id, age, modularity, learning.rate) Polynomial Trajectories Like we discussed in the main text, polynomial trajectories are far and away the most common trajectories modeled with longitudinal data. They require relatively few unique timepoints, are straightforward to model, and offer easily-interpretable parameter estimates. Intercept-Only Model We can first consider the simplest polynomial model, one without even a slope. The intercept-only model simply models person-specific differences in average level across time. We can start here with the LCM, which makes the various specifications easiest to see, but we will also build syntax for models in the other frameworks. int.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14&quot; int.lcm.fit &lt;- growth(int.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(int.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 25 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 7 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 71.246 ## Degrees of freedom 13 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ext6 1.000 ## ext8 1.000 ## ext10 1.000 ## ext12 1.000 ## ext14 1.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 0.000 ## .ext8 0.000 ## .ext10 0.000 ## .ext12 0.000 ## .ext14 0.000 ## int 1.882 0.077 24.397 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 1.761 0.203 8.690 0.000 ## .ext8 1.771 0.189 9.384 0.000 ## .ext10 2.023 0.208 9.730 0.000 ## .ext12 2.243 0.230 9.758 0.000 ## .ext14 2.049 0.348 5.891 0.000 ## int 1.752 0.172 10.161 0.000 We can see that there is significant variance in the intercept factor, suggesting meaningful person-to-person variability in level of externalizing behavior during late childhood and early adolescence. While this might seem a somewhat silly model to fit to these data, this is one half of a random-intercept cross-lag panel model and might be appropriate if we do not expect systematic change over time. However, these intercept-only models are admittedly more plausible for intensive longitudinal data. The MLM specification for this model can be seen below. We will first transform the data into long format before fitting the model. external.math.long &lt;- external.math %&gt;% pivot_longer(cols = starts_with(c(&quot;ext&quot;, &quot;math&quot;)), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(ext|math)(.+)&quot;) %&gt;% mutate(age = as.numeric(age)) int.mlm &lt;- lmer(ext ~ 1 + (1 | id), na.action = na.omit, REML = TRUE, data = external.math.long) summary(int.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ext ~ 1 + (1 | id) ## Data: external.math.long ## ## REML criterion at convergence: 5316.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2539 -0.5600 -0.2063 0.4736 4.5276 ## ## Random effects: ## Groups Name Variance Std.Dev. ## id (Intercept) 1.799 1.341 ## Residual 1.944 1.394 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.89455 0.07736 399.24978 24.49 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note that this is just a random-effects ANOVA model with no predictors. Linear Model We will move quickly through the linear polynomial models because we have covered them extensively thus far. Below is the syntax for the linear LCM. Remember that assessments are biannual so factor loadings should increase by two for each wave. lin.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14&quot; lin.lcm.fit &lt;- growth(lin.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lin.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 19.507 ## Degrees of freedom 10 ## P-value (Chi-square) 0.034 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ext6 1.000 ## ext8 1.000 ## ext10 1.000 ## ext12 1.000 ## ext14 1.000 ## slp =~ ## ext6 0.000 ## ext8 2.000 ## ext10 4.000 ## ext12 6.000 ## ext14 8.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp 0.084 0.042 2.003 0.045 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 0.000 ## .ext8 0.000 ## .ext10 0.000 ## .ext12 0.000 ## .ext14 0.000 ## int 1.664 0.081 20.459 0.000 ## slp 0.074 0.018 4.135 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 1.653 0.239 6.914 0.000 ## .ext8 1.844 0.188 9.807 0.000 ## .ext10 1.910 0.199 9.593 0.000 ## .ext12 1.592 0.227 7.007 0.000 ## .ext14 1.618 0.372 4.346 0.000 ## int 1.068 0.227 4.710 0.000 ## slp 0.024 0.011 2.066 0.039 While we have ignored model fit for most models, one nice thing about many of these models, is that they are nested and allow for formal model comparison with likelihood ratio tests, similar to those we saw with hetero- vs. homoscedastic residuals. For instance, we can compare the intercept-only with a linear model. lavTestLRT(int.lcm.fit, lin.lcm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## lin.lcm.fit 10 5278.2 5318.3 19.506 ## int.lcm.fit 13 5324.0 5352.0 71.246 51.74 3 3.403e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Remember that we compare whether the more constrained model (here the intercept-only) induces a significant decrease in model fit. Here this is true, suggesting that we should retain the linear model over the intercept-only model. If we take a peak at the model fit, this is because the linear model fits the data reasonably well, while the intercept-only model is quite poor in terms of fit. summary(int.lcm.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 25 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 7 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 71.246 ## Degrees of freedom 13 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 361.048 ## Degrees of freedom 10 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.834 ## Tucker-Lewis Index (TLI) 0.872 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2654.990 ## Loglikelihood unrestricted model (H1) -2619.367 ## ## Akaike (AIC) 5323.980 ## Bayesian (BIC) 5352.007 ## Sample-size adjusted Bayesian (BIC) 5329.795 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.105 ## 90 Percent confidence interval - lower 0.082 ## 90 Percent confidence interval - upper 0.130 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.156 summary(lin.lcm.fit, fit.measures = TRUE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 19.507 ## Degrees of freedom 10 ## P-value (Chi-square) 0.034 ## ## Model Test Baseline Model: ## ## Test statistic 361.048 ## Degrees of freedom 10 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.973 ## Tucker-Lewis Index (TLI) 0.973 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -2629.120 ## Loglikelihood unrestricted model (H1) -2619.367 ## ## Akaike (AIC) 5278.240 ## Bayesian (BIC) 5318.279 ## Sample-size adjusted Bayesian (BIC) 5286.547 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.048 ## 90 Percent confidence interval - lower 0.013 ## 90 Percent confidence interval - upper 0.080 ## P-value RMSEA &lt;= 0.05 0.486 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.082 To fit the corresponding MLM, we first need to generate our linear predictor as an observed variable in our data frame (and will need to do so each time we increase the order of the model). Here we will generate the linear predictor by simply subtracting \\(6\\) from the age variable. external.math.long$age &lt;- external.math.long$age - min(external.math.long$age) lin.mlm &lt;- lmer(ext ~ 1 + age + (1 + age | id), na.action = na.omit, REML = TRUE, data = external.math.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(lin.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ext ~ 1 + age + (1 + age | id) ## Data: external.math.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 5269.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.1375 -0.5422 -0.1737 0.4491 3.9389 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 1.02975 1.0148 ## age 0.01778 0.1334 0.75 ## Residual 1.78241 1.3351 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.66939 0.08114 372.83468 20.574 &lt; 2e-16 *** ## age 0.07235 0.01758 288.52536 4.116 5.03e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 And the model comparison reveals the same preference for the linear model. Note that the model is re-estimated with ML [FIML] because the two models contain different fixed effects. REML models can be compared when the models differ only in the variance structure. Fortunately this will be done automatically so we don’t have to “manually” re-estimate the models. anova(int.mlm, lin.mlm) ## Data: external.math.long ## Models: ## int.mlm: ext ~ 1 + (1 | id) ## lin.mlm: ext ~ 1 + age + (1 + age | id) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## int.mlm 3 5319.5 5335.1 -2656.7 5313.5 ## lin.mlm 6 5271.7 5303.0 -2629.9 5259.7 53.736 3 1.277e-11 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Finally, we can see a version of the linear LCSM for the external.math data below. Note again that biannual observations mean that we need to set the factor loadings for the slope factor to \\(2\\) instead of \\(1\\) to indicate the spacing appropriately. lin.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pext6 =~ 1*ext6; ext6 ~ 0; ext6 ~~ ext6; pext6 ~~ 0*pext6 pext8 =~ 1*ext8; ext8 ~ 0; ext8 ~~ ext8; pext8 ~~ 0*pext8 pext10 =~ 1*ext10; ext10 ~ 0; ext10 ~~ ext10; pext10 ~~ 0*pext10 pext12 =~ 1*ext12; ext12 ~ 0; ext12 ~~ ext12; pext12 ~~ 0*pext12 pext14 =~ 1*ext14; ext14 ~ 0; ext14 ~~ ext14; pext14 ~~ 0*pext14 # Regressions Between Adjacent Observations pext8 ~ 1*pext6 pext10 ~ 1*pext8 pext12 ~ 1*pext10 pext14 ~ 1*pext12 # Define Change Latent Variables (delta) delta21 =~ 1*pext8; delta21 ~~ 0*delta21 delta32 =~ 1*pext10; delta32 ~~ 0*delta32 delta43 =~ 1*pext12; delta43 ~~ 0*delta43 delta54 =~ 1*pext14; delta54 ~~ 0*delta54 # Define Intercept and Slope int =~ 1*pext6 slp =~ 2*delta21 + 2*delta32 + 2*delta43 + 2*delta54 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &quot; lin.lcsm.fit &lt;- sem(lin.lcsm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lin.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 10 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 19.507 ## Degrees of freedom 10 ## P-value (Chi-square) 0.034 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## pext6 =~ ## ext6 1.000 ## pext8 =~ ## ext8 1.000 ## pext10 =~ ## ext10 1.000 ## pext12 =~ ## ext12 1.000 ## pext14 =~ ## ext14 1.000 ## delta21 =~ ## pext8 1.000 ## delta32 =~ ## pext10 1.000 ## delta43 =~ ## pext12 1.000 ## delta54 =~ ## pext14 1.000 ## int =~ ## pext6 1.000 ## slp =~ ## delta21 2.000 ## delta32 2.000 ## delta43 2.000 ## delta54 2.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## pext8 ~ ## pext6 1.000 ## pext10 ~ ## pext8 1.000 ## pext12 ~ ## pext10 1.000 ## pext14 ~ ## pext12 1.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp 0.084 0.042 2.003 0.045 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 0.000 ## .ext8 0.000 ## .ext10 0.000 ## .ext12 0.000 ## .ext14 0.000 ## int 1.664 0.081 20.459 0.000 ## slp 0.074 0.018 4.135 0.000 ## .pext6 0.000 ## .pext8 0.000 ## .pext10 0.000 ## .pext12 0.000 ## .pext14 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## .delta54 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ext6 1.653 0.239 6.914 0.000 ## .pext6 0.000 ## .ext8 1.844 0.188 9.807 0.000 ## .pext8 0.000 ## .ext10 1.910 0.199 9.593 0.000 ## .pext10 0.000 ## .ext12 1.592 0.227 7.007 0.000 ## .pext12 0.000 ## .ext14 1.618 0.372 4.346 0.000 ## .pext14 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## .delta54 0.000 ## slp 0.024 0.011 2.066 0.039 ## int 1.068 0.227 4.710 0.000 Quadratic Model Next, we can add an additional factor to capture quadratic curvature in our data. Below is the LCM syntax for this model. Note that this is an extremely straightforward expansion of the syntax we have seen thus far. While this won’t be the case here, sometimes we need to worry about numerically large factor loadings causing some estimation issues in practice (nothing theoretical is wrong with large factor loadings). In those instances, we could divide our factor loadings by some constant to control those values from getting to large (although this will change the interpretation of a per-unit change). quad.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14 quad =~ 0*ext6 + 4*ext8 + 16*ext10 + 36*ext12 + 64*ext14&quot; quad.lcm.fit &lt;- growth(quad.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(quad.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 95 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.437 ## Degrees of freedom 6 ## P-value (Chi-square) 0.489 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## ext6 1.000 1.166 0.731 ## ext8 1.000 1.166 0.625 ## ext10 1.000 1.166 0.566 ## ext12 1.000 1.166 0.546 ## ext14 1.000 1.166 0.551 ## slp =~ ## ext6 0.000 0.000 0.000 ## ext8 2.000 1.040 0.558 ## ext10 4.000 2.079 1.010 ## ext12 6.000 3.119 1.461 ## ext14 8.000 4.159 1.964 ## quad =~ ## ext6 0.000 0.000 0.000 ## ext8 4.000 0.228 0.122 ## ext10 16.000 0.912 0.443 ## ext12 36.000 2.051 0.961 ## ext14 64.000 3.647 1.722 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.108 0.209 -0.514 0.607 -0.177 -0.177 ## quad 0.018 0.023 0.772 0.440 0.270 0.270 ## slp ~~ ## quad -0.029 0.015 -1.933 0.053 -0.970 -0.970 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 0.000 0.000 0.000 ## .ext8 0.000 0.000 0.000 ## .ext10 0.000 0.000 0.000 ## .ext12 0.000 0.000 0.000 ## .ext14 0.000 0.000 0.000 ## int 1.567 0.088 17.809 0.000 1.344 1.344 ## slp 0.182 0.051 3.535 0.000 0.349 0.349 ## quad -0.015 0.007 -2.300 0.021 -0.271 -0.271 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 1.188 0.431 2.758 0.006 1.188 0.466 ## .ext8 1.731 0.191 9.076 0.000 1.731 0.498 ## .ext10 1.691 0.215 7.858 0.000 1.691 0.399 ## .ext12 1.672 0.227 7.379 0.000 1.672 0.367 ## .ext14 1.381 0.649 2.128 0.033 1.381 0.308 ## int 1.360 0.431 3.159 0.002 1.000 1.000 ## slp 0.270 0.124 2.175 0.030 1.000 1.000 ## quad 0.003 0.002 1.705 0.088 1.000 1.000 lavTestLRT(lin.lcm.fit, quad.lcm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## quad.lcm.fit 6 5272.2 5328.2 5.4373 ## lin.lcm.fit 10 5278.2 5318.3 19.5065 14.069 4 0.007077 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The MLM syntax is similarly straightforward. To add a powered term, we can use the I() function, or the poly() function if we wished to use orthogonal polynomials. quad.mlm &lt;- lmer(ext ~ 1 + age + I(age^2) + (1 + age + I(age^2) | id), na.action = na.omit, REML = TRUE, data = external.math.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(quad.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ext ~ 1 + age + I(age^2) + (1 + age + I(age^2) | id) ## Data: external.math.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 5263.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2948 -0.5378 -0.1802 0.4328 4.1605 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.942787 0.97097 ## age 0.162793 0.40348 0.27 ## I(age^2) 0.001871 0.04325 -0.12 -0.96 ## Residual 1.684821 1.29801 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.574442 0.087961 345.809227 17.899 &lt; 2e-16 *** ## age 0.178331 0.051186 357.020201 3.484 0.000555 *** ## I(age^2) -0.015107 0.006678 299.946299 -2.262 0.024398 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 While these models converge without too much issue here, note the strong correlation between the linear and quadratic terms, suggesting that the quadratic term is largely redundant. This is often the case with low numbers of repeated measures. We can technically fit some non-linearities, but they may not be particularly well-specified. The LCSM syntax requires a bit more explanation. The quadratic model is shown below. quad.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pext6 =~ 1*ext6; ext6 ~ 0; ext6 ~~ ext6; pext6 ~~ 0*pext6 pext8 =~ 1*ext8; ext8 ~ 0; ext8 ~~ ext8; pext8 ~~ 0*pext8 pext10 =~ 1*ext10; ext10 ~ 0; ext10 ~~ ext10; pext10 ~~ 0*pext10 pext12 =~ 1*ext12; ext12 ~ 0; ext12 ~~ ext12; pext12 ~~ 0*pext12 pext14 =~ 1*ext14; ext14 ~ 0; ext14 ~~ ext14; pext14 ~~ 0*pext14 # Regressions Between Adjacent Observations pext8 ~ 1*pext6 pext10 ~ 1*pext8 pext12 ~ 1*pext10 pext14 ~ 1*pext12 # Define Change Latent Variables (delta) delta21 =~ 1*pext8; delta21 ~~ 0*delta21 delta32 =~ 1*pext10; delta32 ~~ 0*delta32 delta43 =~ 1*pext12; delta43 ~~ 0*delta43 delta54 =~ 1*pext14; delta54 ~~ 0*delta54 # Define Intercept and Slope int =~ 1*pext6 slp =~ 2*delta21 + 2*delta32 + 2*delta43 + 2*delta54 quad =~ 4*delta21 + 12*delta32 + 20*delta43 + 28*delta54 int ~ 1 slp ~ 1 quad ~ 1 int ~~ slp int ~~ quad slp ~~ slp slp ~~ quad quad ~~ quad &quot; We talked in the Canonical chapter about how the loadings for the linear factor were all \\(1\\), and this could be thought of as summing across the difference factors. Another way to think of this specification is that the factor loadings for the LCSM are the differences between successive loadings for the LCM. In the standard linear case, these are all \\(1\\)s to indicate a constant effect across units of time, whereas in our example in this chapter, they are all differences of \\(2\\) to reflect biannual observations. The same principle can be applied to the loadings for higher-order factors in the LCSM. For a quadratic factor, the LCM loadings are [\\(0\\), \\(4\\), \\(16\\), \\(36\\), \\(64\\)], and therefore the LCSM loadings should be [(\\(4 - 0\\)), (\\(16 - 4\\)), (\\(36 - 16\\)), (\\(64 - 36\\))] = [\\(4\\), \\(12\\), \\(20\\), \\(28\\)]. As a sanity check, we can fit this model and the parameter estimates should match the LCM results exactly. quad.lcsm.fit &lt;- sem(quad.lcsm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(quad.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 95 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.437 ## Degrees of freedom 6 ## P-value (Chi-square) 0.489 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pext6 =~ ## ext6 1.000 1.166 0.731 ## pext8 =~ ## ext8 1.000 1.322 0.709 ## pext10 =~ ## ext10 1.000 1.597 0.775 ## pext12 =~ ## ext12 1.000 1.698 0.796 ## pext14 =~ ## ext14 1.000 1.761 0.832 ## delta21 =~ ## pext8 1.000 0.621 0.621 ## delta32 =~ ## pext10 1.000 0.257 0.257 ## delta43 =~ ## pext12 1.000 0.167 0.167 ## delta54 =~ ## pext14 1.000 0.362 0.362 ## int =~ ## pext6 1.000 1.000 1.000 ## slp =~ ## delta21 2.000 1.267 1.267 ## delta32 2.000 2.529 2.529 ## delta43 2.000 3.665 3.665 ## delta54 2.000 1.629 1.629 ## quad =~ ## delta21 4.000 0.278 0.278 ## delta32 12.000 1.663 1.663 ## delta43 20.000 4.017 4.017 ## delta54 28.000 2.499 2.499 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pext8 ~ ## pext6 1.000 0.882 0.882 ## pext10 ~ ## pext8 1.000 0.828 0.828 ## pext12 ~ ## pext10 1.000 0.941 0.941 ## pext14 ~ ## pext12 1.000 0.964 0.964 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp -0.108 0.209 -0.514 0.607 -0.177 -0.177 ## quad 0.018 0.023 0.772 0.440 0.270 0.270 ## slp ~~ ## quad -0.029 0.015 -1.933 0.053 -0.970 -0.970 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 0.000 0.000 0.000 ## .ext8 0.000 0.000 0.000 ## .ext10 0.000 0.000 0.000 ## .ext12 0.000 0.000 0.000 ## .ext14 0.000 0.000 0.000 ## int 1.567 0.088 17.809 0.000 1.344 1.344 ## slp 0.182 0.051 3.535 0.000 0.349 0.349 ## quad -0.015 0.007 -2.300 0.021 -0.271 -0.271 ## .pext6 0.000 0.000 0.000 ## .pext8 0.000 0.000 0.000 ## .pext10 0.000 0.000 0.000 ## .pext12 0.000 0.000 0.000 ## .pext14 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 1.188 0.431 2.758 0.006 1.188 0.466 ## .pext6 0.000 0.000 0.000 ## .ext8 1.731 0.191 9.076 0.000 1.731 0.498 ## .pext8 0.000 0.000 0.000 ## .ext10 1.691 0.215 7.858 0.000 1.691 0.399 ## .pext10 0.000 0.000 0.000 ## .ext12 1.672 0.227 7.379 0.000 1.672 0.367 ## .pext12 0.000 0.000 0.000 ## .ext14 1.381 0.649 2.128 0.033 1.381 0.308 ## .pext14 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 0.000 0.000 ## slp 0.270 0.124 2.175 0.030 1.000 1.000 ## quad 0.003 0.002 1.705 0.088 1.000 1.000 ## int 1.360 0.431 3.159 0.002 1.000 1.000 lavTestLRT(lin.lcsm.fit, quad.lcsm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## quad.lcsm.fit 6 5272.2 5328.2 5.4373 ## lin.lcsm.fit 10 5278.2 5318.3 19.5065 14.069 4 0.007077 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Inverse Model The final polynomial model we will consider is the inverse model. Unlike the quadratic curvature which reverses, the inverse curve approaches a plateau asymptotically. We can do a quick algebraic transformation to make the factor loadings tractable by inverting the original (i.e., not centered) values and subtracting them from \\(1\\). So for linear loadings [\\(1\\), \\(3\\), \\(5\\), \\(7\\), \\(9\\)], we would have inverse factor loadings [\\(1 - (1/1)\\), \\(1 - (1/3)\\), \\(1 - (1/5)\\), \\(1 - (1/7)\\), \\(1 - (1/9)\\)] or [\\(0\\), \\(2/3\\), \\(4/5\\), \\(6/7\\), \\(8/9\\)]. Inverting the original loadings avoids trying to take the reciprocal of 0 (which results in 6 more weeks of COVID variants) and subtracting from one specifies an upper rather than lower bound effect (this won’t change the nature of the effect, it just makes the sign easier to interpret). inv.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14 inv =~ 0*ext6 + (2/3)*ext8 + (4/5)*ext10 + (6/7)*ext12 + (7/8)*ext14&quot; inv.lcm.fit &lt;- growth(inv.lcm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(inv.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 64 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.839 ## Degrees of freedom 6 ## P-value (Chi-square) 0.442 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## ext6 1.000 1.747 1.099 ## ext8 1.000 1.747 0.925 ## ext10 1.000 1.747 0.855 ## ext12 1.000 1.747 0.830 ## ext14 1.000 1.747 0.799 ## slp =~ ## ext6 0.000 0.000 0.000 ## ext8 2.000 0.358 0.189 ## ext10 4.000 0.716 0.350 ## ext12 6.000 1.073 0.510 ## ext14 8.000 1.431 0.654 ## inv =~ ## ext6 0.000 0.000 0.000 ## ext8 0.667 1.816 0.962 ## ext10 0.800 2.179 1.066 ## ext12 0.857 2.335 1.109 ## ext14 0.875 2.384 1.090 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 0.175 0.141 1.240 0.215 0.560 0.560 ## inv -3.251 3.076 -1.057 0.290 -0.683 -0.683 ## slp ~~ ## inv -0.335 0.302 -1.109 0.267 -0.688 -0.688 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 0.000 0.000 0.000 ## .ext8 0.000 0.000 0.000 ## .ext10 0.000 0.000 0.000 ## .ext12 0.000 0.000 0.000 ## .ext14 0.000 0.000 0.000 ## int 1.551 0.091 17.075 0.000 0.887 0.887 ## slp 0.014 0.030 0.458 0.647 0.076 0.076 ## inv 0.513 0.217 2.368 0.018 0.188 0.188 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 -0.523 1.838 -0.285 0.776 -0.523 -0.207 ## .ext8 1.617 0.240 6.739 0.000 1.617 0.453 ## .ext10 1.811 0.203 8.939 0.000 1.811 0.433 ## .ext12 1.696 0.227 7.461 0.000 1.696 0.383 ## .ext14 1.582 0.447 3.541 0.000 1.582 0.331 ## int 3.052 1.850 1.650 0.099 1.000 1.000 ## slp 0.032 0.033 0.978 0.328 1.000 1.000 ## inv 7.422 5.288 1.404 0.160 1.000 1.000 lavTestLRT(lin.lcm.fit, inv.lcm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## inv.lcm.fit 6 5272.6 5328.6 5.8386 ## lin.lcm.fit 10 5278.2 5318.3 19.5065 13.668 4 0.008434 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note that we are comparing the inverse and linear models, not the inverse and quadratic. This is because while the linear model is nested within both quadratic and inverse models, the two are not nested with respect to one another. However, we might graphically examine the trends implied by the model for a moment. What should be visually apparent is that we get quite a few flips in the direction of curvature in the inverse compared to the quadratic model. Indeed the quadratic effect is negative (\\(-0.015\\)) and the inverse effect is positive (\\(0.513\\)). This sensitivity is likely another indication that curvature is really over-fitting noise in these data rather than reflecting some true non-linearity. Below are how to achieve this model with the MLM: external.math.long$age_inv &lt;- 1 - (external.math.long$age + 1)^(-1) inv.mlm &lt;- lmer(ext ~ 1 + age + age_inv + (1 + age + age_inv | id), na.action = na.omit, REML = TRUE, data = external.math.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(inv.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ext ~ 1 + age + age_inv + (1 + age + age_inv | id) ## Data: external.math.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 5257.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2607 -0.5446 -0.1801 0.4579 4.1099 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.83374 0.9131 ## age 0.01219 0.1104 0.20 ## age_inv 0.90843 0.9531 0.51 -0.17 ## Residual 1.72232 1.3124 ## Number of obs: 1357, groups: id, 405 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.56085 0.09081 319.40873 17.188 &lt;2e-16 *** ## age 0.01432 0.02980 283.39325 0.480 0.6313 ## age_inv 0.49152 0.21733 353.09910 2.262 0.0243 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 anova(lin.mlm, inv.mlm) ## Data: external.math.long ## Models: ## lin.mlm: ext ~ 1 + age + (1 + age | id) ## inv.mlm: ext ~ 1 + age + age_inv + (1 + age + age_inv | id) ## npar AIC BIC logLik deviance Chisq Df Pr(&gt;Chisq) ## lin.mlm 6 5271.7 5303 -2629.9 5259.7 ## inv.mlm 10 5266.9 5319 -2623.4 5246.9 12.825 4 0.01216 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 and LCSM (note that the subtraction method gets a little messy for the slope loadings): inv.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pext6 =~ 1*ext6; ext6 ~ 0; ext6 ~~ ext6; pext6 ~~ 0*pext6 pext8 =~ 1*ext8; ext8 ~ 0; ext8 ~~ ext8; pext8 ~~ 0*pext8 pext10 =~ 1*ext10; ext10 ~ 0; ext10 ~~ ext10; pext10 ~~ 0*pext10 pext12 =~ 1*ext12; ext12 ~ 0; ext12 ~~ ext12; pext12 ~~ 0*pext12 pext14 =~ 1*ext14; ext14 ~ 0; ext14 ~~ ext14; pext14 ~~ 0*pext14 # Regressions Between Adjacent Observations pext8 ~ 1*pext6 pext10 ~ 1*pext8 pext12 ~ 1*pext10 pext14 ~ 1*pext12 # Define Change Latent Variables (delta) delta21 =~ 1*pext8; delta21 ~~ 0*delta21 delta32 =~ 1*pext10; delta32 ~~ 0*delta32 delta43 =~ 1*pext12; delta43 ~~ 0*delta43 delta54 =~ 1*pext14; delta54 ~~ 0*delta54 # Define Intercept and Slope int =~ 1*pext6 slp =~ 2*delta21 + 2*delta32 + 2*delta43 + 2*delta54 inv =~ (2/3)*delta21 + (2/15)*delta32 + (2/35)*delta43 + (1/56)*delta54 int ~ 1 slp ~ 1 inv ~ 1 int ~~ slp int ~~ inv slp ~~ slp slp ~~ inv inv ~~ inv &quot; inv.lcsm.fit &lt;- sem(inv.lcsm, data = external.math, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(inv.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 64 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 405 ## Number of missing patterns 21 ## ## Model Test User Model: ## ## Test statistic 5.839 ## Degrees of freedom 6 ## P-value (Chi-square) 0.442 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pext6 =~ ## ext6 1.000 1.747 1.099 ## pext8 =~ ## ext8 1.000 1.397 0.739 ## pext10 =~ ## ext10 1.000 1.539 0.753 ## pext12 =~ ## ext12 1.000 1.655 0.786 ## pext14 =~ ## ext14 1.000 1.790 0.818 ## delta21 =~ ## pext8 1.000 1.140 1.140 ## delta32 =~ ## pext10 1.000 0.185 0.185 ## delta43 =~ ## pext12 1.000 0.166 0.166 ## delta54 =~ ## pext14 1.000 0.182 0.182 ## int =~ ## pext6 1.000 1.000 1.000 ## slp =~ ## delta21 2.000 0.225 0.225 ## delta32 2.000 1.255 1.255 ## delta43 2.000 1.301 1.301 ## delta54 2.000 1.097 1.097 ## inv =~ ## delta21 0.667 1.141 1.141 ## delta32 0.133 1.274 1.274 ## delta43 0.057 0.566 0.566 ## delta54 0.018 0.149 0.149 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pext8 ~ ## pext6 1.000 1.251 1.251 ## pext10 ~ ## pext8 1.000 0.908 0.908 ## pext12 ~ ## pext10 1.000 0.930 0.930 ## pext14 ~ ## pext12 1.000 0.925 0.925 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 0.175 0.141 1.240 0.215 0.560 0.560 ## inv -3.251 3.076 -1.057 0.290 -0.683 -0.683 ## slp ~~ ## inv -0.335 0.302 -1.109 0.267 -0.688 -0.688 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 0.000 0.000 0.000 ## .ext8 0.000 0.000 0.000 ## .ext10 0.000 0.000 0.000 ## .ext12 0.000 0.000 0.000 ## .ext14 0.000 0.000 0.000 ## int 1.551 0.091 17.075 0.000 0.887 0.887 ## slp 0.014 0.030 0.458 0.647 0.076 0.076 ## inv 0.513 0.217 2.368 0.018 0.188 0.188 ## .pext6 0.000 0.000 0.000 ## .pext8 0.000 0.000 0.000 ## .pext10 0.000 0.000 0.000 ## .pext12 0.000 0.000 0.000 ## .pext14 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .ext6 -0.523 1.838 -0.285 0.776 -0.523 -0.207 ## .pext6 0.000 0.000 0.000 ## .ext8 1.617 0.240 6.739 0.000 1.617 0.453 ## .pext8 0.000 0.000 0.000 ## .ext10 1.811 0.203 8.939 0.000 1.811 0.433 ## .pext10 0.000 0.000 0.000 ## .ext12 1.696 0.227 7.461 0.000 1.696 0.383 ## .pext12 0.000 0.000 0.000 ## .ext14 1.582 0.447 3.541 0.000 1.582 0.331 ## .pext14 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 0.000 0.000 ## slp 0.032 0.033 0.978 0.328 1.000 1.000 ## inv 7.422 5.288 1.404 0.160 1.000 1.000 ## int 3.052 1.850 1.650 0.099 1.000 1.000 lavTestLRT(lin.lcsm.fit, inv.lcsm.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## inv.lcsm.fit 6 5272.6 5328.6 5.8386 ## lin.lcsm.fit 10 5278.2 5318.3 19.5065 13.668 4 0.008434 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Piecewise Trajectories If we do not think that a single polynomial function can sufficiently capture a complex trajectory, we might consider bolting two (or more) polynomial functions together using a piecewise approach. Here we will use the adversity data which covers \\(8\\) years of childhood (ages \\(4-11\\)). The simplest piecewise trajectory can be constructed two distinct linear pieces joined at a knot point. We need at least 3 time points to specify a line but the pieces can share a time point at the knot point. This means we need a minimum of \\(5\\) time points in order to fit even the simplest piecewise model. Note that with this minimum, the knot point is constrained to be at the middle time point, and the knot can never be placed at the first or last two time points because of the 3 time point requirement to estimate the linear slope. Note that as we discussed before, these time point requirements can be accomodated at the group level, and no one individual need be observed \\(5\\) or more times. Indeed this is the case here, where no individual is measured more than \\(4\\) times. There are two general approaches for specifying piecewise models. The first, and more common, approach is the two-rate specification, where each effect can be interpreted in isolation like a regular linear model. We specify the two-rate LCM using the syntax below. Note that we code the factor loadings in such a way that the intercept is at the knot point (age 8). two.rate &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp1 =~ -3*fmin4 + -2*fmin5 + -1*fmin6 + 0*fmin7 + 0*fmin8 + 0*fmin9 + 0*fmin10 + 0*fmin11 slp2 =~ 0*fmin4 + 0*fmin5 + 0*fmin6 + 0*fmin7 + 1*fmin8 + 2*fmin9 + 3*fmin10 + 4*fmin11 &quot; two.rate.fit &lt;- growth(two.rate, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(two.rate.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 50 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 17 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 35.322 ## Degrees of freedom 27 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fmin4 1.000 0.886 0.888 ## fmin5 1.000 0.886 0.942 ## fmin6 1.000 0.886 0.824 ## fmin7 1.000 0.886 0.761 ## fmin8 1.000 0.886 0.706 ## fmin9 1.000 0.886 0.720 ## fmin10 1.000 0.886 0.739 ## fmin11 1.000 0.886 0.661 ## slp1 =~ ## fmin4 -3.000 -0.985 -0.987 ## fmin5 -2.000 -0.657 -0.698 ## fmin6 -1.000 -0.328 -0.305 ## fmin7 0.000 0.000 0.000 ## fmin8 0.000 0.000 0.000 ## fmin9 0.000 0.000 0.000 ## fmin10 0.000 0.000 0.000 ## fmin11 0.000 0.000 0.000 ## slp2 =~ ## fmin4 0.000 0.000 0.000 ## fmin5 0.000 0.000 0.000 ## fmin6 0.000 0.000 0.000 ## fmin7 0.000 0.000 0.000 ## fmin8 1.000 0.068 0.054 ## fmin9 2.000 0.136 0.111 ## fmin10 3.000 0.204 0.170 ## fmin11 4.000 0.272 0.203 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp1 0.138 0.062 2.233 0.026 0.475 0.475 ## slp2 0.027 0.045 0.602 0.547 0.449 0.449 ## slp1 ~~ ## slp2 0.011 0.019 0.548 0.584 0.475 0.475 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## int 0.216 0.062 3.495 0.000 0.244 0.244 ## slp1 0.079 0.029 2.741 0.006 0.239 0.239 ## slp2 0.031 0.020 1.576 0.115 0.455 0.455 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.069 0.388 0.178 0.859 0.069 0.069 ## .fmin5 0.221 0.190 1.161 0.246 0.221 0.250 ## .fmin6 0.539 0.103 5.231 0.000 0.539 0.466 ## .fmin7 0.570 0.156 3.653 0.000 0.570 0.420 ## .fmin8 0.731 0.129 5.671 0.000 0.731 0.464 ## .fmin9 0.605 0.099 6.108 0.000 0.605 0.399 ## .fmin10 0.450 0.123 3.664 0.000 0.450 0.312 ## .fmin11 0.722 0.172 4.191 0.000 0.722 0.401 ## int 0.786 0.151 5.215 0.000 1.000 1.000 ## slp1 0.108 0.056 1.919 0.055 1.000 1.000 ## slp2 0.005 0.019 0.240 0.810 1.000 1.000 ggplot(data.frame(id=two.rate.fit@Data@case.idx[[1]], lavPredict(two.rate.fit,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(fmin)(.+)&quot;) %&gt;% dplyr::mutate(age = as.numeric(age)), aes(x = age, y = fmin, group = id, color = factor(id))) + geom_line() + labs(title = &quot;2-Rate Piecewise LCM Trajectories&quot;, x = &quot;Age&quot;, y = &quot;Predicted Forceps Minor Microstructure&quot;) + theme(legend.position = &quot;none&quot;) The second approach is the added-rate approach where the second slope is defined as the deflection from the original trajectory. We can see this approach below. add.rate &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp1 =~ -3*fmin4 + -2*fmin5 + -1*fmin6 + 0*fmin7 + 1*fmin8 + 2*fmin9 + 3*fmin10 + 4*fmin11 slp2 =~ 0*fmin4 + 0*fmin5 + 0*fmin6 + 0*fmin7 + 1*fmin8 + 2*fmin9 + 3*fmin10 + 4*fmin11 &quot; add.rate.fit &lt;- growth(add.rate, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(add.rate.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 44 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 17 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 35.322 ## Degrees of freedom 27 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fmin4 1.000 0.886 0.888 ## fmin5 1.000 0.886 0.942 ## fmin6 1.000 0.886 0.824 ## fmin7 1.000 0.886 0.761 ## fmin8 1.000 0.886 0.706 ## fmin9 1.000 0.886 0.720 ## fmin10 1.000 0.886 0.739 ## fmin11 1.000 0.886 0.661 ## slp1 =~ ## fmin4 -3.000 -0.985 -0.987 ## fmin5 -2.000 -0.657 -0.698 ## fmin6 -1.000 -0.328 -0.305 ## fmin7 0.000 0.000 0.000 ## fmin8 1.000 0.328 0.262 ## fmin9 2.000 0.657 0.533 ## fmin10 3.000 0.985 0.821 ## fmin11 4.000 1.314 0.980 ## slp2 =~ ## fmin4 0.000 0.000 0.000 ## fmin5 0.000 0.000 0.000 ## fmin6 0.000 0.000 0.000 ## fmin7 0.000 0.000 0.000 ## fmin8 1.000 0.302 0.241 ## fmin9 2.000 0.604 0.491 ## fmin10 3.000 0.906 0.755 ## fmin11 4.000 1.209 0.901 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp1 0.138 0.062 2.233 0.026 0.475 0.475 ## slp2 -0.111 0.101 -1.099 0.272 -0.415 -0.415 ## slp1 ~~ ## slp2 -0.097 0.067 -1.441 0.149 -0.980 -0.980 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## int 0.216 0.062 3.495 0.000 0.244 0.244 ## slp1 0.079 0.029 2.741 0.006 0.239 0.239 ## slp2 -0.048 0.041 -1.150 0.250 -0.157 -0.157 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.069 0.388 0.178 0.859 0.069 0.069 ## .fmin5 0.221 0.190 1.161 0.246 0.221 0.250 ## .fmin6 0.539 0.103 5.231 0.000 0.539 0.466 ## .fmin7 0.570 0.156 3.653 0.000 0.570 0.420 ## .fmin8 0.731 0.129 5.671 0.000 0.731 0.464 ## .fmin9 0.605 0.099 6.108 0.000 0.605 0.399 ## .fmin10 0.450 0.123 3.664 0.000 0.450 0.312 ## .fmin11 0.722 0.172 4.191 0.000 0.722 0.401 ## int 0.786 0.151 5.215 0.000 1.000 1.000 ## slp1 0.108 0.056 1.919 0.055 1.000 1.000 ## slp2 0.091 0.094 0.968 0.333 1.000 1.000 Note that whichever approach we take, the models fit the data identically. This means that the choice between these two specifications should be guided by theoretical considerations of which type of effect you would prefer to interpret. Of course, the models we have seen thus far in this section are the simplest linear-linear piecewise functions we can specify. We could even better specify these linear pieces with additional time points, or we could potentially increase the polynomial order of one or more of the pieces. This could be a great way to model nonlinear growth followed by a plateau for instance. Below, we demonstrate a quadratic-linear piecewise function that could capture this type of growth pattern. To identify this model, we can use trial-level data from the feedback.learning dataset source, with 4 trials specifying the quadratic initial piece, and the remaining trials specifying the second linear slope. Below we show the code to fit and visualize this model. trials &lt;- read.csv(&quot;data/trials.csv&quot;) quad.rate &lt;- &quot;int =~ 1*trial.1 + 1*trial.2 + 1*trial.3 + 1*trial.4 + 1*trial.5 + 1*trial.6 + 1*trial.7 slp1 =~ -3*trial.1 + -2*trial.2 + -1*trial.3 + 0*trial.4 + 0*trial.5 + 0*trial.6 + 0*trial.7 quad =~ 9*trial.1 + 4*trial.2 + 1*trial.3 + 0*trial.4 + 0*trial.5 + 0*trial.6 + 0*trial.7 slp2 =~ 0*trial.1 + 0*trial.2 + 0*trial.3 + 0*trial.4 + 1*trial.5 + 2*trial.6 + 3*trial.7 &quot; quad.rate.fit &lt;- growth(quad.rate, data = trials, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(quad.rate.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 55 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 21 ## ## Number of observations 297 ## Number of missing patterns 2 ## ## Model Test User Model: ## ## Test statistic 46.778 ## Degrees of freedom 14 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## trial.1 1.000 0.900 0.904 ## trial.2 1.000 0.900 0.866 ## trial.3 1.000 0.900 0.821 ## trial.4 1.000 0.900 0.830 ## trial.5 1.000 0.900 0.819 ## trial.6 1.000 0.900 0.780 ## trial.7 1.000 0.900 0.718 ## slp1 =~ ## trial.1 -3.000 -0.846 -0.851 ## trial.2 -2.000 -0.564 -0.543 ## trial.3 -1.000 -0.282 -0.257 ## trial.4 0.000 0.000 0.000 ## trial.5 0.000 0.000 0.000 ## trial.6 0.000 0.000 0.000 ## trial.7 0.000 0.000 0.000 ## quad =~ ## trial.1 9.000 1.028 1.033 ## trial.2 4.000 0.457 0.440 ## trial.3 1.000 0.114 0.104 ## trial.4 0.000 0.000 0.000 ## trial.5 0.000 0.000 0.000 ## trial.6 0.000 0.000 0.000 ## trial.7 0.000 0.000 0.000 ## slp2 =~ ## trial.1 0.000 0.000 0.000 ## trial.2 0.000 0.000 0.000 ## trial.3 0.000 0.000 0.000 ## trial.4 0.000 0.000 0.000 ## trial.5 1.000 0.167 0.152 ## trial.6 2.000 0.333 0.289 ## trial.7 3.000 0.500 0.399 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp1 -0.067 0.061 -1.099 0.272 -0.264 -0.264 ## quad -0.044 0.019 -2.275 0.023 -0.426 -0.426 ## slp2 -0.001 0.024 -0.042 0.967 -0.007 -0.007 ## slp1 ~~ ## quad 0.029 0.027 1.060 0.289 0.895 0.895 ## slp2 0.007 0.023 0.292 0.770 0.140 0.140 ## quad ~~ ## slp2 0.003 0.007 0.393 0.694 0.140 0.140 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .trial.1 0.000 0.000 0.000 ## .trial.2 0.000 0.000 0.000 ## .trial.3 0.000 0.000 0.000 ## .trial.4 0.000 0.000 0.000 ## .trial.5 0.000 0.000 0.000 ## .trial.6 0.000 0.000 0.000 ## .trial.7 0.000 0.000 0.000 ## int 0.416 0.060 6.956 0.000 0.463 0.463 ## slp1 -0.052 0.052 -1.006 0.314 -0.184 -0.184 ## quad -0.065 0.017 -3.709 0.000 -0.566 -0.566 ## slp2 0.164 0.020 8.193 0.000 0.983 0.983 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .trial.1 0.350 0.115 3.047 0.002 0.350 0.354 ## .trial.2 0.285 0.036 7.954 0.000 0.285 0.265 ## .trial.3 0.311 0.039 7.983 0.000 0.311 0.259 ## .trial.4 0.365 0.049 7.506 0.000 0.365 0.311 ## .trial.5 0.370 0.037 9.896 0.000 0.370 0.307 ## .trial.6 0.414 0.044 9.298 0.000 0.414 0.311 ## .trial.7 0.517 0.071 7.249 0.000 0.517 0.329 ## int 0.810 0.091 8.930 0.000 1.000 1.000 ## slp1 0.080 0.079 1.010 0.312 1.000 1.000 ## quad 0.013 0.011 1.193 0.233 1.000 1.000 ## slp2 0.028 0.012 2.334 0.020 1.000 1.000 ggplot(data.frame(id=quad.rate.fit@Data@case.idx[[1]], lavPredict(quad.rate.fit,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;trial&quot;), names_to = c(&quot;.value&quot;, &quot;num&quot;), names_pattern = &quot;(trial).(.)&quot;) %&gt;% dplyr::mutate(trial = as.numeric(trial)), aes(x = num, y = trial, group = id, color = factor(id))) + geom_line() + labs(title = &quot;Quadradic-Linear Piecewise LCM Trajectories&quot;, x = &quot;Age&quot;, y = &quot;Predicted Externalizing Behavior&quot;) + theme(legend.position = &quot;none&quot;) To fit piecewise models in the MLM, we simply create observed variables that correspond to the factor loadings we specified in the LCM code. Below we show how to generate these observed varaiables and the syntax to fit the two-rate version of the linear-linear model. adversity.long &lt;- adversity %&gt;% pivot_longer(cols = starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(fmin)(.+)&quot;) %&gt;% mutate(age = as.numeric(age), slp1 = ifelse(age &gt; 7, 0, age - 7), slp2 = ifelse(age &lt; 7, 0, age - 7), quad = ifelse(age &gt; 7, 0, (age - 7)^2)) two.rate.mlm &lt;- lmer(fmin ~ 1 + slp1 + slp2 + (1 + slp1 + slp2 | id), na.action = na.omit, REML = TRUE, data = adversity.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(two.rate.mlm) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: fmin ~ 1 + slp1 + slp2 + (1 + slp1 + slp2 | id) ## Data: adversity.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 3565.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2040 -0.5616 -0.2004 0.4489 3.9715 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.766249 0.8754 ## slp1 0.020429 0.1429 1.00 ## slp2 0.006305 0.0794 0.42 0.42 ## Residual 0.635271 0.7970 ## Number of obs: 1240, groups: id, 398 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 0.21114 0.06180 403.53944 3.417 0.000698 *** ## slp1 0.07239 0.02774 555.66344 2.610 0.009304 ** ## slp2 0.03752 0.01968 335.58079 1.907 0.057417 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) slp1 ## slp1 0.676 ## slp2 -0.450 -0.486 ## optimizer (bobyqa) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular Fitting the piecewise model in the LCSM framework requires some additional work and unless we wish to include the dual-change effects, these models could be more-simply implemented as LCMs. This is due to a general complication in LCSMs if we wish to place the intercept anywhere except at the initial timepoint. If we look below at the Regressions Between Adjacent Observations section of the code below, we can see that for timepoints that come before the intercept (here before the knot point) we actually regression earlier timepoints on later timepoints. This reversal of the intuitive temporal order allows the LCSM to mimic the negative factor loadings in the LCM. Note also that the intercept timepoint (here pfmin7) appears twice, predicting the timepoint both before and after it. Finally, the loadings of the timepoints prior to the intercept load at a \\(-1\\) on the delta factors rather than a \\(1\\) as usual. The remainder of the model follows the conventions we are accustomed, but we comment below on the specific changes needed here. two.rate.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pfmin4 =~ 1*fmin4; fmin4 ~ 0; fmin4 ~~ fmin4; pfmin4 ~~ 0*fmin4 pfmin5 =~ 1*fmin5; fmin5 ~ 0; fmin5 ~~ fmin5; pfmin5 ~~ 0*fmin5 pfmin6 =~ 1*fmin6; fmin6 ~ 0; fmin6 ~~ fmin6; pfmin6 ~~ 0*fmin6 pfmin7 =~ 1*fmin7; fmin7 ~ 0; fmin7 ~~ fmin7; pfmin7 ~~ 0*fmin7 pfmin8 =~ 1*fmin8; fmin8 ~ 0; fmin8 ~~ fmin8; pfmin8 ~~ 0*fmin8 pfmin9 =~ 1*fmin9; fmin9 ~ 0; fmin9 ~~ fmin9; pfmin9 ~~ 0*fmin9 pfmin10 =~ 1*fmin10; fmin10 ~ 0; fmin10 ~~ fmin10; pfmin10 ~~ 0*fmin10 pfmin11 =~ 1*fmin11; fmin11 ~ 0; fmin11 ~~ fmin11; pfmin11 ~~ 0*fmin11 # Regressions Between Adjacent Observations pfmin4 ~ 1*pfmin5 # temporal order reversed before intercept pfmin5 ~ 1*pfmin6 pfmin6 ~ 1*pfmin7 pfmin8 ~ 1*pfmin7 # intercept time point appears twice pfmin9 ~ 1*pfmin8 pfmin10 ~ 1*pfmin9 pfmin11 ~ 1*pfmin10 # Define Change Latent Variables (delta) # loadings prior to the intercept are negative delta21 =~ -1*pfmin4; delta21 ~~ 0*delta21 delta32 =~ -1*pfmin5; delta32 ~~ 0*delta32 delta43 =~ -1*pfmin6; delta43 ~~ 0*delta43 # loadings after the intercept are as usual delta54 =~ 1*pfmin8; delta54 ~~ 0*delta54 delta65 =~ 1*pfmin9; delta65 ~~ 0*delta65 delta76 =~ 1*pfmin10; delta76 ~~ 0*delta76 delta87 =~ 1*pfmin11; delta87 ~~ 0*delta87 # Define Intercept and Slope int =~ 1*pfmin7 slp1 =~ 1*delta21 + 1*delta32 + 1*delta43 slp2 =~ 1*delta54 + 1*delta65 + 1*delta76 + 1*delta87 int ~ 1; slp1 ~ 1; slp2 ~ 1 slp1 ~~ slp1 slp2 ~~ slp2 int ~~ slp1 + slp2 slp1 ~~ slp2 &quot; two.rate.lcsm.fit &lt;- sem(two.rate.lcsm, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(two.rate.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 50 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 17 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 35.322 ## Degrees of freedom 27 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pfmin4 =~ ## fmin4 1.000 0.963 0.965 ## pfmin5 =~ ## fmin5 1.000 0.815 0.866 ## pfmin6 =~ ## fmin6 1.000 0.786 0.731 ## pfmin7 =~ ## fmin7 1.000 0.886 0.761 ## pfmin8 =~ ## fmin8 1.000 0.919 0.732 ## pfmin9 =~ ## fmin9 1.000 0.955 0.776 ## pfmin10 =~ ## fmin10 1.000 0.995 0.829 ## pfmin11 =~ ## fmin11 1.000 1.038 0.774 ## delta21 =~ ## pfmin4 -1.000 -0.341 -0.341 ## delta32 =~ ## pfmin5 -1.000 -0.403 -0.403 ## delta43 =~ ## pfmin6 -1.000 -0.418 -0.418 ## delta54 =~ ## pfmin8 1.000 0.074 0.074 ## delta65 =~ ## pfmin9 1.000 0.071 0.071 ## delta76 =~ ## pfmin10 1.000 0.068 0.068 ## delta87 =~ ## pfmin11 1.000 0.066 0.066 ## int =~ ## pfmin7 1.000 1.000 1.000 ## slp1 =~ ## delta21 1.000 1.000 1.000 ## delta32 1.000 1.000 1.000 ## delta43 1.000 1.000 1.000 ## slp2 =~ ## delta54 1.000 1.000 1.000 ## delta65 1.000 1.000 1.000 ## delta76 1.000 1.000 1.000 ## delta87 1.000 1.000 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pfmin4 ~ ## pfmin5 1.000 0.846 0.846 ## pfmin5 ~ ## pfmin6 1.000 0.964 0.964 ## pfmin6 ~ ## pfmin7 1.000 1.128 1.128 ## pfmin8 ~ ## pfmin7 1.000 0.965 0.965 ## pfmin9 ~ ## pfmin8 1.000 0.962 0.962 ## pfmin10 ~ ## pfmin9 1.000 0.960 0.960 ## pfmin11 ~ ## pfmin10 1.000 0.959 0.959 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .pfmin4 ~~ ## .fmin4 0.000 NaN NaN ## .pfmin5 ~~ ## .fmin5 0.000 NaN NaN ## .pfmin6 ~~ ## .fmin6 0.000 NaN NaN ## .pfmin7 ~~ ## .fmin7 0.000 NaN NaN ## .pfmin8 ~~ ## .fmin8 0.000 NaN NaN ## .pfmin9 ~~ ## .fmin9 0.000 NaN NaN ## .pfmin10 ~~ ## .fmin10 0.000 NaN NaN ## .pfmin11 ~~ ## .fmin11 0.000 NaN NaN ## int ~~ ## slp1 0.138 0.062 2.233 0.026 0.475 0.475 ## slp2 0.027 0.045 0.602 0.547 0.449 0.449 ## slp1 ~~ ## slp2 0.011 0.019 0.548 0.584 0.475 0.475 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## int 0.216 0.062 3.495 0.000 0.244 0.244 ## slp1 0.079 0.029 2.741 0.006 0.239 0.239 ## slp2 0.031 0.020 1.576 0.115 0.455 0.455 ## .pfmin4 0.000 0.000 0.000 ## .pfmin5 0.000 0.000 0.000 ## .pfmin6 0.000 0.000 0.000 ## .pfmin7 0.000 0.000 0.000 ## .pfmin8 0.000 0.000 0.000 ## .pfmin9 0.000 0.000 0.000 ## .pfmin10 0.000 0.000 0.000 ## .pfmin11 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 0.000 0.000 ## .delta65 0.000 0.000 0.000 ## .delta76 0.000 0.000 0.000 ## .delta87 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.069 0.388 0.178 0.859 0.069 0.069 ## .fmin5 0.221 0.190 1.161 0.246 0.221 0.250 ## .fmin6 0.539 0.103 5.231 0.000 0.539 0.466 ## .fmin7 0.570 0.156 3.653 0.000 0.570 0.420 ## .fmin8 0.731 0.129 5.671 0.000 0.731 0.464 ## .fmin9 0.605 0.099 6.108 0.000 0.605 0.399 ## .fmin10 0.450 0.123 3.664 0.000 0.450 0.312 ## .fmin11 0.722 0.172 4.191 0.000 0.722 0.401 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 0.000 0.000 ## .delta65 0.000 0.000 0.000 ## .delta76 0.000 0.000 0.000 ## .delta87 0.000 0.000 0.000 ## slp1 0.108 0.056 1.919 0.055 1.000 1.000 ## slp2 0.005 0.019 0.240 0.810 1.000 1.000 ## .pfmin4 0.000 0.000 0.000 ## .pfmin5 0.000 0.000 0.000 ## .pfmin6 0.000 0.000 0.000 ## .pfmin7 0.000 0.000 0.000 ## .pfmin8 0.000 0.000 0.000 ## .pfmin9 0.000 0.000 0.000 ## .pfmin10 0.000 0.000 0.000 ## .pfmin11 0.000 0.000 0.000 ## int 0.786 0.151 5.215 0.000 1.000 1.000 If we wish to include proportional change into this model, there is another additional oddity. For the beta parameters prior to the intercept, we actually create a cycle in our model (in technical terms the model is non-recursive), where the delta factor that a given phantom loads on is then regressed on that same phantom variable. The model remains identified, however, because the loading is fixed to \\(-1\\) while the proportional effect is freely estimated. The relevant syntax is below. two.rate.prop.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pfmin4 =~ 1*fmin4; fmin4 ~ 0; fmin4 ~~ fmin4; pfmin4 ~~ 0*fmin4 pfmin5 =~ 1*fmin5; fmin5 ~ 0; fmin5 ~~ fmin5; pfmin5 ~~ 0*fmin5 pfmin6 =~ 1*fmin6; fmin6 ~ 0; fmin6 ~~ fmin6; pfmin6 ~~ 0*fmin6 pfmin7 =~ 1*fmin7; fmin7 ~ 0; fmin7 ~~ fmin7; pfmin7 ~~ 0*fmin7 pfmin8 =~ 1*fmin8; fmin8 ~ 0; fmin8 ~~ fmin8; pfmin8 ~~ 0*fmin8 pfmin9 =~ 1*fmin9; fmin9 ~ 0; fmin9 ~~ fmin9; pfmin9 ~~ 0*fmin9 pfmin10 =~ 1*fmin10; fmin10 ~ 0; fmin10 ~~ fmin10; pfmin10 ~~ 0*fmin10 pfmin11 =~ 1*fmin11; fmin11 ~ 0; fmin11 ~~ fmin11; pfmin11 ~~ 0*fmin11 # Regressions Between Adjacent Observations pfmin4 ~ 1*pfmin5 # temporal order reversed before intercept pfmin5 ~ 1*pfmin6 pfmin6 ~ 1*pfmin7 pfmin8 ~ 1*pfmin7 # intercept time point appears twice pfmin9 ~ 1*pfmin8 pfmin10 ~ 1*pfmin9 pfmin11 ~ 1*pfmin10 # Define Change Latent Variables (delta) # loadings prior to the intercept are negative delta21 =~ -1*pfmin4; delta21 ~~ 0*delta21 delta32 =~ -1*pfmin5; delta32 ~~ 0*delta32 delta43 =~ -1*pfmin6; delta43 ~~ 0*delta43 # loadings after the intercept are as usual delta54 =~ 1*pfmin8; delta54 ~~ 0*delta54 delta65 =~ 1*pfmin9; delta65 ~~ 0*delta65 delta76 =~ 1*pfmin10; delta76 ~~ 0*delta76 delta87 =~ 1*pfmin11; delta87 ~~ 0*delta87 # Define Proportional Change Regressions (beta = equality constraint) # Non-recursive Proportional Paths delta21 ~ beta*pfmin4 delta32 ~ beta*pfmin5 delta43 ~ beta*pfmin6 # Standard Proportional Paths delta54 ~ beta*pfmin7 delta65 ~ beta*pfmin8 delta76 ~ beta*pfmin9 delta87 ~ beta*pfmin10 # Define Intercept and Slope int =~ 1*pfmin7 slp1 =~ 1*delta21 + 1*delta32 + 1*delta43 slp2 =~ 1*delta54 + 1*delta65 + 1*delta76 + 1*delta87 int ~ 1; slp1 ~ 1; slp2 ~ 1 slp1 ~~ slp1 slp2 ~~ slp2 int ~~ slp1 + slp2 slp1 ~~ slp2 &quot; two.rate.prop.lcsm.fit &lt;- sem(two.rate.prop.lcsm, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(two.rate.prop.lcsm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 773 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 24 ## Number of equality constraints 6 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 34.156 ## Degrees of freedom 26 ## P-value (Chi-square) 0.131 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pfmin4 =~ ## fmin4 1.000 0.763 0.741 ## pfmin5 =~ ## fmin5 1.000 0.747 0.800 ## pfmin6 =~ ## fmin6 1.000 0.741 0.705 ## pfmin7 =~ ## fmin7 1.000 0.881 0.747 ## pfmin8 =~ ## fmin8 1.000 0.893 0.720 ## pfmin9 =~ ## fmin9 1.000 0.919 0.757 ## pfmin10 =~ ## fmin10 1.000 0.974 0.820 ## pfmin11 =~ ## fmin11 1.000 1.070 0.779 ## delta21 =~ ## pfmin4 -1.000 -0.103 -0.103 ## delta32 =~ ## pfmin5 -1.000 -0.242 -0.242 ## delta43 =~ ## pfmin6 -1.000 -0.560 -0.560 ## delta54 =~ ## pfmin8 1.000 NA NA ## delta65 =~ ## pfmin9 1.000 NA NA ## delta76 =~ ## pfmin10 1.000 NA NA ## delta87 =~ ## pfmin11 1.000 NA NA ## int =~ ## pfmin7 1.000 1.000 1.000 ## slp1 =~ ## delta21 1.000 12.917 12.917 ## delta32 1.000 5.618 5.618 ## delta43 1.000 2.444 2.444 ## slp2 =~ ## delta54 1.000 NA NA ## delta65 1.000 NA NA ## delta76 1.000 NA NA ## delta87 1.000 NA NA ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## pfmin4 ~ ## pfmin5 1.000 0.979 0.979 ## pfmin5 ~ ## pfmin6 1.000 0.992 0.992 ## pfmin6 ~ ## pfmin7 1.000 1.189 1.189 ## pfmin8 ~ ## pfmin7 1.000 0.986 0.986 ## pfmin9 ~ ## pfmin8 1.000 0.971 0.971 ## pfmin10 ~ ## pfmin9 1.000 0.944 0.944 ## pfmin11 ~ ## pfmin10 1.000 0.910 0.910 ## delta21 ~ ## pfmin4 (beta) 1.299 1.790 0.725 0.468 12.627 12.627 ## delta32 ~ ## pfmin5 (beta) 1.299 1.790 0.725 0.468 5.377 5.377 ## delta43 ~ ## pfmin6 (beta) 1.299 1.790 0.725 0.468 2.320 2.320 ## delta54 ~ ## pfmin7 (beta) 1.299 1.790 0.725 0.468 NA NA ## delta65 ~ ## pfmin8 (beta) 1.299 1.790 0.725 0.468 NA NA ## delta76 ~ ## pfmin9 (beta) 1.299 1.790 0.725 0.468 NA NA ## delta87 ~ ## pfmin10 (beta) 1.299 1.790 0.725 0.468 NA NA ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .pfmin4 ~~ ## .fmin4 0.000 NaN NaN ## .pfmin5 ~~ ## .fmin5 0.000 NaN NaN ## .pfmin6 ~~ ## .fmin6 0.000 NaN NaN ## .pfmin7 ~~ ## .fmin7 0.000 NaN NaN ## .pfmin8 ~~ ## .fmin8 0.000 NaN NaN ## .pfmin9 ~~ ## .fmin9 0.000 NaN NaN ## .pfmin10 ~~ ## .fmin10 0.000 NaN NaN ## .pfmin11 ~~ ## .fmin11 0.000 NaN NaN ## int ~~ ## slp1 -0.550 0.925 -0.594 0.552 -0.615 -0.615 ## slp2 -0.997 1.445 -0.690 0.490 -1.000 -1.000 ## slp1 ~~ ## slp2 0.713 2.177 0.327 0.743 0.621 0.621 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## int 0.212 0.058 3.626 0.000 0.241 0.241 ## slp1 -0.026 0.156 -0.165 0.869 -0.025 -0.025 ## slp2 -0.265 0.410 -0.647 0.518 -0.234 -0.234 ## .pfmin4 0.000 0.000 0.000 ## .pfmin5 0.000 0.000 0.000 ## .pfmin6 0.000 0.000 0.000 ## .pfmin7 0.000 0.000 0.000 ## .pfmin8 0.000 0.000 0.000 ## .pfmin9 0.000 0.000 0.000 ## .pfmin10 0.000 0.000 0.000 ## .pfmin11 0.000 0.000 0.000 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 NA NA ## .delta65 0.000 NA NA ## .delta76 0.000 NA NA ## .delta87 0.000 NA NA ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.478 0.284 1.685 0.092 0.478 0.451 ## .fmin5 0.315 0.203 1.550 0.121 0.315 0.361 ## .fmin6 0.555 0.112 4.945 0.000 0.555 0.502 ## .fmin7 0.613 0.118 5.190 0.000 0.613 0.441 ## .fmin8 0.743 0.136 5.478 0.000 0.743 0.482 ## .fmin9 0.630 0.102 6.191 0.000 0.630 0.427 ## .fmin10 0.463 0.121 3.840 0.000 0.463 0.328 ## .fmin11 0.742 0.500 1.483 0.138 0.742 0.393 ## .delta21 0.000 0.000 0.000 ## .delta32 0.000 0.000 0.000 ## .delta43 0.000 0.000 0.000 ## .delta54 0.000 NA NA ## .delta65 0.000 NA NA ## .delta76 0.000 NA NA ## .delta87 0.000 NA NA ## slp1 1.029 2.469 0.417 0.677 1.000 1.000 ## slp2 1.281 3.663 0.350 0.726 1.000 1.000 ## .pfmin4 0.000 0.000 0.000 ## .pfmin5 0.000 0.000 0.000 ## .pfmin6 0.000 0.000 0.000 ## .pfmin7 0.000 0.000 0.000 ## .pfmin8 0.000 0.000 0.000 ## .pfmin9 0.000 0.000 0.000 ## .pfmin10 0.000 0.000 0.000 ## .pfmin11 0.000 0.000 0.000 ## int 0.776 0.114 6.816 0.000 1.000 1.000 Nonlinear Trajectories However, we sometimes need to move beyond well-defined polynomial models in order to capture the complexity of developmental change over time and consider truly nonlinear trajectories. This is most common in applications with dense observations within-person or that cover wide (i.e., decades) age-ranges between-person, although we can model true nonlinearities in standard applications with 4-6 timepoints. GAMMs will shine in the former case, while LCMs and LCSMs offer some options for the latter. We can start with the GAMM syntax we are familiar with to specify a nonlinear trend across ages \\(8-28\\) in the feedback.learning data. gamm &lt;- gamm4(scale(modularity) ~ 1 + s(age), random = ~ (1 | id), data = feedback.learning) gamtabs(gamm$gam, type = &quot;html&quot;, pnames = c(&quot;Intercept&quot;), snames = c(&quot;s(Age)&quot;), caption = &quot;Modularity as a Function of Age&quot;) ## &lt;!-- html table generated in R 4.1.1 by xtable 1.8-4 package --&gt; ## &lt;!-- Thu Aug 18 18:25:06 2022 --&gt; ## &lt;table border=1&gt; ## &lt;caption align=&quot;bottom&quot;&gt; Modularity as a Function of Age &lt;/caption&gt; ## &lt;tr&gt; &lt;td&gt; A. parametric coefficients &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; Estimate &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; Std. Error &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; t-value &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; p-value &lt;/td&gt; &lt;/tr&gt; ## &lt;tr&gt; &lt;td&gt; Intercept &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; -0.0095 &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; 0.0464 &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; -0.2052 &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; 0.8375 &lt;/td&gt; &lt;/tr&gt; ## &lt;tr&gt; &lt;td&gt; B. smooth terms &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; edf &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; Ref.df &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; F-value &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; p-value &lt;/td&gt; &lt;/tr&gt; ## &lt;tr&gt; &lt;td&gt; s(Age) &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; 4.6471 &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; 4.6471 &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; 28.1838 &lt;/td&gt; &lt;td align=&quot;right&quot;&gt; &amp;lt; 0.0001 &lt;/td&gt; &lt;/tr&gt; ## &lt;a name=tab.gam&gt;&lt;/a&gt; ## &lt;/table&gt; plot.gam(gamm$gam, se = TRUE, rug = TRUE, shade = TRUE, xlab = &quot;Age&quot;, ylab = &quot;Fitted Modularity Values&quot;) Nothing as changed about this model from what we have seen previously because the GAMM intrinsically captures non-linearities through the use of the splines. In principle, given the functional form that is revealed, these data might also be fit with a quadratic polynomial (indeed in McCormick et al., 2021, NeuroImage: see main analyses versus supplemental GAMMs as a sensitivity check). Indeed these models might be a nice tool for this purpose to check the reasonableness of the functional form specified in more restrictive polynomial models, even if we retain the polynomials for interpretability. With expanding age ranges, this type of sensitivity check becomes increasingly important, since the non-linearities of the GAMM are a better theoretical match for the complex patterns of growth across the lifespan. While deceptively simple in their implementation (indeed this is the exact same model we keep fitting), GAMMS are a powerful and flexible tool for fitting developmental trajectories. The SEMs also allow for the inclusion of some nonlinear terms. Like the GAMM, we have already seen the most common nonlinearity through the proportional change parameter of the LCSM. We include the code and output for this model below but otherwise will not explore it further here. executive.function &lt;- read.csv(&quot;data/executive-function.csv&quot;, header = TRUE) %&gt;% select(id, dlpfc1:dlpfc4) proportional.lcsm &lt;- &quot; # Define Phantom Variables (p = phantom) pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (delta) delta21 =~ 1*pdlpfc2; delta21 ~~ 0*delta21 delta32 =~ 1*pdlpfc3; delta32 ~~ 0*delta32 delta43 =~ 1*pdlpfc4; delta43 ~~ 0*delta43 # Define Proportional Change Regressions (beta = equality constraint) delta21 ~ beta*pdlpfc1 delta32 ~ beta*pdlpfc2 delta43 ~ beta*pdlpfc3 # Define Intercept and Slope int =~ 1*pdlpfc1 slp =~ 1*delta21 + 1*delta32 + 1*delta43 int ~ 1 slp ~ 1 int ~~ slp slp ~~ slp &quot; lcsm.proportional &lt;- sem(proportional.lcsm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcsm.proportional) ## lavaan 0.6-12 ended normally after 32 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## Number of equality constraints 2 ## ## Number of observations 342 ## Number of missing patterns 8 ## ## Model Test User Model: ## ## Test statistic 1.132 ## Degrees of freedom 4 ## P-value (Chi-square) 0.889 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## pdlpfc1 =~ ## dlpfc1 1.000 ## pdlpfc2 =~ ## dlpfc2 1.000 ## pdlpfc3 =~ ## dlpfc3 1.000 ## pdlpfc4 =~ ## dlpfc4 1.000 ## delta21 =~ ## pdlpfc2 1.000 ## delta32 =~ ## pdlpfc3 1.000 ## delta43 =~ ## pdlpfc4 1.000 ## int =~ ## pdlpfc1 1.000 ## slp =~ ## delta21 1.000 ## delta32 1.000 ## delta43 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## pdlpfc2 ~ ## pdlpfc1 1.000 ## pdlpfc3 ~ ## pdlpfc2 1.000 ## pdlpfc4 ~ ## pdlpfc3 1.000 ## delta21 ~ ## pdlpfc1 (beta) -0.090 0.276 -0.325 0.745 ## delta32 ~ ## pdlpfc2 (beta) -0.090 0.276 -0.325 0.745 ## delta43 ~ ## pdlpfc3 (beta) -0.090 0.276 -0.325 0.745 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.074 0.162 -0.457 0.647 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int 0.540 0.054 9.994 0.000 ## slp 0.179 0.183 0.981 0.326 ## .pdlpfc1 0.000 ## .pdlpfc2 0.000 ## .pdlpfc3 0.000 ## .pdlpfc4 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .dlpfc1 0.208 0.102 2.043 0.041 ## .pdlpfc1 0.000 ## .dlpfc2 0.573 0.058 9.820 0.000 ## .pdlpfc2 0.000 ## .dlpfc3 0.577 0.060 9.570 0.000 ## .pdlpfc3 0.000 ## .dlpfc4 0.413 0.095 4.358 0.000 ## .pdlpfc4 0.000 ## .delta21 0.000 ## .delta32 0.000 ## .delta43 0.000 ## slp 0.079 0.016 4.970 0.000 ## int 0.796 0.115 6.925 0.000 However, the LCM offers an unique opportunity to model non-linear trends by throwing back to its roots in confirmatory factor analysis. Instead of specifying factor loadings, as we have done up to this point, we can allow a subset of them to be freely-estimated. This means that equal change is estimated between each timepoint, growth can accelerate and decelerate across different increments. However, to identify the growth model, we have to set at least two of the factor loadings to pre-specified values (\\(0\\) and \\(1\\)) to set the scale for the other factor loadings. In general, there are two reasonable specifications. In the first, we set the first loading to \\(0\\) and the second to \\(1\\). This means that the other factor loadings are proportional to the amount of change that occurs between the first and second time point. We can see this specification below. free.load1 &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 basis =~ 0*fmin4 + 1*fmin5 + l3*fmin6 + l4*fmin7 + l5*fmin8 + l6*fmin9 + l7*fmin10 + l8*fmin11 &quot; free.load1.fit &lt;- growth(free.load1, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(free.load1.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 167 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 19 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 22.185 ## Degrees of freedom 25 ## P-value (Chi-square) 0.625 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fmin4 1.000 0.600 0.591 ## fmin5 1.000 0.600 0.649 ## fmin6 1.000 0.600 0.549 ## fmin7 1.000 0.600 0.517 ## fmin8 1.000 0.600 0.468 ## fmin9 1.000 0.600 0.511 ## fmin10 1.000 0.600 0.531 ## fmin11 1.000 0.600 0.431 ## basis =~ ## fmin4 0.000 0.000 0.000 ## fmin5 1.000 0.043 0.046 ## fmin6 (l3) 10.433 29.658 0.352 0.725 0.446 0.408 ## fmin7 (l4) 10.668 29.930 0.356 0.722 0.456 0.393 ## fmin8 (l5) 14.511 41.748 0.348 0.728 0.621 0.484 ## fmin9 (l6) 10.347 28.955 0.357 0.721 0.443 0.377 ## fmin10 (l7) 10.041 28.272 0.355 0.722 0.429 0.380 ## fmin11 (l8) 22.493 65.845 0.342 0.733 0.962 0.691 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## basis 0.006 0.018 0.355 0.723 0.246 0.246 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## int -0.011 0.068 -0.155 0.876 -0.018 -0.018 ## basis 0.021 0.064 0.332 0.740 0.500 0.500 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.671 0.134 5.021 0.000 0.671 0.651 ## .fmin5 0.480 0.114 4.203 0.000 0.480 0.562 ## .fmin6 0.505 0.101 5.008 0.000 0.505 0.422 ## .fmin7 0.642 0.097 6.632 0.000 0.642 0.478 ## .fmin8 0.716 0.146 4.911 0.000 0.716 0.436 ## .fmin9 0.691 0.094 7.340 0.000 0.691 0.502 ## .fmin10 0.606 0.107 5.656 0.000 0.606 0.475 ## .fmin11 0.368 0.215 1.712 0.087 0.368 0.190 ## int 0.360 0.109 3.292 0.001 1.000 1.000 ## basis 0.002 0.011 0.167 0.867 1.000 1.000 Here we label the freely-estimated factor loadings for convenient reference. We also specify the second factor as a basis (or sometimes “shape”) rather than a “slope” factor to reflect the non-linearity inherent in this model. When we examine the model results, we can see a pretty striking pattern of factor loadings. The third loading (l3) is \\(10.43\\), which suggests that more than \\(9\\) times the amount of change occurs between the second and third timepoints as does between the first two (remember we take the difference between adjacent loadings). However, l4 suggests that then there is a sharp deceleration in growth between the next timepoints. At l6, we can see that the factor loading actuall decreases, which is how this model fits a negative trend between adjacent timepoints. Finally, l8 suggests a large increase at the final timepoint, reversing the earlier decreases. One thing to highlight is the increase in complexity just in describing the factor loadings and interpreting adjacent timepoints that do not follow some monotonic trend. Like many non-linear models, visualization of the model-implied trajectories is key for interpreting the effects. We can do so below. ggplot(data.frame(id=free.load1.fit@Data@case.idx[[1]], lavPredict(free.load1.fit,type=&quot;ov&quot;)) %&gt;% pivot_longer(cols = starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(fmin)(.+)&quot;) %&gt;% dplyr::mutate(age = as.numeric(age)), aes(x = age, y = fmin, group = id, color = factor(id))) + geom_line() + labs(title = &quot;Free-loading Model 1 Trajectories&quot;, x = &quot;Age&quot;, y = &quot;Predicted Forceps Minor Microstructure&quot;) + theme(legend.position = &quot;none&quot;) Here we can see the power, and danger, of these free-loading model. Like a GAMM, we can have complex, localized change, with reversals and highly variable slopes. However, in looking at the first couple of timepoints, we have to wonder if we are overfitting noise in the data when some simpler functional form would (e.g., a line) would describe this trend in a more replicable/generalizable way. Very often, these free-loading models will fit the data better than many alternatives we have discussed elsewhere in this primer, but then be very sample-depenedent in an unsatisfying fashion. Like with the GAMM, one potential use for this model is as a sensitivity check for a more-constrained LCM to ensure we are not completely botching the functional form. We can refit this model using a different specification where we set the first loading to \\(0\\) and the last loading to \\(1\\). This scales the estimated loadings to be proportions of the total growth realized by that point. We can see this model below. free.load2 &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 basis =~ 0*fmin4 + l2*fmin5 + l3*fmin6 + l4*fmin7 + l5*fmin8 + l6*fmin9 + l7*fmin10 + 1*fmin11 &quot; free.load2.fit &lt;- growth(free.load2, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(free.load2.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 50 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 19 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 22.185 ## Degrees of freedom 25 ## P-value (Chi-square) 0.625 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fmin4 1.000 0.600 0.591 ## fmin5 1.000 0.600 0.649 ## fmin6 1.000 0.600 0.549 ## fmin7 1.000 0.600 0.517 ## fmin8 1.000 0.600 0.468 ## fmin9 1.000 0.600 0.511 ## fmin10 1.000 0.600 0.531 ## fmin11 1.000 0.600 0.431 ## basis =~ ## fmin4 0.000 0.000 0.000 ## fmin5 (l2) 0.044 0.130 0.342 0.733 0.043 0.046 ## fmin6 (l3) 0.464 0.117 3.962 0.000 0.446 0.408 ## fmin7 (l4) 0.474 0.118 4.036 0.000 0.456 0.393 ## fmin8 (l5) 0.645 0.141 4.564 0.000 0.621 0.484 ## fmin9 (l6) 0.460 0.121 3.800 0.000 0.443 0.377 ## fmin10 (l7) 0.446 0.148 3.024 0.002 0.429 0.380 ## fmin11 1.000 0.962 0.691 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## basis 0.142 0.168 0.842 0.400 0.246 0.246 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## int -0.011 0.068 -0.155 0.876 -0.018 -0.018 ## basis 0.481 0.102 4.729 0.000 0.500 0.500 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.671 0.134 5.021 0.000 0.671 0.651 ## .fmin5 0.480 0.114 4.203 0.000 0.480 0.562 ## .fmin6 0.505 0.101 5.008 0.000 0.505 0.422 ## .fmin7 0.642 0.097 6.632 0.000 0.642 0.478 ## .fmin8 0.716 0.146 4.911 0.000 0.716 0.436 ## .fmin9 0.691 0.094 7.340 0.000 0.691 0.502 ## .fmin10 0.606 0.107 5.656 0.000 0.606 0.475 ## .fmin11 0.368 0.215 1.712 0.087 0.368 0.190 ## int 0.360 0.109 3.292 0.001 1.000 1.000 ## basis 0.925 0.385 2.404 0.016 1.000 1.000 We can see that the loadings are now all less than \\(1\\) but that they follow the same pattern as in the model (which they should, as they are identically-fitting models). However, now the loadings are expressed as percentages of the total change that occurs between the first and final timepoint. Note one odd thing is that when a trajectory follows a parabolic shape, we can get loadings about \\(1\\) reflecting \\(&gt;100%\\) of the overall change has occurred by that time point. Nothing is wrong, per se, with that interpretation, but given the oddness of language it evokes, the first specification is by far the more common. Fixed and Random Effects Before we move on, we want to highlight the distinction we make between fixed and random effects when we talk about the limitations of the functional form with respect to the number of repeated measures, per person. The oft-repeated mantra is that you need \\(3\\) timepoints for a line, \\(4\\) for a quadratic, and so on ad infinitum. But, on the other hand, we can fit a highly complex non-linear developmental trajectory to data where each individual contributes at most \\(2\\) timepoints. How do we reconcile these two things? Well it has to do with whether we treat the effect in question as fixed or random. When we treat a parameter as fixed, we obtain a single value that describes all indiviudals in our sample (barring pesky things like interactions), but when we treat an effect as random, we also model individual differences in that “fixed” parameter (note that we estimate a single variance per random effect, not individual effects, but that’s a longer discussion and we can calculate individual effects with some well-developed methods). So to estimate these individually-varying random effects, we need more repeated measures within-person. However, we can still estimate an overall fixed effect trajectory that takes advantage of greater timepoints between individuals than exist for any given individual. This is how we might estimate a GAMM with some highly complex surface, even though we could never estimate a random effect for any individual since they only contribute up to two observations. We can demonstrate this with our feedback.learning data where we can model both the effect of wave, which is a fully within-person measure, as well as linear and quadratic age. These latter two effects are specified as fixed effects because while age between-person ranges from \\(8 - 29\\), no one person contributes more than \\(3\\) time points, so the quadratic random effect would not be estimable. However, we can estimate a random effect of wave. We can see these effects below. This distinction highlights some of the advantages of having measurement timing heterogeneity for estimating more complex effect than one could do with single-cohort data with fully consistent assessment schedules. feedback.learning &lt;- read.csv(&quot;data/feedback-learning.csv&quot;) %&gt;% select(id, wave, age, modularity, learning.rate) fixrand &lt;- lmer(scale(modularity) ~ 1 + wave + age + I(age^2) + (1 + wave | id), na.action = na.omit, REML = TRUE, data = feedback.learning) summary(fixrand, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: scale(modularity) ~ 1 + wave + age + I(age^2) + (1 + wave | id) ## Data: feedback.learning ## ## REML criterion at convergence: 1852.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.04443 -0.56388 0.00211 0.54870 2.45150 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.42472 0.6517 ## wave 0.01452 0.1205 0.00 ## Residual 0.36813 0.6067 ## Number of obs: 754, groups: id, 297 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -4.653017 0.450546 424.620702 -10.328 &lt; 2e-16 *** ## wave -0.021516 0.038502 499.253403 -0.559 0.577 ## age 0.517778 0.055054 451.217127 9.405 &lt; 2e-16 *** ## I(age^2) -0.013251 0.001576 467.828242 -8.410 4.99e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 "],["05-covariates.html", "Covariates and Distal Outcomes Covariates Distal Outcomes", " Covariates and Distal Outcomes Thus far, we have only considered unconditional growth models. This is somewhat of a misnomer because clearly time is included as a predictor, but that is considered integral to the growth model so we tend not to count it as a conditional model (as with many terminological things in quant: shrugs). What we will do in this section is bring in additional variables to our growth model as predictors. These covariates will either predict the parameters of the growth process (i.e., intercept and slope) or the individual repeated measures directly (some models will allow a single covariate to do both simultaneously). We will read in the relevant data sets below. adversity &lt;- read.csv(&quot;data/adversity.csv&quot;, header = TRUE) executive.function &lt;- read.csv(&quot;data/executive-function.csv&quot;, header = TRUE) Covariates Time Invariant Covariates We will begin with the relatively straightforward time-invariant covariate (TIC). These covariates operate at the level of the growth process: meaning that they predict the random effects (MEMs) or latent factors (SEMs). As the name implies, we will have a single value of each TIC per individual. While we often obtain that value at the first observation, in theory we could have measured that variable at any time and we should get the same value (otherwise it isn’t time-invariant, is it?). One common misconception is that there is any temporal ordering inherent at this level of the model. The TIC and the intercept/slope parameters are time-invariant and so we cannot establish temporal precedence unless we bring other knowledge of the data to bear (e.g., the TIC measures something early in life and the growth parameters are fit to adolescent data). This is the same reason why regressing the slope of one outcome on the intercept of the other is very theoretically dubious unless the growth processes are truly separated in time. At this level, we essentially have cross-sectional regressions (again unless we know something extra about our variables temporally). As such, inclusion of TICs is relatively simple compared with what we will consider for the remainder of this section. We will demonstrate our examples in the MLM and LCM because of the relatively simple syntax, but the principles extend naturally to the GAMM and LCSM. Below we can expand our unconditional growth of fmin to include an early life experience variable. Here we will begin with the multilevel model. Including a TIC is trivially easy from a model syntax standpoint. We can add our early life experience variable (neglect) into the fixed effect just as we have done for age. Even though these variables operate at different levels of the model (age is a level 1 variable and neglect is a level 2 variable) there is no need to differentiate them in the model syntax. We will need to keep track of these different levels of effect in our interpretation but the model really operates at a single reduced-form level and our syntax reflects that fact. adversity.long &lt;- adversity %&gt;% pivot_longer(cols = starts_with(&quot;fmin&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(fmin)(.+)&quot;) %&gt;% mutate(age = as.numeric(age)) %&gt;% drop_na(fmin) tic.mlm &lt;- lmer(fmin ~ 1 + age + neglect + (1 + age | id), na.action = na.omit, REML = TRUE, data = adversity.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(tic.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: fmin ~ 1 + age + neglect + (1 + age | id) ## Data: adversity.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 3544 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.4004 -0.5309 -0.1831 0.4462 3.7548 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.26613 0.5159 ## age 0.01086 0.1042 -0.31 ## Residual 0.62111 0.7881 ## Number of obs: 1240, groups: id, 398 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.17524 0.08671 320.73547 -2.021 0.0441 * ## age 0.05101 0.01199 291.23548 4.256 2.81e-05 *** ## neglect -0.10133 0.01911 397.77909 -5.301 1.91e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Here we can see that there is a positive effect of age, reflecting general increases in FA values across age. Conversely, there is a negative between-person effect of neglect, with those experiencing greater levels of early childhood neglect showing reduced levels of white matter FA in the forceps minor (fmin). Note that this is a prediction of level, not of slopes. We will return to this in a bit when we consider cross-level interactions. The corresponding model in the LCM is similarly straightforward. tic.lcm &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 int ~ neglect&quot; tic.lcm.fit &lt;- growth(tic.lcm, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(tic.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 29 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 49.965 ## Degrees of freedom 39 ## P-value (Chi-square) 0.112 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## fmin4 1.000 ## fmin5 1.000 ## fmin6 1.000 ## fmin7 1.000 ## fmin8 1.000 ## fmin9 1.000 ## fmin10 1.000 ## fmin11 1.000 ## slp =~ ## fmin4 0.000 ## fmin5 1.000 ## fmin6 2.000 ## fmin7 3.000 ## fmin8 4.000 ## fmin9 5.000 ## fmin10 6.000 ## fmin11 7.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~ ## neglect -0.101 0.019 -5.352 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .fmin4 0.000 ## .fmin5 0.000 ## .fmin6 0.000 ## .fmin7 0.000 ## .fmin8 0.000 ## .fmin9 0.000 ## .fmin10 0.000 ## .fmin11 0.000 ## .int 0.026 0.052 0.502 0.616 ## slp 0.049 0.012 3.997 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .fmin4 0.578 0.107 5.380 0.000 ## .fmin5 0.433 0.072 5.998 0.000 ## .fmin6 0.598 0.099 6.032 0.000 ## .fmin7 0.682 0.092 7.434 0.000 ## .fmin8 0.796 0.123 6.459 0.000 ## .fmin9 0.623 0.095 6.592 0.000 ## .fmin10 0.393 0.111 3.543 0.000 ## .fmin11 0.575 0.120 4.791 0.000 ## .int 0.402 0.059 6.835 0.000 ## slp 0.017 0.003 5.031 0.000 This syntax highlights the idea that our TIC is only predicting the intercept (i.e., level). We will extend this model later. However, there are two potential extensions of the TIC model in the SEM that we can consider here. One concerns missing data on our exogenous TIC. For reasons (the reasons aren’t particularly important for our purposes), the standard estimator for SEMs in most software is a conditional estimator, which is the same used in MLMs. The upshot of this estimator is that we cannot accomodate any missing data on exogenous variables (i.e, variables that only act as predictors) in the model. With this estimator any individual with missing observations on the exogenous variable will simply be dropped from the model. We can see this below where we predict the intercept by maternal warmth in early childhood (warmth). joint.lik &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 int ~ warmth&quot; joint.lik.fit &lt;- growth(joint.lik, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(joint.lik.fit, fit.measures = FALSE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 27 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 55.165 ## Degrees of freedom 39 ## P-value (Chi-square) 0.045 We can see that while the dataset has a total of \\(398\\) individuals, only \\(361\\) are being used in the actual model fit. While in the MLM, this would be the price of admission, in the SEM we can utilize the joint rather than the conditional likelihood which instead estimates a mean and variance for the exogenous variable (essentially treating it as an endogenous variable with no predictors). There are two ways to accomplish this. In general, we can simply explicitly include a variance and intercept term for the exogenous variable(s) in the model syntax (this works across programs). We can see this below. joint.lik &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 int ~ warmth warmth ~~ warmth warmth ~ 1&quot; joint.lik.fit &lt;- growth(joint.lik, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(joint.lik.fit, fit.measures = FALSE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 27 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 15 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 55.165 ## Degrees of freedom 39 ## P-value (Chi-square) 0.045 In lavaan we have the additional option to use the argument fixed.x = FALSE which will accomplish the same thing without the additional lines of syntax. joint.lik &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 int ~ warmth&quot; joint.lik.fit &lt;- growth(joint.lik, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;, fixed.x = FALSE) summary(joint.lik.fit, fit.measures = FALSE, estimates = FALSE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 27 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 14 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 56.625 ## Degrees of freedom 40 ## P-value (Chi-square) 0.043 In both instances, we can see that the model utilizes all observations rather than only those with non-missing values on warmth. One particular application where this may be of interest is when doing a larger behavioral study with a smaller neuroimaging component. If the brain measures are predictors, than the joint likelihood approach allows us to estimate the behavioral parameters from the larger dataset when including brain-based variables. Another unique strength of SEMs is the ability to leverage the power of latent variables at all levels of the model. Observed TICs are by-far the most common application of these models, but there is nothing stopping us from attenuating measurement error in the TIC as well using a measurement model. We can see this below where we regress the intercept on a latent measure of cognitive stimulation in the home (measured by observed variables: cog1 - cog4). Unlike the growth-related latent variables, here we allow the factor loadings on the latent cog variable to be freely-estimated. latent.tic &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 cog =~ cog1 + cog2 + cog3 + cog4 cog ~~ 1*cog cog ~ 0*1 int ~ cog&quot; latent.tic.fit &lt;- growth(latent.tic, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(latent.tic.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 29 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 21 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 133.445 ## Degrees of freedom 69 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fmin4 1.000 0.710 0.692 ## fmin5 1.000 0.710 0.735 ## fmin6 1.000 0.710 0.664 ## fmin7 1.000 0.710 0.620 ## fmin8 1.000 0.710 0.574 ## fmin9 1.000 0.710 0.577 ## fmin10 1.000 0.710 0.589 ## fmin11 1.000 0.710 0.520 ## slp =~ ## fmin4 0.000 0.000 0.000 ## fmin5 1.000 0.134 0.139 ## fmin6 2.000 0.268 0.251 ## fmin7 3.000 0.402 0.351 ## fmin8 4.000 0.536 0.434 ## fmin9 5.000 0.670 0.544 ## fmin10 6.000 0.804 0.667 ## fmin11 7.000 0.938 0.687 ## cog =~ ## cog1 1.000 1.000 0.756 ## cog2 0.452 0.084 5.397 0.000 0.452 0.404 ## cog3 0.574 0.095 6.043 0.000 0.574 0.500 ## cog4 0.588 0.098 5.992 0.000 0.588 0.514 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~ ## cog 0.331 0.078 4.268 0.000 0.466 0.466 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## slp ~~ ## cog -0.020 0.018 -1.100 0.271 -0.147 -0.147 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## cog 0.000 0.000 0.000 ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## .cog1 0.000 0.000 0.000 ## .cog2 0.000 0.000 0.000 ## .cog3 0.000 0.000 0.000 ## .cog4 0.000 0.000 0.000 ## .int 0.040 0.052 0.762 0.446 0.056 0.056 ## slp 0.048 0.012 3.878 0.000 0.356 0.356 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## cog 1.000 1.000 1.000 ## .fmin4 0.548 0.107 5.132 0.000 0.548 0.521 ## .fmin5 0.425 0.073 5.837 0.000 0.425 0.455 ## .fmin6 0.593 0.099 5.986 0.000 0.593 0.519 ## .fmin7 0.684 0.092 7.439 0.000 0.684 0.522 ## .fmin8 0.789 0.122 6.451 0.000 0.789 0.516 ## .fmin9 0.628 0.095 6.608 0.000 0.628 0.414 ## .fmin10 0.379 0.109 3.466 0.001 0.379 0.261 ## .fmin11 0.573 0.121 4.748 0.000 0.573 0.307 ## .cog1 0.750 0.124 6.036 0.000 0.750 0.428 ## .cog2 1.051 0.084 12.504 0.000 1.051 0.837 ## .cog3 0.990 0.093 10.672 0.000 0.990 0.750 ## .cog4 0.963 0.095 10.171 0.000 0.963 0.736 ## .int 0.395 0.061 6.461 0.000 0.783 0.783 ## slp 0.018 0.003 5.199 0.000 1.000 1.000 You might wonder why bother estimating a new latent variable rather than simply summing up the cog items and regressing the intercept on the observed measure. Well we can do this below and compare the results to the latent TIC approach. adversity = adversity %&gt;% mutate(cog = cog1 + cog2 + cog3 + cog4) obs.tic &lt;- &quot;int =~ 1*fmin4 + 1*fmin5 + 1*fmin6 + 1*fmin7 + 1*fmin8 + 1*fmin9 + 1*fmin10 + 1*fmin11 slp =~ 0*fmin4 + 1*fmin5 + 2*fmin6 + 3*fmin7 + 4*fmin8 + 5*fmin9 + 6*fmin10 + 7*fmin11 int ~ cog&quot; obs.tic.fit &lt;- growth(obs.tic, data = adversity, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(obs.tic.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 26 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Number of observations 398 ## Number of missing patterns 40 ## ## Model Test User Model: ## ## Test statistic 49.911 ## Degrees of freedom 39 ## P-value (Chi-square) 0.113 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## fmin4 1.000 0.676 0.667 ## fmin5 1.000 0.676 0.708 ## fmin6 1.000 0.676 0.640 ## fmin7 1.000 0.676 0.595 ## fmin8 1.000 0.676 0.549 ## fmin9 1.000 0.676 0.548 ## fmin10 1.000 0.676 0.558 ## fmin11 1.000 0.676 0.494 ## slp =~ ## fmin4 0.000 0.000 0.000 ## fmin5 1.000 0.132 0.138 ## fmin6 2.000 0.263 0.249 ## fmin7 3.000 0.395 0.347 ## fmin8 4.000 0.526 0.427 ## fmin9 5.000 0.658 0.533 ## fmin10 6.000 0.789 0.651 ## fmin11 7.000 0.921 0.673 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~ ## cog 0.069 0.015 4.563 0.000 0.103 0.296 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.000 0.000 0.000 ## .fmin5 0.000 0.000 0.000 ## .fmin6 0.000 0.000 0.000 ## .fmin7 0.000 0.000 0.000 ## .fmin8 0.000 0.000 0.000 ## .fmin9 0.000 0.000 0.000 ## .fmin10 0.000 0.000 0.000 ## .fmin11 0.000 0.000 0.000 ## .int 0.037 0.052 0.715 0.475 0.055 0.055 ## slp 0.049 0.012 3.993 0.000 0.372 0.372 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .fmin4 0.569 0.107 5.305 0.000 0.569 0.555 ## .fmin5 0.436 0.073 5.963 0.000 0.436 0.479 ## .fmin6 0.591 0.098 6.002 0.000 0.591 0.529 ## .fmin7 0.678 0.091 7.424 0.000 0.678 0.525 ## .fmin8 0.782 0.122 6.435 0.000 0.782 0.516 ## .fmin9 0.631 0.095 6.624 0.000 0.631 0.415 ## .fmin10 0.389 0.110 3.524 0.000 0.389 0.265 ## .fmin11 0.568 0.120 4.746 0.000 0.568 0.303 ## .int 0.417 0.060 6.992 0.000 0.912 0.912 ## slp 0.017 0.003 5.151 0.000 1.000 1.000 adversity &lt;- adversity %&gt;% select(-cog) Focusing one the regression of int ~ cog in both models, we can compare the standardized coefficients and see that the observed measure reduces the effect quite substantially (latent TIC: \\(\\beta = 0.466\\), observed TIC: \\(\\beta = 0.296\\)). Since we simulated this measure a, we knew that the true standardized effect should be \\(\\beta_{population} = 0.500\\), highlighting the utility of latent variables to attenuate the effects of measurement error that often bias effects downwards. Cross-Level Interactions Up until now, we have limited our discussion of TICs to include only those that predicted the intercept. This is because when we combine level 1 TVC variables with level 2 TIC variables, we can begin generating cross level interactions. We have not yet discussed TVCs in-depth (we do so below), in growth models the most common cross-level interactions are between TICs and our time variable (here age). As such, we will introuce these effects here before going on to explore TVCs in a more general way. Cross-level interactions are easier to see with the MLM, as the interaction is often not immediately apparent in SEMs. Below we will introduce a treatment TIC (tx) to our earlier TIC model. Here we will switch our TIC of interest to be the variable abuse for…reasons (it is a better demonstration). We will first only predict the intercept as we did previously and then we will fit a cross-level interaction model. tic.mlm &lt;- lmer(fmin ~ 1 + age + abuse + (1 + age | id), na.action = na.omit, REML = TRUE, data = adversity.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(tic.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: fmin ~ 1 + age + abuse + (1 + age | id) ## Data: adversity.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 3557.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.3459 -0.5333 -0.1760 0.4587 3.7771 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.34928 0.5910 ## age 0.01093 0.1046 -0.35 ## Residual 0.62065 0.7878 ## Number of obs: 1240, groups: id, 398 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.18075 0.08801 320.87068 -2.054 0.040824 * ## age 0.05129 0.01200 290.29406 4.273 2.62e-05 *** ## abuse -0.06501 0.01728 387.90442 -3.763 0.000194 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 When we add abuse as a predictor, we are really only estimating intercept differences across levels of experience of abuse (there is an negative effect here). If we want to know whether individuals with different experiences of abuse differ in their slopes, we need to explicitly create an interaction variable (age:abuse). cross.mlm &lt;- lmer(fmin ~ 1 + age + abuse + age:abuse + (1 + age | id), na.action = na.omit, REML = TRUE, data = adversity.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(cross.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: fmin ~ 1 + age + abuse + age:abuse + (1 + age | id) ## Data: adversity.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 3562.1 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.3630 -0.5303 -0.1670 0.4595 3.6994 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.303868 0.55124 ## age 0.009976 0.09988 -0.27 ## Residual 0.622593 0.78905 ## Number of obs: 1240, groups: id, 398 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) -0.180119 0.087311 316.426367 -2.063 0.0399 * ## age 0.051237 0.011889 284.132355 4.309 2.26e-05 *** ## abuse -0.004256 0.033426 308.486988 -0.127 0.8988 ## age:abuse -0.009689 0.004569 276.107835 -2.121 0.0348 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The interaction nature of the second effect is immediately apparent given the construction of the syntax. We can even plot these effects using the interact_plot() function from the interactions package. interact_plot(model = cross.mlm, pred = &quot;age&quot;, modx = &quot;abuse&quot;, interval = TRUE, int.type = &quot;confidence&quot;, x.label = &quot;Age&quot;, y.label = &quot;Forcept Minor White Matter FA&quot;) Here we can see some (non-significant) level differences between those who experience low levels of abuse (\\(-1\\) SD) versus those who experienced mean or high (\\(+1\\) SD) levels of abuse. However, there are significant slope differences (i.e., the interaction term is significant), such that those who experience lower levels of early childhood abuse also show faster gains in white matter FA. For some additional examples that have both intercept and slope differences, you can consult the help tools for the interactions package here. In an SEM approach, seeing how to specify a cross-level interaction is easier, although the interaction nature is somewhat more obscured. Implementing the model is trivial, we simply predict both the intercept and slope with our TIC. We again retain the TVC effects for consistency, even though they are not strictly necessary to demonstrate a cross-level interaction. cross.lcm &lt;- &quot;int =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 ef1 ~ c*dlpfc1 ef2 ~ c*dlpfc2 ef3 ~ c*dlpfc3 ef4 ~ dlpfc4 int ~ tx slp ~ tx&quot; cross.lcm.fit &lt;- growth(cross.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(cross.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 33 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 15 ## Number of equality constraints 2 ## ## Used Total ## Number of observations 296 342 ## Number of missing patterns 7 ## ## Model Test User Model: ## ## Test statistic 18.561 ## Degrees of freedom 21 ## P-value (Chi-square) 0.613 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef1 ~ ## dlpfc1 (c) 0.043 0.023 1.918 0.055 ## ef2 ~ ## dlpfc2 (c) 0.043 0.023 1.918 0.055 ## ef3 ~ ## dlpfc3 (c) 0.043 0.023 1.918 0.055 ## ef4 ~ ## dlpfc4 0.095 0.030 3.132 0.002 ## int ~ ## tx 0.112 0.086 1.294 0.196 ## slp ~ ## tx 0.000 0.030 0.008 0.994 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .int ~~ ## .slp -0.004 0.015 -0.269 0.788 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## .int 2.390 0.063 37.666 0.000 ## .slp 0.033 0.023 1.434 0.151 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.219 0.036 6.040 0.000 ## .ef2 0.242 0.026 9.125 0.000 ## .ef3 0.266 0.029 9.102 0.000 ## .ef4 0.137 0.036 3.852 0.000 ## .int 0.389 0.049 7.990 0.000 ## .slp 0.026 0.008 3.290 0.001 Unlike with the MLM, there is no product variable that we enter explicitly into the model. However, we can think about how the slope factor links the TIC and the individual repeated measures. The factor loadings are increasing integers and so the effect of the TIC on each successive repeated measure gets moderated by the numerical value of the factor loading. This serves the same function as an interaction for the SEM approaches. Time Varying Covariates While TICs can provide important insights into what factors might contribute to individual differences in the growth trajectories, they fundamentally represent cross-sectional regressions of the latent factors on a set of exogenous variables. However, if we want to test the effects of variables that themselves change over time, we can instead move the TVC model. While TICs predict the growth components (and therefore the repeated measures indirectly; hence cross-level interactions), a TVC directly predicts the individual repeated observations. In this section, we will return to our executive.function dataset. Here we can model the impact of DLPFC activation on executive function scores. As with the TIC model, we will first consider the MLM specification of this approach. executive.function.long &lt;- executive.function %&gt;% pivot_longer(cols = starts_with(c(&quot;dlpfc&quot;,&quot;ef&quot;,&quot;age&quot;)), names_to = c(&quot;.value&quot;, &quot;wave&quot;), names_pattern = &quot;(.+)(.)&quot;) %&gt;% mutate(wave = as.numeric(wave) - 1, age = age - min(age, na.rm = TRUE)) tvc.mlm &lt;- lmer(ef ~ 1 + age + dlpfc + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(tvc.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2550 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2978 -0.4809 0.0377 0.5297 3.1320 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.42998 0.6557 ## age 0.01877 0.1370 -0.10 ## Residual 0.23913 0.4890 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.371e+00 4.505e-02 3.626e+02 52.623 &lt; 2e-16 *** ## age 4.610e-02 1.516e-02 2.951e+02 3.041 0.00257 ** ## dlpfc 5.633e-02 2.062e-02 1.197e+03 2.732 0.00638 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We know have a variable that changes within (i.e., across time) as well as between individuals. Here we have actually somewhat blurred that line but we will talk about how to separate these within- and between-person effects towards the end of this chapter. However, for now we can see that there is a positive effect where more DLPFC activation predicts higher executive function scores. Here this is a purely fixed effect meaning that it holds across all individuals. As with the effect of age; however, we can introduce a random effect of the TVC as well but including it in the random effects structure. This addition allows for the possibility that increasing DLPFC activation has differential effects within different individuals. rtvc.mlm &lt;- lmer(ef ~ 1 + age + dlpfc + (1 + age + dlpfc | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(rtvc.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc + (1 + age + dlpfc | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2547.9 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2787 -0.4949 0.0408 0.5271 3.1584 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.443935 0.66628 ## age 0.017585 0.13261 -0.13 ## dlpfc 0.002587 0.05086 -0.41 0.96 ## Residual 0.237147 0.48698 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.36832 0.04568 307.54702 51.842 &lt; 2e-16 *** ## age 0.04646 0.01498 296.52049 3.102 0.00211 ** ## dlpfc 0.05560 0.02092 714.79021 2.658 0.00803 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## optimizer (bobyqa) convergence code: 0 (OK) ## boundary (singular) fit: see ?isSingular Here we’ve added \\(3\\) additional elements in our random effects covariance matrix, one additional variance, and two additional covariances with the effects we had in the prior model. We can see that the correlation between the random slope (age) and DLPFC activation (dlpfc) is quite high. This can lead to estimation issues if this correlation gets too high, and generally reflects redundancy among the random effects. While the model above already gives us the effect of DLPFC on executive funciton scores above and beyond the growth trajectory, the effects are all contemporaneous. That is, predicting executive function at a given time with DLPFC activation from that same time. A more interesting model is one in which we used activation from one time point to predict executive function at a later time point. While relatively rare, these lagged-effect models really represent a more exciting use of the trouble we went to in order to collect these variables over time. Because of the long format used in MLM, including lagged effects necessitates the creation of a new DLFPC variable with values offset one time point. Fortunately dplyr provides a convenient function to accomplish this data management step. It is; however, important to remember to group by id before creating this new variable so the last value of dlpfc for one person does not shift to the next person’s data rows. In this model, we will drop the random effect of dlpfc for simplicity (and it’s redundancy in the prior model). executive.function.long &lt;- executive.function.long %&gt;% group_by(id) %&gt;% mutate(dlpfc.lag = dplyr::lag(dlpfc, 1)) lag.tvc.mlm &lt;- lmer(ef ~ 1 + age + dlpfc + dlpfc.lag + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(lag.tvc.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc + dlpfc.lag + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 1888.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2342 -0.5072 0.0392 0.5511 3.0448 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.435953 0.66027 ## age 0.001306 0.03614 0.39 ## Residual 0.242442 0.49238 ## Number of obs: 892, groups: id, 330 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.31372 0.06229 323.33710 37.142 &lt; 2e-16 *** ## age 0.06044 0.02116 281.02897 2.856 0.00461 ** ## dlpfc 0.07326 0.02378 814.70968 3.081 0.00213 ** ## dlpfc.lag 0.04651 0.02455 823.26058 1.895 0.05850 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Here the effect of the lagged DLPFC variable is non-significant (arbitrary thresholds are arbitrary but live by \\(p &lt; .05\\), die by \\(p &lt; .05\\); just be consistent). However, one concerning thing about the lagged MLM model is that we have a reduced sample size compared to the contemporaneous model (contemporaneous: N obs = \\(1241\\) &amp; N id = \\(342\\); lagged: N obs = \\(892\\) &amp; N id = \\(330\\)). This loss of information is not trivial and comes from two sources. It is helpful to visualize the data frame, which we have done below. executive.function.long %&gt;% filter(id &lt;= 15 &amp; id &gt;= 10) %&gt;% kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Executive Function Data with Lagged Variable**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% row_spec(row = 0, align = &quot;c&quot;) Executive Function Data with Lagged Variable id sex tx wave dlpfc ef age dlpfc.lag 10 1 1 0 1.457 2.889 0.232 NA 10 1 1 1 1.129 1.806 1.331 1.457 10 1 1 2 1.785 2.889 2.280 1.129 10 1 1 3 0.472 2.889 3.280 1.785 11 0 1 0 0.472 2.889 0.152 NA 11 0 1 1 0.472 2.889 1.278 0.472 11 0 1 2 0.472 1.806 2.161 0.472 11 0 1 3 1.129 2.889 3.290 0.472 12 0 1 0 0.472 0.361 0.248 NA 12 0 1 1 -0.512 2.889 1.101 0.472 12 0 1 2 -0.840 2.167 2.408 -0.512 12 0 1 3 -0.184 1.806 3.027 -0.840 13 0 1 0 0.144 3.250 0.335 NA 13 0 1 1 -0.840 2.167 1.261 0.144 13 0 1 2 NA 1.444 2.225 -0.840 13 0 1 3 1.129 2.167 3.182 NA 14 0 0 0 1.129 1.806 0.533 NA 14 0 0 1 1.457 1.806 1.338 1.129 14 0 0 2 2.114 2.167 2.088 1.457 14 0 0 3 1.457 2.167 3.232 2.114 15 0 1 0 1.129 2.528 0.250 NA 15 0 1 1 1.457 2.528 1.003 1.129 15 0 1 2 0.144 2.889 2.111 1.457 15 0 1 3 -0.184 1.806 3.375 0.144 Note that for every person in our data, we have NA values for the first observation of the dlpfc.lag variable. This is because we could not observe DLPFC activation the time point before we began the study. Because of the conditional likelihood approach we discussed previous as the only option in the MLM, all of these first observation rows are removed from the model. If that wasn’t enough of a bummer, any missing data in the contemporaneous DLPFC variable are shifted to be missing in the lagged version for the next time point, so we lose both time points when we include the contemporaneous and lagged effects (which we should pretty much always do to properly specify the model, so don’t be tempted to only include the lagged effect). We can see this effect for id \\(13\\) where DLPFC is missing at time \\(3\\) and so the lagged variable is missing at time \\(4\\). One potential solution proposed by Dan McNeish is that we replace the NA values for the first observation with a constant, \\(0\\), so that we don’t lose those time points but they also do not introduce spurious effects. However, we do not want to remove NA values that arise due to true missing data. executive.function.long[executive.function.long$wave == 0, &quot;dlpfc.lag&quot;] &lt;- 0 lag.tvc.mlm &lt;- lmer(ef ~ 1 + age + dlpfc + dlpfc.lag + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(lag.tvc.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc + dlpfc.lag + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2523.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.3151 -0.4776 0.0375 0.5303 3.0969 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.42664 0.6532 ## age 0.01684 0.1298 -0.07 ## Residual 0.24168 0.4916 ## Number of obs: 1224, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.367e+00 4.507e-02 3.628e+02 52.516 &lt; 2e-16 *** ## age 3.948e-02 1.620e-02 3.397e+02 2.437 0.01531 * ## dlpfc 5.807e-02 2.085e-02 1.179e+03 2.785 0.00544 ** ## dlpfc.lag 4.262e-02 2.186e-02 9.588e+02 1.950 0.05152 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 As we can see, the number of observations and id values is much more similar to the contemporaneous effects model. The lag effect is still not significant, but them’s the breaks. Lag effects are often difficult to detect in these kind of longitudinal models due to the relatively long intervals between observations. Relationships simply decay over time and therefore observations spaced out in year or biennial schedules often don’t result in unique lagged effects. We can also briefly return to the idea of cross-level interactions here. While in the growth model context, we are primarily concerned with cross-level interactions with whatever metric of time we are utilizing in the model, we are not limited to this kind of effect and can moderate the effect of any level 1 TVC with a level 2 TIC. Below might be an example with tx and dlpfc. cross.mlm &lt;- lmer(ef ~ 1 + age + dlpfc + tx + dlpfc:tx + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(cross.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc + tx + dlpfc:tx + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2554.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.3128 -0.4805 0.0457 0.5191 3.1417 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.42661 0.6532 ## age 0.01864 0.1365 -0.10 ## Residual 0.23955 0.4894 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.306e+00 6.180e-02 4.211e+02 37.321 &lt;2e-16 *** ## age 4.603e-02 1.516e-02 2.952e+02 3.037 0.0026 ** ## dlpfc 5.017e-02 2.990e-02 1.207e+03 1.678 0.0937 . ## tx 1.262e-01 8.229e-02 3.981e+02 1.533 0.1260 ## dlpfc:tx 1.256e-02 4.080e-02 1.189e+03 0.308 0.7583 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 interact_plot(model = cross.mlm, pred = &quot;dlpfc&quot;, modx = &quot;tx&quot;, interval = TRUE, int.type = &quot;confidence&quot;, x.label = &quot;DLPFC Activation&quot;, y.label = &quot;Executive Function&quot;, modx.labels = c(&quot;Treatment&quot;, &quot;Control&quot;)) The effects here are not significant, but it is a good principle to keep in mind, especially if fitting these models in a non-growth context. If we turn to the SEMs, we can re-create many of the models we saw with the MLM (although not exclusively in R), but the SEM does allow for some additional flexibility that may be attractive. Because each measure gets its own column at different time points (i.e., wide format), we need to specify each of the contemporaneous (or lagged) effects individually. However, we will not need to explicitly create a lagged version of the variable. We can see the contemporaneous effect model below. Note that each time-specific regression of ef on dlpfc requires its own line of syntax. tvc.lcm &lt;- &quot;int =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 ef1 ~ dlpfc1 ef2 ~ dlpfc2 ef3 ~ dlpfc3 ef4 ~ dlpfc4&quot; tvc.lcm.fit &lt;- growth(tvc.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(tvc.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 37 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## ## Used Total ## Number of observations 296 342 ## Number of missing patterns 7 ## ## Model Test User Model: ## ## Test statistic 16.183 ## Degrees of freedom 17 ## P-value (Chi-square) 0.511 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef1 ~ ## dlpfc1 0.027 0.036 0.773 0.440 ## ef2 ~ ## dlpfc2 0.051 0.029 1.753 0.080 ## ef3 ~ ## dlpfc3 0.044 0.031 1.450 0.147 ## ef4 ~ ## dlpfc4 0.098 0.032 3.080 0.002 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.003 0.015 -0.229 0.819 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## int 2.451 0.047 52.040 0.000 ## slp 0.030 0.019 1.603 0.109 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.220 0.036 6.070 0.000 ## .ef2 0.241 0.026 9.119 0.000 ## .ef3 0.266 0.029 9.113 0.000 ## .ef4 0.138 0.036 3.857 0.000 ## int 0.391 0.049 8.001 0.000 ## slp 0.026 0.008 3.216 0.001 The striking thing here, compared with the MLM results, is that we get \\(4\\) regression coefficients for the relationship between ef and dlpfc instead of \\(1\\). These individual time-specific effects are one of the unique strengths of the SEM approaches, and would be essentially impossible to achieve with most MLMs (Mplus is a bit of a potential exception, but that’s because it specifies MLMs more like SEMs), since this is a weird form of nonlinear interaction between the overall TVC effect and time. However, we could also impose simpler functional forms on these regressions. The simplest is to constrain all of them to be equal. This constraint is the one imposed in the MLM, so we should get a single overall TVC effect with this approach. We can see this below. tvc.lcm &lt;- &quot;int =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 ef1 ~ c*dlpfc1 ef2 ~ c*dlpfc2 ef3 ~ c*dlpfc3 ef4 ~ c*dlpfc4&quot; tvc.lcm.fit &lt;- growth(tvc.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(tvc.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 30 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## Number of equality constraints 3 ## ## Used Total ## Number of observations 296 342 ## Number of missing patterns 7 ## ## Model Test User Model: ## ## Test statistic 19.768 ## Degrees of freedom 20 ## P-value (Chi-square) 0.473 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef1 ~ ## dlpfc1 (c) 0.056 0.021 2.634 0.008 ## ef2 ~ ## dlpfc2 (c) 0.056 0.021 2.634 0.008 ## ef3 ~ ## dlpfc3 (c) 0.056 0.021 2.634 0.008 ## ef4 ~ ## dlpfc4 (c) 0.056 0.021 2.634 0.008 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.004 0.015 -0.269 0.788 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## int 2.429 0.045 54.225 0.000 ## slp 0.048 0.015 3.124 0.002 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.220 0.036 6.067 0.000 ## .ef2 0.241 0.026 9.119 0.000 ## .ef3 0.266 0.029 9.091 0.000 ## .ef4 0.139 0.036 3.896 0.000 ## int 0.390 0.049 8.000 0.000 ## slp 0.027 0.008 3.308 0.001 If we examine the TVC regressions, they are all precisely equal (it should worry us if they are not) and equivalent to the results from the MLM. It is possible through the use of nonlinear constraints to put other functional forms on these regressions. For instance, we could impose a linear constraint so that the regressions increase or decrease over time. We could also impose order constraints where we want the regressions at some time points to be larger than at others. This is where the incredible flexibility of SEM approaches comes out most strongly. The important thing to keep in mind is that this flexibility is also a great way to wander and over-fit our way off a cliff. We need good theoretical justification for our model specification choices and a greater willingness to admit when some features of our model are exploratory to avoid these pitfalls. One current limitation of implementing SEM TVC models in R is in the inability to specify a random effect of the TVC (to our knowledge). This is possible in Mplus and we have included syntax for that model in the external software downloads. Finally, the lagged effect model is simple to implement in SEM approaches. We simply include the earlier time point version of our TVC in the regressions for the time-specific outcomes. We won’t need to worry about inducing additional missing data because we never created a lagged version of our TVC. lag.lcm &lt;- &quot;int =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 ef1 ~ dlpfc1 ef2 ~ dlpfc2 + dlpfc1 ef3 ~ dlpfc3 + dlpfc2 ef4 ~ dlpfc4 + dlpfc3&quot; lag.lcm.fit &lt;- growth(lag.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lag.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 36 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 16 ## ## Used Total ## Number of observations 296 342 ## Number of missing patterns 7 ## ## Model Test User Model: ## ## Test statistic 9.699 ## Degrees of freedom 14 ## P-value (Chi-square) 0.784 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef1 ~ ## dlpfc1 0.045 0.039 1.154 0.248 ## ef2 ~ ## dlpfc2 0.067 0.038 1.783 0.075 ## dlpfc1 0.008 0.044 0.178 0.859 ## ef3 ~ ## dlpfc3 0.077 0.039 1.940 0.052 ## dlpfc2 0.014 0.037 0.376 0.707 ## ef4 ~ ## dlpfc4 0.054 0.037 1.455 0.146 ## dlpfc3 0.106 0.042 2.507 0.012 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.005 0.015 -0.333 0.739 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## int 2.442 0.048 50.832 0.000 ## slp 0.020 0.019 1.052 0.293 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.220 0.036 6.048 0.000 ## .ef2 0.242 0.026 9.143 0.000 ## .ef3 0.265 0.029 9.131 0.000 ## .ef4 0.133 0.035 3.798 0.000 ## int 0.391 0.049 8.007 0.000 ## slp 0.026 0.008 3.245 0.001 Finally, we could constrain the different types of pathways to be equal within type. While the flexibility of the time-specific effects can be powerful, it can also overwhelm us inferentially. What do we do with the fact that only one of our paths here (ef4 ~ dlpfc3) is significant? Who knows. Constraints can both narrow the number of parameters we are interpreting, but also increase the power to detect an overall effect if one exists because we aggregate over more information. lag.lcm &lt;- &quot;int =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 ef1 ~ c1*dlpfc1 ef2 ~ c1*dlpfc2 + c2*dlpfc1 ef3 ~ c1*dlpfc3 + c2*dlpfc2 ef4 ~ c1*dlpfc4 + c2*dlpfc3&quot; lag.lcm.fit &lt;- growth(lag.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lag.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 29 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 16 ## Number of equality constraints 5 ## ## Used Total ## Number of observations 296 342 ## Number of missing patterns 7 ## ## Model Test User Model: ## ## Test statistic 16.245 ## Degrees of freedom 19 ## P-value (Chi-square) 0.641 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef1 ~ ## dlpfc1 (c1) 0.057 0.021 2.691 0.007 ## ef2 ~ ## dlpfc2 (c1) 0.057 0.021 2.691 0.007 ## dlpfc1 (c2) 0.042 0.022 1.879 0.060 ## ef3 ~ ## dlpfc3 (c1) 0.057 0.021 2.691 0.007 ## dlpfc2 (c2) 0.042 0.022 1.879 0.060 ## ef4 ~ ## dlpfc4 (c1) 0.057 0.021 2.691 0.007 ## dlpfc3 (c2) 0.042 0.022 1.879 0.060 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.004 0.015 -0.291 0.771 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## int 2.423 0.045 53.939 0.000 ## slp 0.038 0.016 2.381 0.017 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.221 0.036 6.094 0.000 ## .ef2 0.243 0.027 9.135 0.000 ## .ef3 0.266 0.029 9.115 0.000 ## .ef4 0.137 0.035 3.883 0.000 ## int 0.389 0.049 7.998 0.000 ## slp 0.026 0.008 3.281 0.001 This aggregation of course cuts both ways. Now we have no significant lagged effect (although we only had one out of three before so did we really have it to begin with?), but we do have a significant contemporaneous effect where we had no individual one before. The examples we have included thus far are relatively simple, with a single TVC. Of course all of these models can be expanded to include multiple TVCs, and potentially interactions if we have the sample size to support them. Multivariate Models Those paying close attention (and at this point all the kudos to you) might have been a bit perturbed by the fact that in our Canonical chapter, we fit a growth model to the dlpfc variable, but here we have used it as our TVC. This is indeed of great concern and something we should always be thinking about when including a repeated measure as a TVC. The standard TVC model assumes that there are no systematic changes in the covariate across time. The values obviously change, but not systematically. Rather, the traditional TVC model is well suited for covariates that fluctuates from time point to time point. Weather over short intervals is often a canonical example in more-intensive applications, but we can think also the time of day that testing occurs as one that might be of interest for our purposes. From our earlier model fitting, we know that our dlpfc TVC does not meet this criteria. This is an issue because we essentially have an unmodeled age effect on the TVC, which will introduce bias into our model results. The other issue is that of true exogeneity. Do we really believe that the causal effect in our model only runs from DLPFC activation to executive function, and that there are no reciprocal relationships over time? With something like the weather this is totally plausible; however, with our data this assumption seems unlikely to hold. As such, we might wish to treat both ef and dlpfc as outcomes in a multivariate model. This will involve some difficulty in the MLM, but will be a completely natural extension of the SEM. We will flip our usual order of considering the MLM first and demonstrate the SEM specifications so it’s easier to see where we will run into difficulty with the MLMs. We will first re-fit the TVC model we ended with earlier tvc.lcm &lt;- &quot;int =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 ef1 ~ c*dlpfc1 ef2 ~ c*dlpfc2 ef3 ~ c*dlpfc3 ef4 ~ c*dlpfc4&quot; tvc.lcm.fit &lt;- growth(tvc.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(tvc.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 30 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 13 ## Number of equality constraints 3 ## ## Used Total ## Number of observations 296 342 ## Number of missing patterns 7 ## ## Model Test User Model: ## ## Test statistic 19.768 ## Degrees of freedom 20 ## P-value (Chi-square) 0.473 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef1 ~ ## dlpfc1 (c) 0.056 0.021 2.634 0.008 ## ef2 ~ ## dlpfc2 (c) 0.056 0.021 2.634 0.008 ## ef3 ~ ## dlpfc3 (c) 0.056 0.021 2.634 0.008 ## ef4 ~ ## dlpfc4 (c) 0.056 0.021 2.634 0.008 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int ~~ ## slp -0.004 0.015 -0.269 0.788 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## int 2.429 0.045 54.225 0.000 ## slp 0.048 0.015 3.124 0.002 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.220 0.036 6.067 0.000 ## .ef2 0.241 0.026 9.119 0.000 ## .ef3 0.266 0.029 9.091 0.000 ## .ef4 0.139 0.036 3.896 0.000 ## int 0.390 0.049 8.000 0.000 ## slp 0.027 0.008 3.308 0.001 To transform this model into a multivariate version, we need to estimate an intercept and slope for both the ef and the dlpfc variables. One thing to note is that we should be explicit about including the correlations between the growth factors within- and across-construct, as well as cross-construct, time-specific covariances between the individual repeated measures. These time-specific residuals are often necessary and help account for unmeasured common causes that might induce correlations among the repeated measures above-and-beyond the growth factors themselves. We can do all the usual things with these residual covariances, including testing equality constraints or even constraining them to zero and assess their impact on model fit through likelihood ratio tests. For now we will estimate unique relationships, as that is the default in SEM approaches. multivar.lcm &lt;- &quot; # Growth Factors for EF int.ef =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp.ef =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 # Growth Factors for DLPFC int.dlpfc =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp.dlpfc =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4 # Factor Covariances int.ef ~~ slp.ef + int.dlpfc + slp.dlpfc slp.ef ~~ int.dlpfc + slp.dlpfc int.dlpfc ~~ slp.dlpfc # Time-Specific Residual Covariance ef1 ~~ dlpfc1 ef2 ~~ dlpfc2 ef3 ~~ dlpfc3 ef4 ~~ dlpfc4&quot; multivar.lcm.fit &lt;- growth(multivar.lcm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(multivar.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 50 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 26 ## ## Number of observations 342 ## Number of missing patterns 28 ## ## Model Test User Model: ## ## Test statistic 11.574 ## Degrees of freedom 18 ## P-value (Chi-square) 0.868 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp.ef =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## int.dlpfc =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## slp.dlpfc =~ ## dlpfc1 0.000 ## dlpfc2 1.000 ## dlpfc3 2.000 ## dlpfc4 3.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef ~~ ## slp.ef -0.010 0.016 -0.634 0.526 ## int.dlpfc 0.084 0.046 1.823 0.068 ## slp.dlpfc -0.022 0.019 -1.159 0.247 ## slp.ef ~~ ## int.dlpfc 0.011 0.017 0.647 0.518 ## slp.dlpfc 0.011 0.008 1.319 0.187 ## int.dlpfc ~~ ## slp.dlpfc -0.125 0.031 -4.072 0.000 ## .ef1 ~~ ## .dlpfc1 -0.037 0.035 -1.066 0.286 ## .ef2 ~~ ## .dlpfc2 0.048 0.027 1.738 0.082 ## .ef3 ~~ ## .dlpfc3 0.023 0.029 0.781 0.435 ## .ef4 ~~ ## .dlpfc4 -0.013 0.037 -0.348 0.728 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int.ef 2.407 0.042 57.447 0.000 ## slp.ef 0.059 0.015 3.921 0.000 ## int.dlpfc 0.545 0.053 10.212 0.000 ## slp.dlpfc 0.120 0.021 5.696 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.236 0.038 6.250 0.000 ## .ef2 0.262 0.027 9.569 0.000 ## .ef3 0.263 0.028 9.329 0.000 ## .ef4 0.123 0.034 3.615 0.000 ## .dlpfc1 0.235 0.063 3.733 0.000 ## .dlpfc2 0.566 0.055 10.268 0.000 ## .dlpfc3 0.577 0.057 10.110 0.000 ## .dlpfc4 0.399 0.074 5.389 0.000 ## int.ef 0.425 0.050 8.485 0.000 ## slp.ef 0.030 0.008 3.675 0.000 ## int.dlpfc 0.775 0.086 9.020 0.000 ## slp.dlpfc 0.081 0.016 5.134 0.000 This model is quite simple for a SEM approach, and we can examine how different constructs travel together over time by examining the inter-relations among the growth factors. However, this is ultimately cross-sectional correlations because there is no temporal order at the latent level, either between intercepts and slope or between factors of different constructs. If we want to examine cross-lagged relationships among the repeated measures themselves (ala the standard cross-lag panel model we won’t consider here for numerous reasons), we might wish to introduce regression relationships among the repeated measures. There are several ways to specify these regression among the repeated measures in a multivariate growth model; however, we will focus on what is known as the random-intercept cross-lag panel model (RI-CLPM) and it’s generalization in the latent curve model with structured residuals (LCM-SR). For an overview of potential alternatives, see Usami &amp; Hamaker, 2019. We retain the time-specific residual covariances, but now we include regression coefficients between the residuals of the repeated measures (hence “structured residuals”). Note that for the RI-CLPM, we remove the slope factors. In the LCM-SR, we can include any combination of latent growth factors, so that will be the term we will use to reference this general type of model, with the RI-CLPM being a special case. riclpm &lt;- &quot; # Random Intercept for EF int.ef =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 # Random Intercept for DLPFC int.dlpfc =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 # Factor Covariances int.ef ~~ int.dlpfc # Time-Specific Residual Covariance ef1 ~~ dlpfc1 ef2 ~~ dlpfc2 ef3 ~~ dlpfc3 ef4 ~~ dlpfc4 # Autoregressive and Cross-Regressive Effects ef2 ~ ef1 + dlpfc1 ef3 ~ ef2 + dlpfc2 ef4 ~ ef3 + dlpfc3 dlpfc2 ~ dlpfc1 + ef1 dlpfc3 ~ dlpfc2 + ef2 dlpfc4 ~ dlpfc3 + ef3&quot; riclpm.fit &lt;- growth(riclpm, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(riclpm.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 44 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 29 ## ## Number of observations 342 ## Number of missing patterns 28 ## ## Model Test User Model: ## ## Test statistic 30.269 ## Degrees of freedom 15 ## P-value (Chi-square) 0.011 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## int.dlpfc =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef2 ~ ## ef1 0.027 0.018 1.472 0.141 ## dlpfc1 0.022 0.037 0.605 0.545 ## ef3 ~ ## ef2 0.034 0.019 1.792 0.073 ## dlpfc2 0.034 0.035 0.971 0.332 ## ef4 ~ ## ef3 0.065 0.019 3.490 0.000 ## dlpfc3 0.087 0.034 2.579 0.010 ## dlpfc2 ~ ## dlpfc1 0.291 0.065 4.481 0.000 ## ef1 -0.001 0.027 -0.042 0.966 ## dlpfc3 ~ ## dlpfc2 0.131 0.063 2.083 0.037 ## ef2 0.052 0.029 1.771 0.077 ## dlpfc4 ~ ## dlpfc3 0.175 0.061 2.886 0.004 ## ef3 0.081 0.029 2.795 0.005 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef ~~ ## int.dlpfc 0.030 0.032 0.959 0.338 ## .ef1 ~~ ## .dlpfc1 -0.008 0.033 -0.243 0.808 ## .ef2 ~~ ## .dlpfc2 0.050 0.029 1.711 0.087 ## .ef3 ~~ ## .dlpfc3 0.060 0.033 1.827 0.068 ## .ef4 ~~ ## .dlpfc4 0.022 0.030 0.724 0.469 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int.ef 2.390 0.046 52.341 0.000 ## int.dlpfc 0.546 0.052 10.501 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.313 0.032 9.656 0.000 ## .ef2 0.262 0.028 9.267 0.000 ## .ef3 0.280 0.030 9.445 0.000 ## .ef4 0.229 0.026 8.773 0.000 ## .dlpfc1 0.627 0.069 9.120 0.000 ## .dlpfc2 0.568 0.060 9.507 0.000 ## .dlpfc3 0.669 0.069 9.660 0.000 ## .dlpfc4 0.639 0.062 10.310 0.000 ## int.ef 0.412 0.040 10.263 0.000 ## int.dlpfc 0.352 0.063 5.551 0.000 With the LCM-SR, we simply add back the slope factors for each of our constructs. Note that in practice, we do not need to specify the same type of trajectory for each variable. It’s entirely possible that one variable might follow a linear and the other a quadratic. Indeed one construct might only need a random intercept (we will see this later); we can mix and match as we please. lcmsr &lt;- &quot; # Growth Factors for EF int.ef =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp.ef =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 # Growth Factors for DLPFC int.dlpfc =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp.dlpfc =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4 # Factor Covariances int.ef ~~ slp.ef + int.dlpfc + slp.dlpfc slp.ef ~~ int.dlpfc + slp.dlpfc int.dlpfc ~~ slp.dlpfc # Time-Specific Residual Covariance ef1 ~~ dlpfc1 ef2 ~~ dlpfc2 ef3 ~~ dlpfc3 ef4 ~~ dlpfc4 # Autoregressive and Cross-Regressive Effects ef2 ~ ef1 + dlpfc1 ef3 ~ ef2 + dlpfc2 ef4 ~ ef3 + dlpfc3 dlpfc2 ~ dlpfc1 + ef1 dlpfc3 ~ dlpfc2 + ef2 dlpfc4 ~ dlpfc3 + ef3&quot; lcmsr.fit &lt;- growth(lcmsr, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcmsr.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 72 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 38 ## ## Number of observations 342 ## Number of missing patterns 28 ## ## Model Test User Model: ## ## Test statistic 1.299 ## Degrees of freedom 6 ## P-value (Chi-square) 0.972 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp.ef =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## int.dlpfc =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## slp.dlpfc =~ ## dlpfc1 0.000 ## dlpfc2 1.000 ## dlpfc3 2.000 ## dlpfc4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef2 ~ ## ef1 0.022 0.048 0.463 0.643 ## dlpfc1 0.031 0.047 0.664 0.507 ## ef3 ~ ## ef2 0.035 0.088 0.402 0.688 ## dlpfc2 0.074 0.044 1.702 0.089 ## ef4 ~ ## ef3 0.052 0.133 0.390 0.697 ## dlpfc3 0.191 0.076 2.522 0.012 ## dlpfc2 ~ ## dlpfc1 0.030 0.087 0.346 0.729 ## ef1 0.091 0.054 1.699 0.089 ## dlpfc3 ~ ## dlpfc2 0.006 0.076 0.077 0.939 ## ef2 0.163 0.096 1.702 0.089 ## dlpfc4 ~ ## dlpfc3 -0.062 0.155 -0.403 0.687 ## ef3 0.274 0.145 1.887 0.059 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef ~~ ## slp.ef -0.020 0.019 -1.030 0.303 ## int.dlpfc 0.069 0.057 1.202 0.229 ## slp.dlpfc -0.046 0.026 -1.752 0.080 ## slp.ef ~~ ## int.dlpfc -0.016 0.022 -0.731 0.465 ## slp.dlpfc -0.009 0.013 -0.675 0.500 ## int.dlpfc ~~ ## slp.dlpfc -0.115 0.046 -2.504 0.012 ## .ef1 ~~ ## .dlpfc1 -0.013 0.046 -0.287 0.774 ## .ef2 ~~ ## .dlpfc2 0.059 0.029 2.044 0.041 ## .ef3 ~~ ## .dlpfc3 0.113 0.047 2.392 0.017 ## .ef4 ~~ ## .dlpfc4 0.059 0.056 1.057 0.291 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int.ef 2.421 0.044 54.641 0.000 ## slp.ef -0.033 0.112 -0.298 0.765 ## int.dlpfc 0.539 0.054 9.985 0.000 ## slp.dlpfc -0.089 0.124 -0.715 0.475 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.238 0.045 5.345 0.000 ## .ef2 0.268 0.030 8.961 0.000 ## .ef3 0.282 0.045 6.270 0.000 ## .ef4 0.144 0.051 2.815 0.005 ## .dlpfc1 0.262 0.106 2.466 0.014 ## .dlpfc2 0.559 0.058 9.605 0.000 ## .dlpfc3 0.557 0.099 5.614 0.000 ## .dlpfc4 0.409 0.103 3.980 0.000 ## int.ef 0.424 0.056 7.640 0.000 ## slp.ef 0.025 0.013 1.931 0.054 ## int.dlpfc 0.736 0.125 5.898 0.000 ## slp.dlpfc 0.086 0.027 3.252 0.001 For all the reasons we have discussed so far (and common practice in CLPMs more generally), it is common to test equality constraints on the auto- and cross-regressive effects in these models. We can see an example of this below. lcmsr &lt;- &quot; # Growth Factors for EF int.ef =~ 1*ef1 + 1*ef2 + 1*ef3 + 1*ef4 slp.ef =~ 0*ef1 + 1*ef2 + 2*ef3 + 3*ef4 # Growth Factors for DLPFC int.dlpfc =~ 1*dlpfc1 + 1*dlpfc2 + 1*dlpfc3 + 1*dlpfc4 slp.dlpfc =~ 0*dlpfc1 + 1*dlpfc2 + 2*dlpfc3 + 3*dlpfc4 # Factor Covariances int.ef ~~ slp.ef + int.dlpfc + slp.dlpfc slp.ef ~~ int.dlpfc + slp.dlpfc int.dlpfc ~~ slp.dlpfc # Time-Specific Residual Covariance ef1 ~~ dlpfc1 ef2 ~~ dlpfc2 ef3 ~~ dlpfc3 ef4 ~~ dlpfc4 # Autoregressive and Cross-Regressive Effects ef2 ~ c1*ef1 + c3*dlpfc1 ef3 ~ c1*ef2 + c3*dlpfc2 ef4 ~ c1*ef3 + c3*dlpfc3 dlpfc2 ~ c2*dlpfc1 + c4*ef1 dlpfc3 ~ c2*dlpfc2 + c4*ef2 dlpfc4 ~ c2*dlpfc3 + c4*ef3&quot; lcmsr.fit &lt;- growth(lcmsr, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(lcmsr.fit, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 57 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 38 ## Number of equality constraints 8 ## ## Number of observations 342 ## Number of missing patterns 28 ## ## Model Test User Model: ## ## Test statistic 9.555 ## Degrees of freedom 14 ## P-value (Chi-square) 0.794 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef =~ ## ef1 1.000 ## ef2 1.000 ## ef3 1.000 ## ef4 1.000 ## slp.ef =~ ## ef1 0.000 ## ef2 1.000 ## ef3 2.000 ## ef4 3.000 ## int.dlpfc =~ ## dlpfc1 1.000 ## dlpfc2 1.000 ## dlpfc3 1.000 ## dlpfc4 1.000 ## slp.dlpfc =~ ## dlpfc1 0.000 ## dlpfc2 1.000 ## dlpfc3 2.000 ## dlpfc4 3.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ef2 ~ ## ef1 (c1) -0.020 0.020 -1.010 0.312 ## dlpfc1 (c3) 0.030 0.030 0.979 0.328 ## ef3 ~ ## ef2 (c1) -0.020 0.020 -1.010 0.312 ## dlpfc2 (c3) 0.030 0.030 0.979 0.328 ## ef4 ~ ## ef3 (c1) -0.020 0.020 -1.010 0.312 ## dlpfc3 (c3) 0.030 0.030 0.979 0.328 ## dlpfc2 ~ ## dlpfc1 (c2) 0.026 0.061 0.419 0.675 ## ef1 (c4) 0.014 0.028 0.497 0.619 ## dlpfc3 ~ ## dlpfc2 (c2) 0.026 0.061 0.419 0.675 ## ef2 (c4) 0.014 0.028 0.497 0.619 ## dlpfc4 ~ ## dlpfc3 (c2) 0.026 0.061 0.419 0.675 ## ef3 (c4) 0.014 0.028 0.497 0.619 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef ~~ ## slp.ef -0.012 0.016 -0.774 0.439 ## int.dlpfc 0.062 0.051 1.204 0.229 ## slp.dlpfc -0.016 0.021 -0.801 0.423 ## slp.ef ~~ ## int.dlpfc 0.013 0.017 0.739 0.460 ## slp.dlpfc 0.005 0.009 0.584 0.559 ## int.dlpfc ~~ ## slp.dlpfc -0.124 0.032 -3.849 0.000 ## .ef1 ~~ ## .dlpfc1 -0.018 0.039 -0.447 0.655 ## .ef2 ~~ ## .dlpfc2 0.049 0.027 1.775 0.076 ## .ef3 ~~ ## .dlpfc3 0.031 0.030 1.020 0.308 ## .ef4 ~~ ## .dlpfc4 0.001 0.039 0.018 0.985 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int.ef 2.419 0.044 54.605 0.000 ## slp.ef 0.066 0.021 3.159 0.002 ## int.dlpfc 0.536 0.054 9.901 0.000 ## slp.dlpfc 0.102 0.032 3.178 0.001 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.224 0.039 5.746 0.000 ## .ef2 0.261 0.027 9.571 0.000 ## .ef3 0.258 0.028 9.191 0.000 ## .ef4 0.115 0.035 3.342 0.001 ## .dlpfc1 0.253 0.085 2.969 0.003 ## .dlpfc2 0.566 0.055 10.214 0.000 ## .dlpfc3 0.592 0.064 9.304 0.000 ## .dlpfc4 0.413 0.088 4.677 0.000 ## int.ef 0.439 0.053 8.349 0.000 ## slp.ef 0.032 0.009 3.736 0.000 ## int.dlpfc 0.754 0.106 7.134 0.000 ## slp.dlpfc 0.077 0.021 3.668 0.000 As always, we can extend this model in a number of ways that we won’t go into here for sake of time (ha ha ha you may say to yourself). While uncommon, we could impose functions on the cross-regressive paths, add additional outcome variables, and include both TIC and (true) TVCs to this model. The limitations are as always, proper theoretical models for that complexity, and sufficient data to estimate all of these effects uniquely. Multivariate LCSMs have some additional peculiarities that we will explore since they diverge somewhat from the LCM we have mostly focused on. However, as with all SEMs, the problem is much more keeping track of the parameter syntax than it is an inability to estimate certain effects. The main point of divergence between the LCM and LCSM is the inclusion of proportional parameters in the multivariate model. Because of this, we will dive straight into that model instead of building up in the way we did with the LCM. Below we can see the syntax for this multivariate dual-change LCSM. multivar.dualchange &lt;- &quot; # Define Phantom Variables (p = phantom) pef1 =~ 1*ef1; ef1 ~ 0; ef1 ~~ ef1; pef1 ~~ 0*pef1 pef2 =~ 1*ef2; ef2 ~ 0; ef2 ~~ ef2; pef2 ~~ 0*pef2 pef3 =~ 1*ef3; ef3 ~ 0; ef3 ~~ ef3; pef3 ~~ 0*pef3 pef4 =~ 1*ef4; ef4 ~ 0; ef4 ~~ ef4; pef4 ~~ 0*pef4 pdlpfc1 =~ 1*dlpfc1; dlpfc1 ~ 0; dlpfc1 ~~ dlpfc1; pdlpfc1 ~~ 0*pdlpfc1 pdlpfc2 =~ 1*dlpfc2; dlpfc2 ~ 0; dlpfc2 ~~ dlpfc2; pdlpfc2 ~~ 0*pdlpfc2 pdlpfc3 =~ 1*dlpfc3; dlpfc3 ~ 0; dlpfc3 ~~ dlpfc3; pdlpfc3 ~~ 0*pdlpfc3 pdlpfc4 =~ 1*dlpfc4; dlpfc4 ~ 0; dlpfc4 ~~ dlpfc4; pdlpfc4 ~~ 0*pdlpfc4 # Regressions Between Adjacent Observations pef2 ~ 1*pef1 pef3 ~ 1*pef2 pef4 ~ 1*pef3 pdlpfc2 ~ 1*pdlpfc1 pdlpfc3 ~ 1*pdlpfc2 pdlpfc4 ~ 1*pdlpfc3 # Define Change Latent Variables (d) def21 =~ 1*pef2; def21 ~~ 0*def21 def32 =~ 1*pef3; def32 ~~ 0*def32 def43 =~ 1*pef4; def43 ~~ 0*def43 ddlpfc21 =~ 1*pdlpfc2; ddlpfc21 ~~ 0*ddlpfc21 ddlpfc32 =~ 1*pdlpfc3; ddlpfc32 ~~ 0*ddlpfc32 ddlpfc43 =~ 1*pdlpfc4; ddlpfc43 ~~ 0*ddlpfc43 # Define Proportional Change Regressions (beta = equality constraint) def21 ~ beta1*pef1 + beta3*pdlpfc1 def32 ~ beta1*pef2 + beta3*pdlpfc2 def43 ~ beta1*pef3 + beta3*pdlpfc3 ddlpfc21 ~ beta2*pdlpfc1 + beta4*pef1 ddlpfc32 ~ beta2*pdlpfc2 + beta4*pef2 ddlpfc43 ~ beta2*pdlpfc3 + beta4*pef3 # Define Intercept and Slope int.ef =~ 1*pef1 slp.ef =~ 1*def21 + 1*def32 + 1*def43 int.ef ~ 1; int.ef ~~ int.ef slp.ef ~ 1; slp.ef ~~ slp.ef int.ef ~~ slp.ef int.dlpfc =~ 1*pdlpfc1 slp.dlpfc =~ 1*ddlpfc21 + 1*ddlpfc32 + 1*ddlpfc43 int.dlpfc ~ 1; int.dlpfc ~~ int.dlpfc slp.dlpfc ~ 1; slp.dlpfc ~~ slp.dlpfc int.dlpfc ~~ slp.dlpfc # Cross-Construct Covariances int.ef ~~ int.dlpfc + slp.dlpfc slp.ef ~~ int.dlpfc + slp.dlpfc &quot; multivar.dualchange &lt;- sem(multivar.dualchange, data = executive.function, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(multivar.dualchange, fit.measures = FALSE, estimates = TRUE, standardize = FALSE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 122 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 34 ## Number of equality constraints 8 ## ## Number of observations 342 ## Number of missing patterns 28 ## ## Model Test User Model: ## ## Test statistic 14.490 ## Degrees of freedom 18 ## P-value (Chi-square) 0.697 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## pef1 =~ ## ef1 1.000 ## pef2 =~ ## ef2 1.000 ## pef3 =~ ## ef3 1.000 ## pef4 =~ ## ef4 1.000 ## pdlpfc1 =~ ## dlpfc1 1.000 ## pdlpfc2 =~ ## dlpfc2 1.000 ## pdlpfc3 =~ ## dlpfc3 1.000 ## pdlpfc4 =~ ## dlpfc4 1.000 ## def21 =~ ## pef2 1.000 ## def32 =~ ## pef3 1.000 ## def43 =~ ## pef4 1.000 ## ddlpfc21 =~ ## pdlpfc2 1.000 ## ddlpfc32 =~ ## pdlpfc3 1.000 ## ddlpfc43 =~ ## pdlpfc4 1.000 ## int.ef =~ ## pef1 1.000 ## slp.ef =~ ## def21 1.000 ## def32 1.000 ## def43 1.000 ## int.dlpfc =~ ## pdlpfc1 1.000 ## slp.dlpfc =~ ## ddlpfc21 1.000 ## ddlpfc32 1.000 ## ddlpfc43 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## pef2 ~ ## pef1 1.000 ## pef3 ~ ## pef2 1.000 ## pef4 ~ ## pef3 1.000 ## pdlpfc2 ~ ## pdlpfc1 1.000 ## pdlpfc3 ~ ## pdlpfc2 1.000 ## pdlpfc4 ~ ## pdlpfc3 1.000 ## def21 ~ ## pef1 (bet1) 0.249 0.596 0.418 0.676 ## pdlpfc1 (bet3) 0.069 0.155 0.448 0.654 ## def32 ~ ## pef2 (bet1) 0.249 0.596 0.418 0.676 ## pdlpfc2 (bet3) 0.069 0.155 0.448 0.654 ## def43 ~ ## pef3 (bet1) 0.249 0.596 0.418 0.676 ## pdlpfc3 (bet3) 0.069 0.155 0.448 0.654 ## ddlpfc21 ~ ## pdlpfc1 (bet2) -0.077 0.379 -0.204 0.839 ## pef1 (bet4) 0.067 0.425 0.157 0.875 ## ddlpfc32 ~ ## pdlpfc2 (bet2) -0.077 0.379 -0.204 0.839 ## pef2 (bet4) 0.067 0.425 0.157 0.875 ## ddlpfc43 ~ ## pdlpfc3 (bet2) -0.077 0.379 -0.204 0.839 ## pef3 (bet4) 0.067 0.425 0.157 0.875 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## int.ef ~~ ## slp.ef -0.118 0.244 -0.483 0.629 ## int.dlpfc ~~ ## slp.dlpfc -0.085 0.197 -0.430 0.667 ## int.ef ~~ ## int.dlpfc 0.064 0.043 1.466 0.143 ## slp.dlpfc -0.032 0.164 -0.193 0.847 ## slp.ef ~~ ## int.dlpfc -0.046 0.088 -0.525 0.600 ## slp.dlpfc 0.013 0.041 0.330 0.742 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.000 ## .ef2 0.000 ## .ef3 0.000 ## .ef4 0.000 ## .dlpfc1 0.000 ## .dlpfc2 0.000 ## .dlpfc3 0.000 ## .dlpfc4 0.000 ## int.ef 2.417 0.043 56.656 0.000 ## slp.ef -0.600 1.414 -0.424 0.671 ## int.dlpfc 0.541 0.054 9.978 0.000 ## slp.dlpfc 0.007 0.900 0.008 0.994 ## .pef1 0.000 ## .pef2 0.000 ## .pef3 0.000 ## .pef4 0.000 ## .pdlpfc1 0.000 ## .pdlpfc2 0.000 ## .pdlpfc3 0.000 ## .pdlpfc4 0.000 ## .def21 0.000 ## .def32 0.000 ## .def43 0.000 ## .ddlpfc21 0.000 ## .ddlpfc32 0.000 ## .ddlpfc43 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ef1 0.242 0.040 6.105 0.000 ## .pef1 0.000 ## .ef2 0.258 0.028 9.325 0.000 ## .pef2 0.000 ## .ef3 0.269 0.033 8.177 0.000 ## .pef3 0.000 ## .ef4 0.096 0.074 1.296 0.195 ## .pef4 0.000 ## .dlpfc1 0.219 0.130 1.689 0.091 ## .pdlpfc1 0.000 ## .dlpfc2 0.571 0.060 9.447 0.000 ## .pdlpfc2 0.000 ## .dlpfc3 0.573 0.060 9.489 0.000 ## .pdlpfc3 0.000 ## .dlpfc4 0.415 0.105 3.966 0.000 ## .pdlpfc4 0.000 ## .def21 0.000 ## .def32 0.000 ## .def43 0.000 ## .ddlpfc21 0.000 ## .ddlpfc32 0.000 ## .ddlpfc43 0.000 ## int.ef 0.427 0.048 8.873 0.000 ## slp.ef 0.053 0.114 0.462 0.644 ## int.dlpfc 0.788 0.136 5.791 0.000 ## slp.dlpfc 0.080 0.031 2.614 0.009 This absolute wall of syntax specifies a really compelling model of change. Not only does change depend on the prior level within a variable, it also depends on the prior level of the other variable in the model. These non-linearities can provide a powerful and flexible tool to assess reciprocal relationships among variables as they travel together over time. Now that we have a taste of the power, we can turn to the process of fitting multivariate models in the MLM. Unfortunately, the MLM is fundamentally a univariate model that we will need to trick in order to turn into a multivariate model. To do so, we need to do some data management to combine our two outcomes (ef and dlpfc) into a single column. However, to keep track of which values correspond to which outcome, we will also create a set of dummy codes that indicate the original variable. The easiest way to do this is to begin by stacking our data frame on top of itself and then generating these new variables. multivar.long &lt;- rbind(executive.function.long, executive.function.long) multivar.long$dv &lt;- c(executive.function.long$ef, executive.function.long$dlpfc) multivar.long$ef_dummy &lt;- c(rep(1, nrow(executive.function.long)), rep(0, nrow(executive.function.long))) multivar.long$dlpfc_dummy &lt;- c(rep(0, nrow(executive.function.long)), rep(1, nrow(executive.function.long))) multivar.long$dv_factor &lt;- factor(multivar.long$ef_dummy, levels = c(0, 1), labels = c(&quot;DLPFC&quot;, &quot;EF&quot;)) multivar.long &lt;- multivar.long %&gt;% arrange(id) It’s helpful to visualize what this results in for our data. We can display the first three participants’ data below. multivar.long %&gt;% filter(id &lt;= 3) %&gt;% kable(label = NA, format = &quot;html&quot;, digits = 3, booktabs = TRUE, escape = FALSE, caption = &quot;**Executive Function Multivariate Data**&quot;, align = &quot;c&quot;, row.names = FALSE) %&gt;% row_spec(row = 0, align = &quot;c&quot;) Executive Function Multivariate Data id sex tx wave dlpfc ef age dlpfc.lag dv ef_dummy dlpfc_dummy dv_factor 1 1 0 0 -0.184 2.167 0.285 0.000 2.167 1 0 EF 1 1 0 1 1.129 1.806 1.316 -0.184 1.806 1 0 EF 1 1 0 2 -0.840 1.444 2.332 1.129 1.444 1 0 EF 1 1 0 3 0.472 2.889 3.370 -0.840 2.889 1 0 EF 1 1 0 0 -0.184 2.167 0.285 0.000 -0.184 0 1 DLPFC 1 1 0 1 1.129 1.806 1.316 -0.184 1.129 0 1 DLPFC 1 1 0 2 -0.840 1.444 2.332 1.129 -0.840 0 1 DLPFC 1 1 0 3 0.472 2.889 3.370 -0.840 0.472 0 1 DLPFC 2 1 0 0 0.801 0.722 0.347 0.000 0.722 1 0 EF 2 1 0 1 1.129 1.444 1.382 0.801 1.444 1 0 EF 2 1 0 2 0.801 1.806 2.256 1.129 1.806 1 0 EF 2 1 0 3 1.457 2.528 3.279 0.801 2.528 1 0 EF 2 1 0 0 0.801 0.722 0.347 0.000 0.801 0 1 DLPFC 2 1 0 1 1.129 1.444 1.382 0.801 1.129 0 1 DLPFC 2 1 0 2 0.801 1.806 2.256 1.129 0.801 0 1 DLPFC 2 1 0 3 1.457 2.528 3.279 0.801 1.457 0 1 DLPFC 3 1 1 0 0.472 3.250 0.211 0.000 3.250 1 0 EF 3 1 1 1 1.129 3.250 1.306 0.472 3.250 1 0 EF 3 1 1 2 0.144 2.528 2.079 1.129 2.528 1 0 EF 3 1 1 3 0.144 2.528 3.317 0.144 2.528 1 0 EF 3 1 1 0 0.472 3.250 0.211 0.000 0.472 0 1 DLPFC 3 1 1 1 1.129 3.250 1.306 0.472 1.129 0 1 DLPFC 3 1 1 2 0.144 2.528 2.079 1.129 0.144 0 1 DLPFC 3 1 1 3 0.144 2.528 3.317 0.144 0.144 0 1 DLPFC We’ve doubled the number of rows per participant and when ef_dummy \\(= 1\\), the value of dv is the same as ef and the same as dlpfc when ef_dummy \\(= 0\\). Creating the factor variable (dv_factor) is both to help us keep track of which value is which more easily and will play a role in structuring the covariance matrix in the model syntax. In order to best approximate the full bivariate growth model we fit with the LCM, we need to fit a more-complex variance structure than is currently available in lmer. As such, we will return to nlme for this section. The syntax is a bit odd, so we will cover it in-depth before we fit the model. We will model the combined dv variable as a function of our constructed dummy variables and their interactions with age. We will not model an overall intercept (dv ~ 0) since dv is a combination of our two outcomes. Instead, our dummy codes (ef_dummy and dlpfc_dummy) will estimate our outcome-specific intercepts, and the interactions (ef_dummy:age and dlpfc_dummy:age) will estimate the outcome-specific slopes. We will include all of these effects in the random effects argument as well. We will estimate different residual variances for each outcome using the weights argument and nesting our estimates within our dv_factor (this must be a different variable than one that appears in our formula for some reason). We will updates some options in our lmeControl() function to aid in convergence. lmeCtlList = lmeControl(maxIter = 10000, msMaxIter = 10000, tolerance = 1e-7, niterEM = 10000, msMaxEval = 10000, msVerbose = FALSE, returnObject = FALSE, gradHess = TRUE, opt = &#39;optim&#39;, optimMethod = &#39;Nelder-Mead&#39;) bivar.mod = lme(dv ~ 0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age, random = list(id = ~ 0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age), weights = varIdent(form = ~ 1 | dv_factor), na.action = na.omit, method = &#39;REML&#39;, data = multivar.long, control = lmeCtlList) summary(bivar.mod, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: multivar.long ## AIC BIC logLik ## 6096.803 6190.317 -3032.401 ## ## Random effects: ## Formula: ~0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## ef_dummy 0.60518018 ef_dmm dlpfc_ ef_dm: ## dlpfc_dummy 0.84810498 0.164 ## ef_dummy:age 0.06661496 0.603 0.228 ## age:dlpfc_dummy 0.23083480 -0.162 -0.441 0.544 ## Residual 0.51369758 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | dv_factor ## Parameter estimates: ## EF DLPFC ## 1.000000 1.359233 ## Fixed effects: dv ~ 0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age ## Value Std.Error DF t-value p-value ## ef_dummy 2.3978105 0.04222929 2211 56.78075 0e+00 ## dlpfc_dummy 0.5165680 0.05809525 2211 8.89174 0e+00 ## ef_dummy:age 0.0524502 0.01389671 2211 3.77429 2e-04 ## age:dlpfc_dummy 0.1180178 0.02152941 2211 5.48170 0e+00 ## Correlation: ## ef_dmm dlpfc_ ef_dm: ## dlpfc_dummy 0.101 ## ef_dummy:age -0.383 0.045 ## age:dlpfc_dummy -0.074 -0.619 0.087 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.2972806148 -0.5072575404 0.0006136973 0.5483199752 2.9557944969 ## ## Number of Observations: 2556 ## Number of Groups: 342 While we do get the effects of interest with this model, there is an important remaining mis-specification. With the model above, we have to assume that the time-specific residuals are independent (covariances set to zero). This is a very untenable assumption, so we need to add a new argument to our model. The correlation argument in nlme allows us to correlate observations within a given age. Note that we nest that correlation within individual (id) and then age. bivar.mod = lme(dv ~ 0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age, random = list(id = ~ 0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age), weights = varIdent(form = ~ 1 | dv_factor), correlation = corSymm(form= ~ 1 | id / age), na.action = na.omit, method = &#39;REML&#39;, data = multivar.long, control = lmeCtlList) summary(bivar.mod, correlation = FALSE) ## Linear mixed-effects model fit by REML ## Data: multivar.long ## AIC BIC logLik ## 6098.521 6197.879 -3032.26 ## ## Random effects: ## Formula: ~0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## ef_dummy 0.61734102 ef_dmm dlpfc_ ef_dm: ## dlpfc_dummy 0.84412177 0.124 ## ef_dummy:age 0.05911848 0.521 0.411 ## age:dlpfc_dummy 0.22681712 -0.121 -0.436 0.481 ## Residual 0.51539308 ## ## Correlation Structure: General ## Formula: ~1 | id/age ## Parameter estimate(s): ## Correlation: ## 1 ## 2 0.034 ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | dv_factor ## Parameter estimates: ## EF DLPFC ## 1.000000 1.359071 ## Fixed effects: dv ~ 0 + ef_dummy + ef_dummy:age + dlpfc_dummy + dlpfc_dummy:age ## Value Std.Error DF t-value p-value ## ef_dummy 2.3968681 0.04279496 2211 56.00819 0e+00 ## dlpfc_dummy 0.5166041 0.05799390 2211 8.90790 0e+00 ## ef_dummy:age 0.0535814 0.01381578 2211 3.87827 1e-04 ## age:dlpfc_dummy 0.1179464 0.02144521 2211 5.49989 0e+00 ## Correlation: ## ef_dmm dlpfc_ ef_dm: ## dlpfc_dummy 0.089 ## ef_dummy:age -0.409 0.058 ## age:dlpfc_dummy -0.069 -0.618 0.094 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -3.313960152 -0.505059042 0.008674745 0.546833154 2.948330769 ## ## Number of Observations: 2556 ## Number of Groups: 342 With this specification we do allow the residuals to correlate, but they are constrained to be equal across all of the time points in our model. Freeing this residual constraint to allow for unique correlations is possible, but requires us to fit the model in SAS. This model syntax will be provided in the downloadable files. Within- and Betwen-Person Variance In longitudinal models, we are deeply interested in understanding within-person processes (i.e., how individuals change over time). However, we need to be on guard against between-person differences masquerading as these within-person effects. For instance, there is a substantively different understanding of adolescent substance use if it is guided by within-person effects (e.g., adolescent are more likely to use illicit drugs when they are with their peers) versus between-person effects (e.g., adolescents with more friends are more likely to use illicit drugs). Unfortunately, we can often unintentionally conflate these two types of effects in our models. This happens because variables at level \\(1\\) (e.g., TVCs) contain information about both within- (level \\(1\\)) and between- (level \\(2\\)) person differences. To take our example thus far, individuals might show higher or lower DLPFC activation relative to the last time they played the task (i.e., within-person differences) but also some individuals might consistently show higher (or lower) than average DLFPC activation relative to other individuals in the sample (i.e., between-person differences). We can return to our contemporaneous TVC model to demonstrate this principle. Below is the model we fit before. uncens.mlm &lt;- lmer(ef ~ 1 + age + dlpfc + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(uncens.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2550 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2978 -0.4809 0.0377 0.5297 3.1320 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.42998 0.6557 ## age 0.01877 0.1370 -0.10 ## Residual 0.23913 0.4890 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.371e+00 4.505e-02 3.626e+02 52.623 &lt; 2e-16 *** ## age 4.610e-02 1.516e-02 2.951e+02 3.041 0.00257 ** ## dlpfc 5.633e-02 2.062e-02 1.197e+03 2.732 0.00638 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 So now we know that the coefficient associated with the dlpfc predictor is a weighted combination of the within- and between-person effect. We can apply well-known principles of variable centering in the MLM in order to separate out these effects. For a more in-depth treatment of these approaches, see Curran &amp; Bauer (2011). The first approach is called grand-mean centering. Here we do something relatively intuitive and simply subtract the mean of all of the observations of dlpfc across individuals to create dlpfc.grdcent. This simply makes the zero-point of dlpfc represent the mean of the variable. Unsurprisingly, this simple linear transformation of our model will not change the model results except to change the interpretation of the intercept (i.e., the expected value of the outcome when all predictors are zero will change because the zero-point of dlpfc.grdcent has changed). However, the effect of dlpfc.grdcent will still confound the within- and between-person effects. executive.function.long &lt;- executive.function.long %&gt;% mutate(dlpfc.grdcent = dlpfc - mean(executive.function.long$dlpfc, na.rm = TRUE)) grdcent.mlm &lt;- lmer(ef ~ 1 + age + dlpfc.grdcent + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(grdcent.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc.grdcent + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2550 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2978 -0.4809 0.0377 0.5297 3.1320 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.42998 0.6557 ## age 0.01877 0.1370 -0.10 ## Residual 0.23913 0.4890 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.411e+00 4.393e-02 3.372e+02 54.886 &lt; 2e-16 *** ## age 4.610e-02 1.516e-02 2.951e+02 3.041 0.00257 ** ## dlpfc.grdcent 5.633e-02 2.062e-02 1.197e+03 2.732 0.00638 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In order to disaggregate these effects, we need to include the person-specific means of dlpfc as an additional predictor. Creating this variable is straightforward, we will just need to remember to do the mean operation within-person by using the group_by(id) function. The syntax for this model is below. executive.function.long &lt;- executive.function.long %&gt;% group_by(id) %&gt;% mutate(dlpfc.mean = mean(dlpfc, na.rm = TRUE)) grdcent.mlm &lt;- lmer(ef ~ 1 + age + dlpfc.grdcent + dlpfc.mean + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(grdcent.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc.grdcent + dlpfc.mean + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2551.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2992 -0.4855 0.0375 0.5286 3.1170 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.43366 0.6585 ## age 0.01899 0.1378 -0.13 ## Residual 0.23880 0.4887 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.34839 0.05851 472.22497 40.136 &lt; 2e-16 *** ## age 0.04825 0.01522 295.72959 3.171 0.00168 ** ## dlpfc.grdcent 0.03965 0.02308 889.69637 1.718 0.08613 . ## dlpfc.mean 0.08332 0.05105 507.67410 1.632 0.10328 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 By conditioning the effect of dlpfc.grdcent on the effect of dlpfc.mean, we get a pure estimate of the within-person effect of DLPFC activation on executive function scores. The effect of dlpfc.mean itself is a little harder to interpret. With grand-mean centering, the effect of dlpfc.mean represents the difference between the within- and between-person effect. If we wish to compute the between-person effect itself, we can linearly combine the parameter estimates using the contest1D() function from the lmerTest package. This function will compute both the point estimate and inferential test for the computed parameter. The vector of weights (c(0, 0, 1, 1)) tells the function to ignore the (Intercept) and age coefficients and to add the dlpfc.grdcent (within-person effect) and dlpfc.mean (between- minus within-person effect) coefficients together. Since the within-person effects cancel each other out in this equation, we are left with the pure between-person effect. lmerTest::contest1D(grdcent.mlm, c(0, 0, 1, 1)) ## Estimate Std. Error df t value Pr(&gt;|t|) ## 1 0.1229694 0.04560471 330.8157 2.696419 0.007367606 We can see that the between-person effect (\\(\\gamma = 0.123\\)) is substantially larger than the within-person effect (\\(\\gamma = 0.040\\)). While the grand-mean centering approach is relatively intuitive in the centering process (simply subtract a single value from all observations), the effects it produces are less intuitive. We must include the person-specific means in the model to get de-confounded effects, and the effect of the person-specific means is not always what we wish to interpret and we run the risk of mis-interpreting it as the between-person effect itself rather than the difference in effects. Thus, we might wish to consider an alternative centering approach. This alternative is group-mean centering. Unlike grand-mean centering, here we will subtract a different value (namely the person-mean) from each person’s observations. As such, our new predictor (dlpfc.grpcent) is fundamentally different from the original dlpfc variable because we have removed all mean differences between individuals from the new variable. Because we have discarded this information, the group-mean centered variable can give us a pure estimate of the within-person effect even if we do not include the group means in the model. As such, if we only care about the within-person effect, we can obtain that effect without needing to include the additional predictor in the model. We can see this model below. executive.function.long &lt;- executive.function.long %&gt;% mutate(dlpfc.grpcent = dlpfc - dlpfc.mean) grpcent.mlm &lt;- lmer(ef ~ 1 + age + dlpfc.grpcent + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(grpcent.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc.grpcent + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2554.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.3069 -0.4910 0.0335 0.5368 3.1355 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.43351 0.6584 ## age 0.01883 0.1372 -0.08 ## Residual 0.23884 0.4887 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.40789 0.04407 338.52746 54.639 &lt; 2e-16 *** ## age 0.04769 0.01521 296.02312 3.136 0.00188 ** ## dlpfc.grpcent 0.03948 0.02305 888.90401 1.713 0.08710 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 If we are interested in both the within- and between-person effects; however, we can include the person-specific means (dlpfc.mean) as we did before. As an added bonus, the effect of dlpfc.mean is a pure estimate of the between-person effect without needing to do any additional transformations. grpcent.mlm &lt;- lmer(ef ~ 1 + age + dlpfc.grpcent + dlpfc.mean + (1 + age | id), na.action = na.omit, REML = TRUE, data = executive.function.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) summary(grpcent.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: ef ~ 1 + age + dlpfc.grpcent + dlpfc.mean + (1 + age | id) ## Data: executive.function.long ## Control: lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e+05)) ## ## REML criterion at convergence: 2551.5 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -3.2992 -0.4855 0.0375 0.5286 3.1170 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 0.43366 0.6585 ## age 0.01899 0.1378 -0.13 ## Residual 0.23880 0.4887 ## Number of obs: 1241, groups: id, 342 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 2.31971 0.05478 377.98608 42.345 &lt; 2e-16 *** ## age 0.04825 0.01522 295.72959 3.171 0.00168 ** ## dlpfc.grpcent 0.03965 0.02308 889.69639 1.718 0.08613 . ## dlpfc.mean 0.12297 0.04560 330.81567 2.696 0.00737 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Of course, if we wished to get the difference in effects, we can compute it from this model (essentially the inverse of what we did previously). Here we subtract the within-person effect from the between-person effect. contest1D(grpcent.mlm, c(0, 0, -1, 1)) ## Estimate Std. Error df t value Pr(&gt;|t|) ## 1 0.08332361 0.05105263 507.674 1.632112 0.103276 Fortunately for us, we have already seen one of the primary methods for separating within- versus between-person effects in the SEM: the LCM-SR. In these models, all of the between-person effects are isolated to the level of the latent factors, while the within-person effects are isolated to the residuals of the repeated measures. If we have a TVC model, our grand- or group-mean centered variables enter as preditors of the repeated measure residuals, while the person-specific means enter as predictors of the latent factors. While this is equivalent to the MLM in the case of TVCs, the expanded capacity of the SEM allows us to include multiple outcomes and reciprocal effects between different constructs traveling together across time. With the growth factors isolating the between-person effects, these reciprocal effects represent pure estimates of within-person effects. Distal Outcomes Up until this point, we have considered how to include predictors in our growth models to explain individual differences in patterns of change over time. However, if we think that these differences in developmental trajectories mean anything (and we’d like to think they do), we might wish to predict some future outcome that is meaningful for our theoretical question of interest. For instance, do greater increases in executive function scores during adolescence predict greater education attainment, lifetime earnings, or reduced contact with criminal-legal institutions? Such questions are uncomfortably rare in developmental cognitive neuroscience, leaving a big opening for questions of “so what?” for our programs of research. Commensurate with their relative scarcity in substantive research, much less work has gone into the development of quantitative methods and best-practices for distal outcome prediction. As such, readers should take the methods presented in this section as a work-in-progress, awaiting further developments (some of which we can confidently say are in the works). For this section, we will draw the externalizing data from our external.math data set. However, here we have included data from a follow-up study on lifetime incarceration as of age \\(35\\). As such, we can predict the likelihood of an individual experiencing incarceration as an adult based on trajectory information from when they were in early adolescence. externalizing &lt;- read.csv(&quot;data/externalizing-outcome.csv&quot;, header = TRUE) externalizing.long &lt;- externalizing %&gt;% pivot_longer(cols = starts_with(&quot;ext&quot;), names_to = c(&quot;.value&quot;, &quot;age&quot;), names_pattern = &quot;(ext)(.+)&quot;) %&gt;% mutate(age = as.numeric(age)) In the MEMs, outcome prediction usually proceeds via a two-step procedure (with Mplus again being an exception for reasons we have already discussed). As such, we fit the growth model to the repeated measures data, obtain individual estimates of the random effects, and then predict the distal outcome in a second regression analysis. The linear model we fit will be familiar to use, and then we can use the ranef() function from lme4 to obtain our estimates of the random effects. Note that these are Empirical Bayes (EB) estimates of the random effects, which have som enice statistical properties. For our purposes, we should know that EB estimates are “shrunken” meaning that individuals with more extreme values and those individuals with that contribute fewer data points to the model are shrunk towards the mean effect. This helps to reduce outliers and differences in reliability for individual estimates based on smaller numbers of repeated measures. We can see the code to obtain these effects below. distal.mlm &lt;- lmer(ext ~ 1 + age + (1 + age | id), na.action = na.omit, REML = TRUE, data = externalizing.long, control = lmerControl(optimizer = &quot;bobyqa&quot;, optCtrl = list(maxfun = 2e5))) random.effs &lt;- ranef(distal.mlm)$id names(random.effs) &lt;- c(&quot;int&quot;, &quot;slp&quot;) externalizing &lt;- cbind(externalizing, random.effs) Now that we have obtained these EB estimates, we can bring them into the secondary regression analysis. Here our outcome of lifetime incarceration (incarc) is binary ($0 = $ “never incarcerated”, $1 = $ “ever incarcerated”), so we will utilize the glm() function (“generalized linear model”) instead of lm() (“general linear model”) to deal with the discrete nature of our outcome. While we won’t spend much time on the distinctions between linear and nonlinear models, see here for a great general review of the topic in R. distal.glm &lt;- glm(incarc ~ 1 + int + slp, family = &quot;binomial&quot;, data = externalizing) summary(distal.glm) ## ## Call: ## glm(formula = incarc ~ 1 + int + slp, family = &quot;binomial&quot;, data = externalizing) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.7151 -0.3186 -0.2004 -0.1445 2.8305 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.391 0.318 -10.666 &lt;2e-16 *** ## int 2.875 1.270 2.263 0.0236 * ## slp 5.710 3.274 1.744 0.0811 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 203.63 on 404 degrees of freedom ## Residual deviance: 149.99 on 402 degrees of freedom ## AIC: 155.99 ## ## Number of Fisher Scoring iterations: 6 externalizing &lt;- externalizing %&gt;% select(-c(int, slp)) We can see that while the intercept of the trajectory has a significant positive prospective effect on the propensity for individuals to experience lifetime incarceration, the slope is not significant (so close; more on that in a bit). Essentially, those adolescents who show higher initial levels of antisocial behavior are more likely to report being incarcerated at some point in their lifetime. The coefficients we see in this model represent the log-odds parameters. You might see these reported in the odds scale, which just involves the exponentiation of these parameters. We can see this below and generate confidence intervals on the odds parameters. exp(cbind(coef(distal.glm), confint(distal.glm))) ## 2.5 % 97.5 % ## (Intercept) 0.03366191 0.01685404 5.927967e-02 ## int 17.72246349 1.49556757 2.248848e+02 ## slp 301.85964003 0.51755237 2.085331e+05 So for a one unit increase in the trajectory intercept, we expect a 17.72 change in the odds of being incarcerated, and a substantial increase of 301.85 in the odds for a per-unit change in the slope of the trajectory (again not significant but we can play out this exercise). One reason we often need to be careful about these “per one unit” changes in the trajectory parameters, especially for the slope, is that often the parameters do not have large ranges. Indeed, often the full range of the slope parameter will not extend over an entire unit because of the way it is scaled (in per time-unit change). We can see this when we plot the predicted probabilities of incarceration against the trajectory parameters. Note that to get the predicted probabilities, we simply divide the odds by \\(1\\) plus the odds. So \\(P(incarc_{i} = 1) = e^{log-odds} / 1 + e^{log-odds}\\). We can see this below. random.effs &lt;- random.effs %&gt;% mutate(incarc = externalizing$incarc, pred = stats::predict.glm(distal.glm)) %&gt;% mutate(pred.prob = exp(pred) / (1 + exp(pred))) head(random.effs) ## int slp incarc pred pred.prob ## 1 -0.08707305 -0.10376294 0 -4.234191 0.014284520 ## 2 -0.10130152 -0.03397105 0 -3.876587 0.020300771 ## 3 -0.29188615 -0.08666453 0 -4.725364 0.008789548 ## 4 0.42109753 0.13725150 0 -1.397103 0.198276302 ## 5 0.26380031 0.20359046 1 -1.470513 0.186864687 ## 6 0.21702008 0.10030029 0 -2.194781 0.100220132 ggplot(random.effs, aes(x = int, y = incarc)) + geom_point(aes(color = factor(incarc)), shape = &quot;|&quot;, size = 3) + geom_point(data = random.effs, mapping = aes(x = int, y = pred.prob, color = factor(incarc))) + ylim(0, 1) + stat_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = TRUE) + labs(title = &quot;Plotting Predicted Probabilities of Lifetime Incarceration&quot;, x = &quot;Intercept (Wave 1) of Adolescent Antisocial Behavior&quot;, y = &quot;Predicted Probability of Incarceration&quot;) + theme(legend.position = &quot;none&quot;) ggplot(random.effs, aes(x = slp, y = incarc)) + geom_point(aes(color = factor(incarc)), shape = &quot;|&quot;, size = 3) + geom_point(data = random.effs, mapping = aes(x = slp, y = pred.prob, color = factor(incarc))) + ylim(0, 1) + stat_smooth(method = &quot;glm&quot;, method.args = list(family = &quot;binomial&quot;), se = TRUE) + labs(title = &quot;Plotting Predicted Probabilities of Lifetime Incarceration&quot;, x = &quot;Slope of Adolescent Antisocial Behavior&quot;, y = &quot;Predicted Probability of Incarceration&quot;) + theme(legend.position = &quot;none&quot;) As we can see, the slope parameter in particular does not cover a full 1 unit range, and most of the observations are between \\(-0.2\\) and \\(0.2\\). Here we have plotted the predicted probabilities of incarceration (dots) against each of the parameters, color-coded by their observed response on the incarceration item (red = “No”, green = “Yes”). Note that there is some mismatch, especially in the middle-zones of the plots, where some of those who have actually experienced incarceration have low model-implied probabilities, and vice versa. This is perfectly normal and means we simply haven’t included all of the multitude of relevant predictors for lifetime incarceration (which is completely unsurprising given what we know about incarceration patterns in the population). We will not go much further on diagnostics here, but just to note: there is a single point at the very high end of the graph that seems to be anchoring the curve fairly strongly. It would be a great idea to test the model sensitivity to excluding this person from the analysis. Of course, it was a bit of a bummer that the slope term wasn’t quite significant (and yes of course we shouldn’t care, but of course we do). Slope effects are often very interesting from an intervention perspective, with the idea that if we could just bend those curves down during adolescence, perhaps we could avoid some of these negative life outcomes. Well tough cookies in this model, but one of the reasons that we do not get a slope effect for this data in particular is because of the high degree of correlation between the EB estimates of the random effects, which is quite high (\\(r =\\) 0.847). Similar to the ideas outlined in multi-growth models, the correlation in predictors here isn’t doing us any favors. We can check the variance inflation factor for this model below using the vif() function from the car package. car::vif(distal.glm) ## int slp ## 2.772259 2.772259 Which indicates that our standard errors are approximately \\(2.77\\) larger than if we had uncorrelated predictors. While this isn’t enormous, it likely contributes to a non-significant slope effect. This type of correlation between the random effects is not uncommon and is one of the challenges associated with these kinds of questions (although there are some developments that I am currently working on that might help with this, so stay tuned if interested). We can do a very similar 2-step approach with the LCM by generating factor scores. Here we will use the lavPredict() function from lavaan with method = \"regression\". The other option is to use method = \"Bartlett\". In general, regression factor scores perform better as predictors (which is what we want here), while Bartlett scores are better as outcomes (Skrondal &amp; Laak, 2001). lin.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14 &quot; lin.lcm.fit &lt;- growth(lin.lcm, data = externalizing, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) factor.scores &lt;- lavPredict(lin.lcm.fit, type = &quot;lv&quot;, method = &quot;regression&quot;) externalizing &lt;- cbind(externalizing, factor.scores) We can then perform the same regression for step \\(2\\). distal.glm &lt;- glm(incarc ~ 1 + int + slp, family = &quot;binomial&quot;, data = externalizing) summary(distal.glm) ## ## Call: ## glm(formula = incarc ~ 1 + int + slp, family = &quot;binomial&quot;, data = externalizing) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.7234 -0.3135 -0.1990 -0.1407 2.8590 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -6.3940 0.9079 -7.043 1.89e-12 *** ## int 1.9245 0.5964 3.227 0.00125 ** ## slp -3.0144 4.4679 -0.675 0.49988 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 203.63 on 404 degrees of freedom ## Residual deviance: 149.13 on 402 degrees of freedom ## AIC: 155.13 ## ## Number of Fisher Scoring iterations: 6 externalizing &lt;- externalizing %&gt;% select(-c(int, slp)) Now our slope effect is no-where near significance. The correlation between the factor scores here is even higher (\\(r =\\) 0.929) so our VIF is 5.817 which might contribute to that. However, part of it is that factor scores and EM estimates are different ways of estimating an unobserved quantity so we will get different results depending on our approach. One common alternative in SEMs is to go ahead and include the distal outcome into the same model that estimates the trajectory and estimate everything simultaneously we can see the syntax for this model below. The inclusion of the new parameters are trivial from a syntax perspective; we just add the regression directly. However, because incarc is a binary variable, we need to include new options in the growth() function. Specifically, we change the estimator to \"WLSMV\" (see here for details on different estimator options) and indicate that incarc is a categorical variable with ordered = \"incarc\". sim.lcm &lt;- &quot;int =~ 1*ext6 + 1*ext8 + 1*ext10 + 1*ext12 + 1*ext14 slp =~ 0*ext6 + 2*ext8 + 4*ext10 + 6*ext12 + 8*ext14 incarc ~ 1 + int + slp &quot; sim.lcm.fit &lt;- growth(sim.lcm, data = externalizing, estimator = &quot;WLSMV&quot;, ordered = &quot;incarc&quot;) Unfortunately, when we try to estimate this model, we get an error message lavaan ERROR: data contains no observations, which should be slighly concerning… What is happening here is that in this dataset, because no one person is observed on adjacent measures (e.g., ext6 &amp; ext7), everyone has missing data. This was not an issue in the linear versions of the model because we could use Maximum Likelihood, however, currently lavaan does not support categorical ML, and WLSMV will listwise delete individuals with missing data. Unfortunately for us, that’s \\(100\\) percent of adolescents in our sample. We would need to turn to Mplus or another program for results from this model. As we mentioned, this area of methodological research is still relatively under-developed and awaits solutions to many of the limitations we have run into here. "],["06-nesting.html", "Nested Data Unconditional Model Categorical Predictors Multiple Groups Models Fixed Effect Approach Random Effect Approach Cluster Correction", " Nested Data The final topic we will consider is the way we account for nesting within longitudinal data. While technically all of longitudinal modeling involves nested data (i.e., multiple observations nested within the same individual), here we focus more on between-person nesting groups (e.g., classroom, family, data collection sites). As we will see, there are several forms of the models that we have already used that deal with nesting. The achieve dataset we will work with here are from a 4-wave school-based assessment of math and science achievement across ages \\(12\\) - \\(17\\). Schools were drawn from \\(5\\) different metropolitan areas and assessments were conducted by separate research teams in each city. Here we will mostly focus on the science achievement data, but may draw examples from math achievement if they differ in interesting ways. achieve &lt;- read.csv(&quot;data/achieve.csv&quot;, header = TRUE) achieve.wide &lt;- achieve %&gt;% pivot_wider(id_cols = c(&quot;site&quot;, &quot;school&quot;, &quot;id&quot;, &quot;male&quot;), names_from = &quot;wave&quot;, values_from = c(&quot;sci&quot;, &quot;math&quot;), names_sep = &quot;.&quot;, values_fill = NA) As always, we can fit an unconditional growth model to give us a baseline of expectations for the effects we will in subsequent models. Here we will fit the MLM and LCM versions as they are the simplest representations. Unconditional Model unc.mlm &lt;- lmer(sci ~ 1 + wave + (1 + wave | id), na.action = na.omit, REML = TRUE, data = achieve) summary(unc.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: sci ~ 1 + wave + (1 + wave | id) ## Data: achieve ## ## REML criterion at convergence: 24100 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.5673 -0.4152 0.0084 0.4532 4.2100 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 94.998 9.747 ## wave 4.035 2.009 -0.09 ## Residual 12.367 3.517 ## Number of obs: 3643, groups: id, 1200 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 5.881e+01 3.180e-01 1.133e+03 185.0 &lt;2e-16 *** ## wave 1.987e+00 8.716e-02 8.628e+02 22.8 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 unc.lcm &lt;- &quot;int =~ 1*sci.1 + 1*sci.2 + 1*sci.3 + 1*sci.4 slp =~ 0*sci.1 + 1*sci.2 + 2*sci.3 + 3*sci.4&quot; unc.lcm.fit &lt;- growth(unc.lcm, data = achieve.wide, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(unc.lcm.fit, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-12 ended normally after 138 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 9 ## ## Used Total ## Number of observations 1200 1237 ## Number of missing patterns 15 ## ## Model Test User Model: ## ## Test statistic 55.402 ## Degrees of freedom 5 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 3806.133 ## Degrees of freedom 6 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.987 ## Tucker-Lewis Index (TLI) 0.984 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -12038.652 ## Loglikelihood unrestricted model (H1) -12010.951 ## ## Akaike (AIC) 24095.304 ## Bayesian (BIC) 24141.115 ## Sample-size adjusted Bayesian (BIC) 24112.527 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.092 ## 90 Percent confidence interval - lower 0.071 ## 90 Percent confidence interval - upper 0.114 ## P-value RMSEA &lt;= 0.05 0.001 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.031 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 9.722 0.934 ## sci.2 1.000 9.722 0.898 ## sci.3 1.000 9.722 0.851 ## sci.4 1.000 9.722 0.757 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.910 0.176 ## sci.3 2.000 3.820 0.334 ## sci.4 3.000 5.730 0.446 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 3.184 1.033 3.083 0.002 0.172 0.172 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## int 60.782 0.299 203.517 0.000 6.252 6.252 ## slp 2.048 0.090 22.857 0.000 1.072 1.072 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 13.812 1.437 9.610 0.000 13.812 0.128 ## .sci.2 12.641 0.948 13.341 0.000 12.641 0.108 ## .sci.3 8.580 0.950 9.028 0.000 8.580 0.066 ## .sci.4 18.517 1.984 9.331 0.000 18.517 0.112 ## int 94.510 4.430 21.333 0.000 1.000 1.000 ## slp 3.648 0.442 8.256 0.000 1.000 1.000 ## ## R-Square: ## Estimate ## sci.1 0.872 ## sci.2 0.892 ## sci.3 0.934 ## sci.4 0.888 As a general takeaway, we have an average science achievement of around \\(60\\) (these scores are arbitrarily scaled so that isn’t incredibly informative) but more of interest, science achievement is increasing over time approximately \\(2\\) points per year of school. Categorical Predictors Nesting induces correlations between observations because members of the same group are more similar to one another than members of other groups. The practical upshot of these models is that we obtain different values of parameters across group (although the methods for this will vary). Perhaps the simplest method for doing so, and therefore accounting for group differences, is to predict the mean of the outcome variable using a categorical predictor. In longitudinal modeling, this most often occurs at the level of the individual as a TIC. As such, we already know how to fit this kind of model from the last chapter. We can show this syntax again below. Here we predict the intercept and slope random effects with male to examine differences between self-reported males and females. In the MLM syntax, we simply include male in the regression equation if we want to predict mean differences in science achievement. cat.mlm.1 &lt;- lmer(sci ~ 1 + wave + male + (1 + wave | id), na.action = na.omit, REML = TRUE, data = achieve) summary(cat.mlm.1, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: sci ~ 1 + wave + male + (1 + wave | id) ## Data: achieve ## ## REML criterion at convergence: 24092 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.5819 -0.4169 0.0084 0.4561 4.1991 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 94.728 9.733 ## wave 4.041 2.010 -0.09 ## Residual 12.364 3.516 ## Number of obs: 3643, groups: id, 1200 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 58.0466 0.4255 1235.3629 136.425 &lt; 2e-16 *** ## wave 1.9866 0.0872 862.4361 22.783 &lt; 2e-16 *** ## male 1.5965 0.5918 1190.5962 2.698 0.00708 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Here we see that males show \\(1.6\\) units higher science achievement compared with females (the reference category). It is possible to predict other parameters in the model, although the options in mixed-effects models tend to be more limited compared with SEM approaches. For instance, if we thought error variance might differ across groups, we could include this in our MLM syntax through the variance identity (varIdent) function. The form equation, ~ 1 | male, mimics the regression equation where we have a separate “intercept” (here just read this as estimate) nested within group (male). We can then go through the procedure we covered in Chapter 3 to recover the different estimates for males and females (here in standard deviations, but we can easily square these values to obtain variances). cat.mlm.2 &lt;- lme(sci ~ 1 + wave + male, random = ~ 1 + wave | id, weights = varIdent(form = ~ 1 | male), na.action = na.omit, method = &quot;REML&quot;, data = achieve) summary(cat.mlm.2) ## Linear mixed-effects model fit by REML ## Data: achieve ## AIC BIC logLik ## 24090.94 24140.54 -12037.47 ## ## Random effects: ## Formula: ~1 + wave | id ## Structure: General positive-definite, Log-Cholesky parametrization ## StdDev Corr ## (Intercept) 9.705310 (Intr) ## wave 2.004751 -0.091 ## Residual 3.278687 ## ## Variance function: ## Structure: Different standard deviations per stratum ## Formula: ~1 | male ## Parameter estimates: ## 0 1 ## 1.000000 1.153432 ## Fixed effects: sci ~ 1 + wave + male ## Value Std.Error DF t-value p-value ## (Intercept) 58.06283 0.4214427 2442 137.77158 0.0000 ## wave 1.97570 0.0869694 2442 22.71723 0.0000 ## male 1.60921 0.5911793 1198 2.72203 0.0066 ## Correlation: ## (Intr) wave ## wave -0.260 ## male -0.660 -0.019 ## ## Standardized Within-Group Residuals: ## Min Q1 Med Q3 Max ## -4.3578043 -0.4226075 0.0073624 0.4638169 3.9981046 ## ## Number of Observations: 3643 ## Number of Groups: 1200 c(cat.mlm.2$sigma, cat.mlm.2$sigma * exp(as.numeric(cat.mlm.2$modelStruct$varStruct))) ## [1] 3.278687 3.781742 These results show that males appear to have increased variability in their science achievement compared to females in addition to a higher average. Note that we are not getting a direct effect estimate here, but rather estimating values separately for each group. There are not clear ways of implementing that kind of effect in lme4, so we will not go too much further except to mention that within the mixed-effect world of models, you can directly model predictors of variability with location-scale models, although those generally require more intensive longitudinal kinds of data. As such, we will not consider this further. Because these categorical variables enter the model at the person level, in the mixed-effects models they predict the random effects rather than the individual time-specific observations. However, in the SEM, we can additionally predict one (or more) of the individual repeated measures. We can see this approach in a version of a MIMIC model, where we predict both the latent factors and the first repeated measure (sci.1). cat.lcm &lt;- &quot;int =~ 1*sci.1 + 1*sci.2 + 1*sci.3 + 1*sci.4 slp =~ 0*sci.1 + 1*sci.2 + 2*sci.3 + 3*sci.4 int ~ male slp ~ male sci.1 ~ male&quot; cat.lcm.fit &lt;- growth(cat.lcm, data = achieve.wide, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(cat.lcm.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 149 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 12 ## ## Number of observations 1237 ## Number of missing patterns 16 ## ## Model Test User Model: ## ## Test statistic 37.324 ## Degrees of freedom 6 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 9.812 0.944 ## sci.2 1.000 9.812 0.904 ## sci.3 1.000 9.812 0.859 ## sci.4 1.000 9.812 0.768 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.941 0.179 ## sci.3 2.000 3.883 0.340 ## sci.4 3.000 5.824 0.456 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~ ## male 2.659 0.649 4.095 0.000 0.271 0.135 ## slp ~ ## male -0.288 0.217 -1.324 0.186 -0.148 -0.074 ## sci.1 ~ ## male -1.511 0.336 -4.503 0.000 -1.511 -0.073 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .int ~~ ## .slp 2.789 1.036 2.693 0.007 0.148 0.148 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## .int 60.057 0.412 145.793 0.000 6.121 6.121 ## .slp 1.907 0.121 15.788 0.000 0.982 0.982 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 13.139 1.423 9.234 0.000 13.139 0.122 ## .sci.2 12.579 0.946 13.301 0.000 12.579 0.107 ## .sci.3 8.827 0.954 9.255 0.000 8.827 0.068 ## .sci.4 17.512 1.947 8.994 0.000 17.512 0.107 ## .int 94.515 4.423 21.370 0.000 0.982 0.982 ## .slp 3.749 0.440 8.517 0.000 0.995 0.995 These approaches are relatively simple ways to incorporate nesting information into the model, but highlight the continuity with more complex approaches we will discuss as we move forward in this chapter. Multiple Groups Models While the categorical predictor allows us to vary some parameters across groups, a unique power of the SEM is the multiple group model, where we can estimate unique parameters of essentially any type across any number of groups (although the number of groups tends to be small in practice). The reason for a small number of groups tends to be due to sample size requirements within-group. SEM is still a large-sample estimator in the multiple groups model, so we have to be careful we aren’t under-powering the model at the group level, even if the overall sample size is large. Below we can see how the multiple-group LCM is specified. Nothing changes about the syntax object mult.g1 from what we have seen before, however, now we include the argument group = \"male\" to indicate that we want to obtain unique estimates for females and males. Typically, these models require setting some small set of parameters equal in the model just to identify the model, so here we conveniently achieve this through having the same set factor loadings for the growth model. We can see the results below. mult.g1 &lt;- &quot;int =~ 1*sci.1 + 1*sci.2 + 1*sci.3 + 1*sci.4 slp =~ 0*sci.1 + 1*sci.2 + 2*sci.3 + 3*sci.4&quot; mult.g1.fit &lt;- growth(mult.g1, data = achieve.wide, group = &quot;male&quot;, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(mult.g1.fit, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 226 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 18 ## ## Number of observations per group: Used Total ## 1 576 600 ## 0 624 637 ## Number of missing patterns per group: ## 1 15 ## 0 15 ## ## Model Test User Model: ## ## Test statistic 61.451 ## Degrees of freedom 10 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## 1 30.756 ## 0 30.695 ## ## Model Test Baseline Model: ## ## Test statistic 3772.258 ## Degrees of freedom 12 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.986 ## Tucker-Lewis Index (TLI) 0.984 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -12013.745 ## Loglikelihood unrestricted model (H1) -11983.019 ## ## Akaike (AIC) 24063.489 ## Bayesian (BIC) 24155.111 ## Sample-size adjusted Bayesian (BIC) 24097.936 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.093 ## 90 Percent confidence interval - lower 0.071 ## 90 Percent confidence interval - upper 0.115 ## P-value RMSEA &lt;= 0.05 0.001 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.036 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## ## Group 1 [1]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 10.624 0.933 ## sci.2 1.000 10.624 0.903 ## sci.3 1.000 10.624 0.859 ## sci.4 1.000 10.624 0.765 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.824 0.155 ## sci.3 2.000 3.648 0.295 ## sci.4 3.000 5.472 0.394 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 4.373 1.704 2.567 0.010 0.226 0.226 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## int 61.564 0.472 130.490 0.000 5.795 5.795 ## slp 2.217 0.136 16.342 0.000 1.216 1.216 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 16.927 2.377 7.121 0.000 16.927 0.130 ## .sci.2 13.629 1.534 8.882 0.000 13.629 0.098 ## .sci.3 9.128 1.557 5.861 0.000 9.128 0.060 ## .sci.4 24.031 3.370 7.131 0.000 24.031 0.124 ## int 112.875 7.647 14.760 0.000 1.000 1.000 ## slp 3.327 0.713 4.665 0.000 1.000 1.000 ## ## ## Group 2 [0]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 8.752 0.936 ## sci.2 1.000 8.752 0.894 ## sci.3 1.000 8.752 0.844 ## sci.4 1.000 8.752 0.750 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.967 0.201 ## sci.3 2.000 3.934 0.379 ## sci.4 3.000 5.901 0.506 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 1.811 1.234 1.467 0.142 0.105 0.105 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## int 60.051 0.372 161.225 0.000 6.861 6.861 ## slp 1.902 0.118 16.087 0.000 0.967 0.967 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 10.906 1.731 6.301 0.000 10.906 0.125 ## .sci.2 11.783 1.175 10.028 0.000 11.783 0.123 ## .sci.3 8.222 1.177 6.984 0.000 8.222 0.076 ## .sci.4 13.792 2.349 5.870 0.000 13.792 0.101 ## int 76.605 4.979 15.386 0.000 1.000 1.000 ## slp 3.870 0.547 7.069 0.000 1.000 1.000 We can see that we now have separate test statistics and sample sizes that reflect the fact that we are - to a large extent - estimating separate models. We also can see that our parameter estimates are broken up into Group 1 [1] and Group 2 [0]. The value in brackets represents the value of the grouping variable male, so here Group 1 is males and Group 2 is female (you could change this variable into a labeled factor and then those labels would be more informative). It’s important to note the ordering of the groups for future steps. Here we can qualitatively say that among other things, males seem to start higher (\\(61.6\\) vs. \\(60.1\\)) and increase more rapidly (\\(2.22\\) vs. \\(1.90\\)) in their achievement, and have a higher correlation between starting point and rate of change (\\(r = 0.226\\) vs. \\(r = .105\\)), compared with females. However, a natural question is whether these differences are significant. We can explicitly test differences across groups by introducing group-specific labels into our model syntax and building composite parameters where we get a formal inferential test on the difference. A really nice feature of maximum likelihood parameters is that linear operations on the parameter are themselves maximum likelihood parameters themselves. To achieve this, we simply pre-multiply a given parameter by a vector of labels (e.g., c(Mi, Fi)) and then define the composite parameter using the := operator. Here we will test the difference between the intercept (c(Mi, Fi)) and slope factor means (c(Ms, Fs)), and the covariance between factors (c(Mc, Fc)). This is where keeping track of the group order becomes important so we don’t mis-label our parameters of interest and reverse our inference. The D* composite parameters are then created by simply subtracting F* from the M* parameters. mult.g2 &lt;- &quot;int =~ 1*sci.1 + 1*sci.2 + 1*sci.3 + 1*sci.4 slp =~ 0*sci.1 + 1*sci.2 + 2*sci.3 + 3*sci.4 int ~ c(Mi, Fi)*1 slp ~ c(Ms, Fs)*1 int ~~ c(Mc, Fc)*slp Di := Mi - Fi Ds := Ms - Fs Dc := Mc - Fc&quot; mult.g2.fit &lt;- growth(mult.g2, data = achieve.wide, group = &quot;male&quot;, estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(mult.g2.fit, fit.measures = FALSE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 215 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 18 ## ## Number of observations per group: Used Total ## 1 576 600 ## 0 624 637 ## Number of missing patterns per group: ## 1 15 ## 0 15 ## ## Model Test User Model: ## ## Test statistic 61.451 ## Degrees of freedom 10 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## 1 30.756 ## 0 30.695 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## ## Group 1 [1]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 10.624 0.933 ## sci.2 1.000 10.624 0.903 ## sci.3 1.000 10.624 0.859 ## sci.4 1.000 10.624 0.765 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.824 0.155 ## sci.3 2.000 3.648 0.295 ## sci.4 3.000 5.472 0.394 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp (Mc) 4.373 1.704 2.567 0.010 0.226 0.226 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int (Mi) 61.564 0.472 130.490 0.000 5.795 5.795 ## slp (Ms) 2.217 0.136 16.342 0.000 1.216 1.216 ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 16.927 2.377 7.121 0.000 16.927 0.130 ## .sci.2 13.629 1.534 8.882 0.000 13.629 0.098 ## .sci.3 9.128 1.557 5.861 0.000 9.128 0.060 ## .sci.4 24.031 3.370 7.131 0.000 24.031 0.124 ## int 112.875 7.647 14.760 0.000 1.000 1.000 ## slp 3.327 0.713 4.665 0.000 1.000 1.000 ## ## ## Group 2 [0]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 8.752 0.936 ## sci.2 1.000 8.752 0.894 ## sci.3 1.000 8.752 0.844 ## sci.4 1.000 8.752 0.750 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.967 0.201 ## sci.3 2.000 3.934 0.379 ## sci.4 3.000 5.901 0.506 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp (Fc) 1.811 1.234 1.467 0.142 0.105 0.105 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int (Fi) 60.051 0.372 161.225 0.000 6.861 6.861 ## slp (Fs) 1.902 0.118 16.087 0.000 0.967 0.967 ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 10.906 1.731 6.301 0.000 10.906 0.125 ## .sci.2 11.783 1.175 10.028 0.000 11.783 0.123 ## .sci.3 8.222 1.177 6.984 0.000 8.222 0.076 ## .sci.4 13.792 2.349 5.870 0.000 13.792 0.101 ## int 76.605 4.979 15.386 0.000 1.000 1.000 ## slp 3.870 0.547 7.069 0.000 1.000 1.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## Di 1.513 0.601 2.517 0.012 -1.066 -1.066 ## Ds 0.316 0.180 1.753 0.080 0.249 0.249 ## Dc 2.562 2.104 1.217 0.223 0.120 0.120 We will only focus here on the Defined Parameters section, where we can see that while males have higher absolute estimates on all of these parameters we have tested, only the mean of the intercept factor significantly differs across groups. These are only a subset we chose for demonstration purposes, and we could explore others if we chose. However, this model allows maximally different estimates, which belies one of the real strengths of the multiple-groups model, which is to selectively set a subset of parameters equal across groups. This allows us to bridge the gap between fitting the model in each group uniquely and fitting a single-group model where we ignore nesting altogether. The parameters we set equal benefit from increased power because it is not diluted by the smaller sub-samples and reduce the number of parameters we need to interpret. One common approach is to start with the type of model we first fit, with all parameters unequal, and then progressively build in equality constraints and test whether they reduce the fit of the model. We can do this in two ways, either through the syntax (changing labels like c(Mi, Fi) to be the same like c(i, i)) or through the argument group.equal in the model fitting function. The first approach gives us more control, but can be tedious in large models, while the latter is less precise but quick. For instance, if we want to constrain the factor means equal across groups, we can simply include means in the group.equal argument. We can see the results below. mult.g3 &lt;- &quot;int =~ 1*sci.1 + 1*sci.2 + 1*sci.3 + 1*sci.4 slp =~ 0*sci.1 + 1*sci.2 + 2*sci.3 + 3*sci.4&quot; mult.g3.fit &lt;- growth(mult.g3, data = achieve.wide, group = &quot;male&quot;, group.equal = c(&quot;means&quot;), estimator = &quot;ML&quot;, missing = &quot;FIML&quot;) summary(mult.g3.fit, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = FALSE) ## lavaan 0.6-12 ended normally after 163 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 18 ## Number of equality constraints 2 ## ## Number of observations per group: Used Total ## 1 576 600 ## 0 624 637 ## Number of missing patterns per group: ## 1 15 ## 0 15 ## ## Model Test User Model: ## ## Test statistic 71.847 ## Degrees of freedom 12 ## P-value (Chi-square) 0.000 ## Test statistic for each group: ## 1 37.058 ## 0 34.789 ## ## Model Test Baseline Model: ## ## Test statistic 3772.258 ## Degrees of freedom 12 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.984 ## Tucker-Lewis Index (TLI) 0.984 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -12018.943 ## Loglikelihood unrestricted model (H1) -11983.019 ## ## Akaike (AIC) 24069.886 ## Bayesian (BIC) 24151.327 ## Sample-size adjusted Bayesian (BIC) 24100.505 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.091 ## 90 Percent confidence interval - lower 0.072 ## 90 Percent confidence interval - upper 0.112 ## P-value RMSEA &lt;= 0.05 0.000 ## ## Standardized Root Mean Square Residual: ## ## SRMR 0.058 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## ## Group 1 [1]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 10.658 0.933 ## sci.2 1.000 10.658 0.901 ## sci.3 1.000 10.658 0.857 ## sci.4 1.000 10.658 0.764 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.822 0.154 ## sci.3 2.000 3.643 0.293 ## sci.4 3.000 5.465 0.392 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 4.638 1.697 2.733 0.006 0.239 0.239 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## int (.20.) 60.622 0.295 205.481 0.000 5.688 5.688 ## slp (.21.) 2.037 0.090 22.661 0.000 1.118 1.118 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 17.021 2.367 7.190 0.000 17.021 0.130 ## .sci.2 13.673 1.541 8.872 0.000 13.673 0.098 ## .sci.3 9.399 1.557 6.035 0.000 9.399 0.061 ## .sci.4 23.359 3.312 7.054 0.000 23.359 0.120 ## int 113.598 7.692 14.768 0.000 1.000 1.000 ## slp 3.318 0.710 4.674 0.000 1.000 1.000 ## ## ## Group 2 [0]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int =~ ## sci.1 1.000 8.773 0.936 ## sci.2 1.000 8.773 0.894 ## sci.3 1.000 8.773 0.844 ## sci.4 1.000 8.773 0.749 ## slp =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.975 0.201 ## sci.3 2.000 3.949 0.380 ## sci.4 3.000 5.924 0.505 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int ~~ ## slp 1.853 1.241 1.494 0.135 0.107 0.107 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## int (.20.) 60.622 0.295 205.481 0.000 6.910 6.910 ## slp (.21.) 2.037 0.090 22.661 0.000 1.031 1.031 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 10.894 1.725 6.315 0.000 10.894 0.124 ## .sci.2 11.772 1.171 10.053 0.000 11.772 0.122 ## .sci.3 8.040 1.165 6.902 0.000 8.040 0.074 ## .sci.4 14.177 2.357 6.015 0.000 14.177 0.103 ## int 76.967 5.013 15.354 0.000 1.000 1.000 ## slp 3.899 0.550 7.086 0.000 1.000 1.000 Now note that the factor means (labels .20. and .21.) are equal across males and females. We could mix and match syntax and argument constraints if we like; like many things in SEM, we can have full control as long as we keep things organized. We can test whether this more constrained model fits significantly worse than the maximally-different model using a likelihood ratio test. lavTestLRT(mult.g1.fit, mult.g3.fit) ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## mult.g1.fit 10 24064 24155 61.451 ## mult.g3.fit 12 24070 24151 71.847 10.397 2 0.005526 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Here it appears that constraining the factor means does significantly decrease model fit, so we wouldn’t conclude that this constraint is appropriate. We could do this kind of testing with other parameters if we chose, although we won’t here for space and simplicity. The complexity and utility of the multiple groups models is not something we can explore fully here, and interested readers can find a much larger literature on these kinds of models if they wish to implement them in their own research (see the manuscript for a general starting point). Fixed Effect Approach The fixed effect approach is (rarely for quantitative methods) exactly what it sounds like in the context of mixed-effect models, we simply include our grouping variable as a fixed effect in the model. This has the convenience of account for unmeasured or otherwise unmodeled differences between groups that might bias the effects. In the most common use of the fixed-effects approach, we account for intercept differences by including a main effect of the group. In the context of our data example, we will model the effect of site on science achievement using a fixed approach. Within the lmer() syntax, we can use the short-cute of factor(site) to generate a series of dummy-codes, where site == 1 is the reference category. We can see the results of this below. fixed.mlm1 &lt;- lmer(sci ~ 1 + wave + factor(site) + (1 + wave | id), na.action = na.omit, REML = TRUE, data = achieve) summary(fixed.mlm1, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: sci ~ 1 + wave + factor(site) + (1 + wave | id) ## Data: achieve ## ## REML criterion at convergence: 24082.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.5642 -0.4218 0.0130 0.4559 4.2084 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 94.706 9.732 ## wave 4.048 2.012 -0.10 ## Residual 12.355 3.515 ## Number of obs: 3643, groups: id, 1200 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 58.59757 0.56691 1247.30166 103.363 &lt;2e-16 *** ## wave 1.98858 0.08722 861.42604 22.800 &lt;2e-16 *** ## factor(site)2 1.58400 0.86061 1183.63741 1.841 0.0659 . ## factor(site)3 0.40383 0.89404 1189.48204 0.452 0.6516 ## factor(site)4 0.25571 0.83030 1186.72499 0.308 0.7582 ## factor(site)5 -2.21401 1.05705 1193.40188 -2.095 0.0364 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note that the (Intercept) term is the intercept for Site 1 and each of the effects factor(site)* indicate the relative difference from that term for the other sites. If we wished to use an absolute coding scheme, we change the 1 to a 0 (indicating that we don’t wish to estimate a reference intercept) and re-estimate the model. fixed.mlm2 &lt;- lmer(sci ~ 0 + wave + factor(site) + (1 + wave | id), na.action = na.omit, REML = TRUE, data = achieve) summary(fixed.mlm2, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: sci ~ 0 + wave + factor(site) + (1 + wave | id) ## Data: achieve ## ## REML criterion at convergence: 24082.3 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.5642 -0.4218 0.0130 0.4559 4.2084 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 94.706 9.732 ## wave 4.048 2.012 -0.10 ## Residual 12.355 3.515 ## Number of obs: 3643, groups: id, 1200 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## wave 1.989e+00 8.722e-02 8.614e+02 22.80 &lt;2e-16 *** ## factor(site)1 5.860e+01 5.669e-01 1.247e+03 103.36 &lt;2e-16 *** ## factor(site)2 6.018e+01 6.675e-01 1.226e+03 90.16 &lt;2e-16 *** ## factor(site)3 5.900e+01 7.105e-01 1.240e+03 83.04 &lt;2e-16 *** ## factor(site)4 5.885e+01 6.287e-01 1.248e+03 93.61 &lt;2e-16 *** ## factor(site)5 5.638e+01 9.073e-01 1.231e+03 62.14 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 These results are equivalent to the first coding scheme but we get the intercept estimate for each site instead of computing differences from a chosen site (note the change in what the inference test tells us). Like mentioned above, the fixed effect approach is most commonly used for intercept differences, but can logically be extended to account for effect differences across sites (or another grouping variable). We can accomplish this by modeling the interaction of site with our time predictor like below. fixed.mlm3 &lt;- lmer(sci ~ 1 + wave + factor(site) + wave:factor(site) + (1 + wave | id), na.action = na.omit, REML = TRUE, data = achieve) summary(fixed.mlm3, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: sci ~ 1 + wave + factor(site) + wave:factor(site) + (1 + wave | id) ## Data: achieve ## ## REML criterion at convergence: 24076.6 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.5317 -0.4176 0.0117 0.4573 4.2531 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id (Intercept) 94.674 9.730 ## wave 3.997 1.999 -0.09 ## Residual 12.365 3.516 ## Number of obs: 3643, groups: id, 1200 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 58.40288 0.59914 1154.84398 97.477 &lt;2e-16 *** ## wave 2.13593 0.17030 972.01926 12.542 &lt;2e-16 *** ## factor(site)2 1.74603 0.92295 1120.17539 1.892 0.0588 . ## factor(site)3 1.10856 0.96191 1134.56798 1.152 0.2494 ## factor(site)4 0.03638 0.89457 1141.90715 0.041 0.9676 ## factor(site)5 -1.45252 1.13802 1139.05117 -1.276 0.2021 ## wave:factor(site)2 -0.12248 0.25311 860.24892 -0.484 0.6286 ## wave:factor(site)3 -0.52808 0.26582 877.36603 -1.987 0.0473 * ## wave:factor(site)4 0.15811 0.24806 912.54273 0.637 0.5240 ## wave:factor(site)5 -0.56471 0.31249 860.82676 -1.807 0.0711 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Here we return to the reference coding to test whether the effect of wave differs across sites from the reference. We can see how parameter do tend to multiply rapidly, however, with a relatively small set of grouping levels (here we only have 5 site), this is manageable. With larger numbers of groups (e.g., families), this approach would become less tenable. Note that we still have our random effect across individuals, but we’ve removed site-level differences from those estimates through the use of the fixed effects approach. Very often we will not interpret the associated parameters, but include them to de-confound our estimates of interest. Another thing to mention is that this isn’t a “pure” form of the fixed-effects approach, since we still include the random effect of individual. The purely fixed-effect approach is more common/appropriate for group-based clustered (e.g., site, country) rather than individual-based clustering (as we always have in longitudinal data) since we cannot include individual level fixed-effects without breaking the model (it isn’t identified). Random Effect Approach If we want to move into accounting for grouping variables with many levels, the random effects framework provides a nice and ready solution. Indeed, we have been using it for the nesting of repeated measures within individuals this whole time. Within MEMs, we can include higher levels of nesting by expanding the structure of the random effects in our model syntax. Here we expand our classic (1 + wave | id) to include the higher level of nesting individuals within schools (1 + wave | school/id). rand.mlm &lt;- lmer(sci ~ 1 + wave + (1 + wave | school/id), na.action = na.omit, REML = TRUE, data = achieve) summary(rand.mlm, correlation = FALSE) ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [&#39;lmerModLmerTest&#39;] ## Formula: sci ~ 1 + wave + (1 + wave | school/id) ## Data: achieve ## ## REML criterion at convergence: 23997.8 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.4223 -0.4199 0.0095 0.4600 4.3843 ## ## Random effects: ## Groups Name Variance Std.Dev. Corr ## id:school (Intercept) 84.8326 9.2105 ## wave 3.5757 1.8909 -0.10 ## school (Intercept) 12.8283 3.5817 ## wave 0.5724 0.7566 -0.14 ## Residual 12.3154 3.5093 ## Number of obs: 3643, groups: id:school, 1200; school, 41 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 58.4281 0.6514 35.6571 89.70 &lt; 2e-16 *** ## wave 1.9598 0.1516 34.9520 12.93 7.07e-15 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The ordering of school/id is important otherwise we have schools nested within individual which will make the model sad (it’s true). We can check that we’ve done this in the model summary where we have \\(1200\\) individuals nested within schools (id:school) and \\(41\\) schools. If we compare this model to the model where we ignore nesting within school, we will notice that the fixed effects have not changed that much, but that our estimate of individual-level variance has been broken up into individual- and school-level variability. This situation is fairly common (although not guaranteed), with fixed effects that are relatively robust to omitting higher levels of nesting, but mis-attributed variance estimates at lower levels of nesting that over-estimate inter-individual variance. Compared with the fairly natural extension of the MEMs to higher levels of nesting, multilevel SEM estimation is much more challenging and the current options in R are fairly limited. For instance, lavaan currently only allows complete case continuous data with a random intercept at the higher level of nesting (see the current tutorial). This is an active area of improvement so additional options are likely to be available soon. We provide Mplus examples of the full model that more closely resembles the MLM above. However, for completeness, we fit the model we can in lavaan below. mlsem &lt;- &quot; level: 1 int.w =~ 1*sci.1 + 1*sci.2 + 1*sci.3 + 1*sci.4 slp.w =~ 0*sci.1 + 1*sci.2 + 2*sci.3 + 3*sci.4 sci.1 ~~ a*sci.1 sci.2 ~~ a*sci.2 sci.3 ~~ a*sci.3 sci.4 ~~ a*sci.4 level: 2 int.b =~ 1*sci.1 + 1*sci.2 + 1*sci.3 + 1*sci.4 sci.1 ~~ b*sci.1 sci.2 ~~ b*sci.2 sci.3 ~~ b*sci.3 sci.4 ~~ b*sci.4&quot; mlsem.fit &lt;- growth(mlsem, data = achieve.wide, cluster = &quot;school&quot;, estimator = &quot;ML&quot;, missing = &quot;listwise&quot;, optim.method = &quot;em&quot;) summary(mlsem.fit, fit.measures = TRUE, estimates = TRUE, standardize = TRUE, rsquare = TRUE) ## lavaan 0.6-12 ended normally after 41 iterations ## ## Estimator ML ## Optimization method EM ## Number of model parameters 15 ## Number of equality constraints 6 ## ## Used Total ## Number of observations 482 1237 ## Number of clusters [school] 35 ## ## Model Test User Model: ## ## Test statistic 68.230 ## Degrees of freedom 15 ## P-value (Chi-square) 0.000 ## ## Model Test Baseline Model: ## ## Test statistic 2526.704 ## Degrees of freedom 12 ## P-value 0.000 ## ## User Model versus Baseline Model: ## ## Comparative Fit Index (CFI) 0.979 ## Tucker-Lewis Index (TLI) 0.983 ## ## Loglikelihood and Information Criteria: ## ## Loglikelihood user model (H0) -5969.695 ## Loglikelihood unrestricted model (H1) -5935.580 ## ## Akaike (AIC) 11957.390 ## Bayesian (BIC) 11994.991 ## Sample-size adjusted Bayesian (BIC) 11966.426 ## ## Root Mean Square Error of Approximation: ## ## RMSEA 0.086 ## 90 Percent confidence interval - lower 0.066 ## 90 Percent confidence interval - upper 0.107 ## P-value RMSEA &lt;= 0.05 0.002 ## ## Standardized Root Mean Square Residual (corr metric): ## ## SRMR (within covariance matrix) 0.012 ## SRMR (between covariance matrix) 0.025 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Observed ## Observed information based on Hessian ## ## ## Level 1 [within]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int.w =~ ## sci.1 1.000 8.513 0.947 ## sci.2 1.000 8.513 0.915 ## sci.3 1.000 8.513 0.858 ## sci.4 1.000 8.513 0.789 ## slp.w =~ ## sci.1 0.000 0.000 0.000 ## sci.2 1.000 1.750 0.188 ## sci.3 2.000 3.501 0.353 ## sci.4 3.000 5.251 0.487 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int.w ~~ ## slp.w 1.317 0.922 1.428 0.153 0.088 0.088 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## int.w 3.402 0.427 7.965 0.000 0.400 0.400 ## slp.w 2.098 0.134 15.668 0.000 1.198 1.198 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 (a) 8.373 0.395 21.224 0.000 8.373 0.104 ## .sci.2 (a) 8.373 0.395 21.224 0.000 8.373 0.097 ## .sci.3 (a) 8.373 0.395 21.224 0.000 8.373 0.085 ## .sci.4 (a) 8.373 0.395 21.224 0.000 8.373 0.072 ## int.w 72.471 5.263 13.771 0.000 1.000 1.000 ## slp.w 3.063 0.324 9.441 0.000 1.000 1.000 ## ## R-Square: ## Estimate ## sci.1 0.896 ## sci.2 0.903 ## sci.3 0.915 ## sci.4 0.928 ## ## ## Level 2 [school]: ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## int.b =~ ## sci.1 1.000 4.083 0.969 ## sci.2 1.000 4.083 0.969 ## sci.3 1.000 4.083 0.969 ## sci.4 1.000 4.083 0.969 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 0.000 0.000 0.000 ## .sci.2 0.000 0.000 0.000 ## .sci.3 0.000 0.000 0.000 ## .sci.4 0.000 0.000 0.000 ## int.b 59.767 0.427 139.929 0.000 14.639 14.639 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .sci.1 (b) 1.090 0.302 3.609 0.000 1.090 0.061 ## .sci.2 (b) 1.090 0.302 3.609 0.000 1.090 0.061 ## .sci.3 (b) 1.090 0.302 3.609 0.000 1.090 0.061 ## .sci.4 (b) 1.090 0.302 3.609 0.000 1.090 0.061 ## int.b 16.668 6.440 2.588 0.010 1.000 1.000 ## ## R-Square: ## Estimate ## sci.1 0.939 ## sci.2 0.939 ## sci.3 0.939 ## sci.4 0.939 Here we get a similar layout for the results as the multiple groups model, with the within estimates first, and then the school-level estimates next. We needed to set the residuals to be homoscedastic to achieve convergence here, but in principle these can be allowed to vary. Cluster Correction The fixed effects point estimates within the model tend to be robust to the omission of higher levels of nesting, however, their standard errors do tend to be inaccurate. As such, sometimes we might wish to simply not interpret the variance components and focus on regression coefficients or other parts of our model. This might be less frequent in growth modeling, but for completeness we will consider this type of application. In this instance, we can simply implement a cluster-correction to our standard errors and then proceed as usual to interpret the model parameters. To our knowledge, this is not currently an option in R, so we provide the Mplus syntax to do so below. "],["07-datasets.html", "Datasets Descriptions", " Datasets Use the button below to download all datasets used in this primer. Note that these datasets have been either simulated or synthesized and therefore are not to be used to test substantive research hypotheses. Download Codebook Datasets Descriptions Executive Function The executive.function dataset is a single-cohort longitudinal design, consisting of \\(342\\) adolescents, ages \\(11.74 - 15.33\\), assessed annually across \\(4\\) waves. The repeated measures of interest are DLPFC activation during an executive function task (dlpfc*) and behavioral scores on that task (ef*). Additional variables include time-invariant covariates, self-identified sex (sex) and assigned treatment group (tx), as well as age at observation (age*). A subset of this dataset is used as the single.cohort data in Chapter 3. Feedback Learning The feedback.learning dataset is an accelerated longitudinal design, consisting of \\(297\\) young people, ages \\(8.01 - 28.72\\), assessed annually across \\(3\\) waves. The repeated measures of interest are brain network modularity (modularity) and behavioral performance (learning.rate) during a feedback learning task. Additional variables include the time-invariant covariate of self-identified sex (male) and time-varying covariates including, wave of assessment (wave), pubertal status (puberty), and IQ (iq). This dataset is used as the accelerated dataset in Chapter 3. These data were synthesized from data analyzed in McCormick et al., 2021. the real data used in that manuscript is provided in the supplemental material. Externalizing and Math The external.math dataset is a multiple-cohort longitudinal design, consisting of \\(405\\) adolescents, ages \\(6 - 14\\), measured bi-annually across \\(4\\) waves. The repeated measures of interest are measures of externalizing behavior (ext*) and math achievement (math*). Adversity The adversity dataset is a multiple-cohort longitudinal design, consisting of \\(398\\) children, ages \\(4 - 11\\), measured bi-annually across \\(4\\) waves. The repeated measure of interest is the white matter fractional anisotropy of the forceps minor tract (fmin*). Additional variables include a set of time-invariant covariates: self-identifed sex (sex), experiences of early-childhood abuse (abuse), experiences of early-childhood neglect (neglect), levels of early-childhood parental warmth (warmth), and four measures of cognitive stimulation (cog*). This dataset is used as the multiple.cohort dataset in Chapter 3. Trials The trials dataset contains trial-level responses from the feedback learning task that was used in the feedback.learning dataset. The repeated measures include \\(7\\) trials for \\(297\\) individuals. Achieve The achieve dataset is a single-cohort longitudinal design, consisting of \\(1237\\) adolescents, ages \\(12 - 17\\), sampled across \\(4\\) waves from \\(41\\) schools in \\(5\\) geographic locations (site). The repeated measures of interest include math (math) and science (sci) achievement scores. The dataset includes an additional time-invariant covariate of self-identified sex (male). "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
